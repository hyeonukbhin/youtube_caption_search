[all right welcome back to machine](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m00s)
00:00:00

[learning I am really excited to be able](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m01s)
00:00:01

[to share some amazing stuff that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m06s)
00:00:06

[University of San Francisco students](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m08s)
00:00:08

[have built during the week or written](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m10s)
00:00:10

[about during the week and quite a few](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m12s)
00:00:12

[things are going to show you have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m15s)
00:00:15

[already spread around the internet quite](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m17s)
00:00:17

[a bit lots of tweets and posts and all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m20s)
00:00:20

[kinds of stuff happening one of the the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m25s)
00:00:25

[first to be widely shared was this one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m29s)
00:00:29

[by Tyler who did something really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m31s)
00:00:31

[interesting he he started out by saying](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m34s)
00:00:34

[like what if I like create the synthetic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m38s)
00:00:38

[data set where the independent variables](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m40s)
00:00:40

[is like the X and the y and the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m42s)
00:00:42

[dependent variable is like color right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m44s)
00:00:44

[and interestingly he showed me an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m47s)
00:00:47

[earlier version of this where he wasn't](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m48s)
00:00:48

[using color he was just like putting the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m50s)
00:00:50

[actual numbers in here and this thing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m52s)
00:00:52

[kind of wasn't really working at all and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m55s)
00:00:55

[as soon as he started using Kawa it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m57s)
00:00:57

[started working really well and so I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h00m59s)
00:00:59

[wanted to mention that one of the things](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m01s)
00:01:01

[that unfortunately we we don't teach you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m03s)
00:01:03

[at USF is a theory of human perception](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m05s)
00:01:05

[perhaps we should because actually when](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m10s)
00:01:10

[it comes to visualization its kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m12s)
00:01:12

[the most important thing to know is what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m14s)
00:01:14

[is the human eye or what is what what it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m16s)
00:01:16

[was the human brain good at perceiving](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m19s)
00:01:19

[there's a whole area of academic study](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m20s)
00:01:20

[on this and one of the things that we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m23s)
00:01:23

[best at perceiving is differences in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m25s)
00:01:25

[color right so that's why as soon as we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m27s)
00:01:27

[look at this picture of this synthetic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m30s)
00:01:30

[data he created you can immediately say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m31s)
00:01:31

[oh there's kind of four areas of you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m33s)
00:01:33

[know lighter red color so what he did](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m36s)
00:01:36

[was he said okay what if we like tried](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m40s)
00:01:40

[to create a machine learning model of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m42s)
00:01:42

[this synthetic data set and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m45s)
00:01:45

[specifically he created a tree and the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m47s)
00:01:47

[cool thing is that you can actually draw](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m50s)
00:01:50

[the tree right so after he created the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m52s)
00:01:52

[tree he did this all in matplotlib](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m55s)
00:01:55

[matplotlib is very flexible right he](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m56s)
00:01:56

[actually drew the tree boundaries so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h01m59s)
00:01:59

[that's already a pretty neat trick is to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m03s)
00:02:03

[be actually able to draw the tree but](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m06s)
00:02:06

[then he did something even cleverer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m08s)
00:02:08

[which is he said okay so what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m09s)
00:02:09

[predictions does the tree make well as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m11s)
00:02:11

[the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m13s)
00:02:13

[average of each of these areas and so to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m13s)
00:02:13

[do that we can actually draw the average](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m16s)
00:02:16

[color alright there's actually kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m18s)
00:02:18

[pretty](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m21s)
00:02:21

[here is the predictions that the tree](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m22s)
00:02:22

[makes now here's where it gets really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m24s)
00:02:24

[interesting is like you can as you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m29s)
00:02:29

[randomly generate trees through](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m31s)
00:02:31

[resampling and so here are four trees](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m35s)
00:02:35

[generated through resampling they're all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m39s)
00:02:39

[like pretty similar but a little bit](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m42s)
00:02:42

[different and so now we can actually](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m43s)
00:02:43

[visualize bagging and to visualize](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m45s)
00:02:45

[bagging we literally take the average of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m47s)
00:02:47

[the four pictures all right that's what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m50s)
00:02:50

[bagging is and there it is alright and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m53s)
00:02:53

[so here is like the the fuzzy decision](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m56s)
00:02:56

[boundaries of a random forest and I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h02m59s)
00:02:59

[think this is kind of amazing right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m03s)
00:03:03

[because it's it's like a I wish I had](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m04s)
00:03:04

[this actually when I started teaching](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m07s)
00:03:07

[you all random forest because I could](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m08s)
00:03:08

[have skipped a couple of classes it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m10s)
00:03:10

[just like okay that's what we do you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m12s)
00:03:12

[know we create the decision boundaries](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m14s)
00:03:14

[we average each area and then we we do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m16s)
00:03:16

[it a few times in average all of them](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m20s)
00:03:20

[okay so that's what a random forest does](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m21s)
00:03:21

[and I think like this is just such a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m23s)
00:03:23

[great example of making the complex easy](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m25s)
00:03:25

[through through pictures so congrats to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m30s)
00:03:30

[Tyler for that it actually turns out](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m33s)
00:03:33

[that he has actually reinvented](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m36s)
00:03:36

[something that somebody else has already](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m39s)
00:03:39

[done a guy called Christian any who went](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m41s)
00:03:41

[on to be one of the world's foremost](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m43s)
00:03:43

[machine learning researchers actually](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m46s)
00:03:46

[included almost exactly this technique](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m48s)
00:03:48

[in a book he wrote about decision](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m50s)
00:03:50

[forests so it's actually kind of cool](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m52s)
00:03:52

[that Tyler ended up reinventing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m53s)
00:03:53

[something that one of the world's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m55s)
00:03:55

[foremost authorities on v decision](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m57s)
00:03:57

[forests actually it has created so I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h03m59s)
00:03:59

[thought that was me that's nice because](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m02s)
00:04:02

[when we pup when we posted this on](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m04s)
00:04:04

[Twitter you know got a lot of attention](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m05s)
00:04:05

[and finally somebody with it was able to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m07s)
00:04:07

[say like oh you know what this this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m09s)
00:04:09

[actually already exists so Tyler has](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m10s)
00:04:10

[gone away and you know started reading](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m12s)
00:04:12

[that book something else which is super](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m14s)
00:04:14

[cool is Jason Carpenter created a whole](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m18s)
00:04:18

[new library called Parfitt and Parfitt](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m22s)
00:04:22

[is a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m26s)
00:04:26

[parallelized fitting of multiple models](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m27s)
00:04:27

[for the purpose of selecting hyper](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m30s)
00:04:30

[parameters and there's a lot I really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m33s)
00:04:33

[like about this he's shown a clear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m35s)
00:04:35

[example of how to use it right and like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m40s)
00:04:40

[the API looks very similar to other grid](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m42s)
00:04:42

[search based approaches but it uses the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m45s)
00:04:45

[validation techniques that Rachel wrote](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m48s)
00:04:48

[about and that we learnt about a couple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m51s)
00:04:51

[of weeks ago of using a good validation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m53s)
00:04:53

[set and you know what he's done here is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m55s)
00:04:55

[in his blog post that introduces it you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h04m59s)
00:04:59

[know he's he's gone right back and said](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m03s)
00:05:03

[like what are hyper parameters why do we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m06s)
00:05:06

[have to train them and he's kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m08s)
00:05:08

[explained every step and then the the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m09s)
00:05:09

[module itself is like it's it's very](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m12s)
00:05:12

[polished you know he's added](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m15s)
00:05:15

[documentation to it he's added a nice](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m16s)
00:05:16

[readme to it and it's kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m18s)
00:05:18

[interesting when you actually look at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m21s)
00:05:21

[the code you realize you know it's very](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m22s)
00:05:22

[simple you know which is it's definitely](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m24s)
00:05:24

[not a bad thing that's a good thing as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m26s)
00:05:26

[to is to make things simple but by kind](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m28s)
00:05:28

[of writing this little bit of code and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m32s)
00:05:32

[then packaging it up so nicely he's made](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m34s)
00:05:34

[it really easy for other people to use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m36s)
00:05:36

[this technique which is great and so one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m38s)
00:05:38

[of the things I've been really thrilled](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m42s)
00:05:42

[to see is then Vinay went along and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m44s)
00:05:44

[combined two things from our class one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m46s)
00:05:46

[was to take profit and then the other](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m49s)
00:05:49

[was to take the kind of accelerated SGD](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m52s)
00:05:52

[approach to classification we turn](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m54s)
00:05:54

[learned about in the last lesson and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m57s)
00:05:57

[combine the two to say like okay well](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h05m59s)
00:05:59

[let's now use half it to help us find](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m01s)
00:06:01

[the parameters of a SGD logistic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m04s)
00:06:04

[regression so I think that's really a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m08s)
00:06:08

[really great idea something else which I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m10s)
00:06:10

[thought was terrific is print sexually](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m15s)
00:06:15

[basically went through and summarized](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m18s)
00:06:18

[pretty much all the stuff we learnt in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m22s)
00:06:22

[the random and random forest](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m25s)
00:06:25

[interpretation plus and he went even](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m26s)
00:06:26

[further than that as he described each](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m30s)
00:06:30

[of the different approaches to random](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m32s)
00:06:32

[forest interpretation he described how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m34s)
00:06:34

[it's done so here for example is feature](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m38s)
00:06:38

[importance](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m40s)
00:06:40

[a variable permutation a little picture](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m41s)
00:06:41

[of each one and then super cool here is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m44s)
00:06:44

[the code to implement it from scratch so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m47s)
00:06:47

[I think this is like really nice post](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m51s)
00:06:51

[you know describing something that not](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m54s)
00:06:54

[many people understand and showing you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m56s)
00:06:56

[know exactly how it works both with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h06m58s)
00:06:58

[pictures and with code that implements](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m00s)
00:07:00

[it from scratch so I think that's really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m03s)
00:07:03

[really great one of the things I really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m05s)
00:07:05

[like here is that for like the tree](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m07s)
00:07:07

[interpreter but he actually showed how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m10s)
00:07:10

[you can take the tree interpreter output](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m13s)
00:07:13

[and feed it into the new waterfall chart](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m15s)
00:07:15

[package that Chris USF student built to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m18s)
00:07:18

[show how you can actually visualize the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m21s)
00:07:21

[contributions of the tree interpreter in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m24s)
00:07:24

[a waterfall chart so again kind of a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m27s)
00:07:27

[nice combination of multiple pieces of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m28s)
00:07:28

[technology we both learned about and and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m32s)
00:07:32

[built as a group I also really thought](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m34s)
00:07:34

[this kernel there's been a few](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m39s)
00:07:39

[interesting kernels share it and I'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m40s)
00:07:40

[share some more next week and diverse](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m42s)
00:07:42

[wrote this really nice kernel showing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m44s)
00:07:44

[this is quite challenging careful](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m46s)
00:07:46

[competition on detecting icebergs versus](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m49s)
00:07:49

[chips and it's a kind of a weird two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m52s)
00:07:52

[channel satellite data which is very](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m56s)
00:07:56

[hard to visualize and he actually went](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h07m59s)
00:07:59

[through and basically described kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m03s)
00:08:03

[the formulas for how these like radar](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m05s)
00:08:05

[scattering things actually work and then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m08s)
00:08:08

[actually managed to come up with a code](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m12s)
00:08:12

[that allowed him to recreate you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m14s)
00:08:14

[the actual 3d icebergs or ships and I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m18s)
00:08:18

[have not seen that done before or like I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m25s)
00:08:25

[you know it's it's quite challenging to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m27s)
00:08:27

[know how to visualize his data and then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m29s)
00:08:29

[he went on to show how to build a neural](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m31s)
00:08:31

[net to try to interpret this so that was](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m34s)
00:08:34

[pretty fantastic as well so yeah](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m37s)
00:08:37

[congratulations](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m40s)
00:08:40

[for all of you I know for a lot of you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m41s)
00:08:41

[you know you're posting stuff out there](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m43s)
00:08:43

[to the rest of the world for the first](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m47s)
00:08:47

[time you know and it's kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m48s)
00:08:48

[intimidating you're used to writing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m50s)
00:08:50

[stuff that you got a hand into a teacher](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m52s)
00:08:52

[and there](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m54s)
00:08:54

[any ones who see it and you know it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m55s)
00:08:55

[kind of scary the first time you do it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m58s)
00:08:58

[but then the first time somebody you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h08m59s)
00:08:59

[know that votes your cable kernel or ATS](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m01s)
00:09:01

[a clap to your medium post he suddenly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m04s)
00:09:04

[realized oh I'm actually I've written](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m06s)
00:09:06

[something that people like that's that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m09s)
00:09:09

[pretty great so if you haven't tried](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m11s)
00:09:11

[yourself yet](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m13s)
00:09:13

[I again invite you to try writing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m14s)
00:09:14

[something and if you're not sure you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m18s)
00:09:18

[could write a summary of a lesson you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m20s)
00:09:20

[could write a summary of like if there's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m23s)
00:09:23

[something you found hard like maybe you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m25s)
00:09:25

[found it hard to fire up a gpu-based AWS](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m27s)
00:09:27

[instance you eventually figured it out](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m30s)
00:09:30

[you know you could write down just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m31s)
00:09:31

[describe how you solve that problem or](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m33s)
00:09:33

[if one of your classmates didn't](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m34s)
00:09:34

[understand something and you explained](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m37s)
00:09:37

[it to them then you could like write](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m39s)
00:09:39

[down something saying like oh there's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m40s)
00:09:40

[this concept that some people have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m42s)
00:09:42

[trouble understanding here's a good way](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m43s)
00:09:43

[I think of explaining it there's all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m45s)
00:09:45

[kinds of stuff you could you could do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m47s)
00:09:47

[okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m52s)
00:09:52

[so let's go back to SGD and so we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h09m53s)
00:09:53

[going back through this logbook which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m04s)
00:10:04

[Rachel put together basically taking us](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m09s)
00:10:09

[through kind of SGD from scratch for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m12s)
00:10:12

[purpose of digit recognition and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m16s)
00:10:16

[actually quite a lot of the stuff we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m19s)
00:10:19

[look at today is going to be closely](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m20s)
00:10:20

[following part of the computation or](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m24s)
00:10:24

[linear algebra course which you can both](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m27s)
00:10:27

[find the MOOCs on faster I or at USF](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m30s)
00:10:30

[it'll be an elective next year alright](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m33s)
00:10:33

[so if you find some of this this stuff](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m35s)
00:10:35

[interesting and I hope you do then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m39s)
00:10:39

[please consider signing up for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m41s)
00:10:41

[elective or checking out the video](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m43s)
00:10:43

[online so we're building neural networks](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m45s)
00:10:45

[and we're starting with an assumption](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m56s)
00:10:56

[that we've downloaded the eminence data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h10m59s)
00:10:59

[we've normalized it by subtracting the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m01s)
00:11:01

[main and divided by the standard](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m03s)
00:11:03

[deviation okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m04s)
00:11:04

[so the data is it's slightly unusual in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m06s)
00:11:06

[that although they represent images they](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m11s)
00:11:11

[where they were downloaded as each image](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m13s)
00:11:13

[was a 784 long rank one tensor so it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m15s)
00:11:15

[been flattened out okay and so for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m20s)
00:11:20

[purpose of drawing pictures of it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m23s)
00:11:23

[we had to resize it to 28 by 28 but the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m25s)
00:11:25

[actual data we've got is not 28 by 28 it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m31s)
00:11:31

[says it's it's 784 long flattened out](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m34s)
00:11:34

[okay four basic steps we're gonna take](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m40s)
00:11:40

[here is to start out with training the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m44s)
00:11:44

[world's simplest neural network](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m49s)
00:11:49

[basically a logistic regression right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m51s)
00:11:51

[no hidden layers and we're going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m54s)
00:11:54

[Train it using a library fast AI and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h11m56s)
00:11:56

[we're going to build the network using a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m00s)
00:12:00

[library plate watch right and then we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m02s)
00:12:02

[going to gradually get rid of all the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m05s)
00:12:05

[libraries right so first of all well get](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m06s)
00:12:06

[rid of the N n neural net library and pi](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m09s)
00:12:09

[torch and write that ourselves then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m12s)
00:12:12

[we'll get rid of the fast a I fit](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m16s)
00:12:16

[function and write that ourselves and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m18s)
00:12:18

[then we'll get rid of the PI torch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m20s)
00:12:20

[optimizer and write that ourselves and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m22s)
00:12:22

[so by the end of this notebook](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m25s)
00:12:25

[we'll have written all the pieces](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m29s)
00:12:29

[ourselves the only thing that will end](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m30s)
00:12:30

[up relying on is the two key things that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m32s)
00:12:32

[pi torch gives us which is a the ability](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m35s)
00:12:35

[to write Python code and have it run on](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m37s)
00:12:37

[the GPU and be the ability to write](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m39s)
00:12:39

[Python code and have it automatically](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m42s)
00:12:42

[differentiated for us okay so there are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m45s)
00:12:45

[two things we're not going to attempt to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m48s)
00:12:48

[write ourselves because it's boring and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m50s)
00:12:50

[pointless but everything else we'll try](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m51s)
00:12:51

[and write ourselves on top of those two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m53s)
00:12:53

[things ok so our starting point is like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h12m56s)
00:12:56

[not doing anything ourselves it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m01s)
00:13:01

[basically having it all done for us and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m03s)
00:13:03

[so PI torch has an N n library which is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m05s)
00:13:05

[where the neural net stuff lives](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m08s)
00:13:08

[you can create a multi-layer neural](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m10s)
00:13:10

[network by using the sequential function](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m13s)
00:13:13

[and then passing in a list of the layers](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m15s)
00:13:15

[that you want and we asked for a linear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m17s)
00:13:17

[layer followed by a softmax layer and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m20s)
00:13:20

[that defines our logistic regression](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m22s)
00:13:22

[okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m25s)
00:13:25

[the input to our linear layer is 28 by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m26s)
00:13:26

[28 as we just discussed the output is 10](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m29s)
00:13:29

[because we want a probability for each](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m33s)
00:13:33

[of the numbers not through 9 for each of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m35s)
00:13:35

[our images okay CUDA sticks it on the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m38s)
00:13:38

[GPU and then fit fits a model ok so we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m43s)
00:13:43

[start out with a random set of weights](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m52s)
00:13:52

[and then fit users gradient descent to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m54s)
00:13:54

[make it better we had to tell the fit](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h13m56s)
00:13:56

[function what criterion to use in other](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m00s)
00:14:00

[words what counts is better and we told](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m03s)
00:14:03

[it to use negative log likelihood we'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m06s)
00:14:06

[learn about that in the next lesson what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m08s)
00:14:08

[that is exactly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m10s)
00:14:10

[we had to tell it what optimizer to use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m11s)
00:14:11

[and we said please use opt M not Adam](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m14s)
00:14:14

[the details of that we won't cover in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m17s)
00:14:17

[this course we're going to use something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m20s)
00:14:20

[build something simpler called SGD if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m21s)
00:14:21

[you interested in Adam we just covered](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m24s)
00:14:24

[that in the dick learning course and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m25s)
00:14:25

[what metrics do you want to print out we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m28s)
00:14:28

[decided to print out accuracy ok so that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m30s)
00:14:30

[was that and so if we do that ok so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m34s)
00:14:34

[after we fit it we get an accuracy of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m42s)
00:14:42

[generally somewhere around 91 92 percent](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m44s)
00:14:44

[so what we going to do from here is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m47s)
00:14:47

[we're going to gradually we're going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m50s)
00:14:50

[repeat this exact same thing so we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m52s)
00:14:52

[going to rebuild this model you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m54s)
00:14:54

[four or five times fitting it building](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h14m58s)
00:14:58

[it and fitting it with less and less](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m01s)
00:15:01

[libraries ok](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m02s)
00:15:02

[so the second thing that we did last](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m04s)
00:15:04

[time was to try to start to define the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m07s)
00:15:07

[the module ourselves right so instead of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m13s)
00:15:13

[saying the network is a sequential bunch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m17s)
00:15:17

[of these layers let's not use that like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m20s)
00:15:20

[at all and try and define it ourself](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m23s)
00:15:23

[from scratch okay so to do that we have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m25s)
00:15:25

[to use our because that's how we build](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m29s)
00:15:29

[everything in play torch and we have to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m33s)
00:15:33

[create a class which inherits from an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m36s)
00:15:36

[end module so n n dot module is a PI](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m41s)
00:15:41

[torch class that takes our class and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m44s)
00:15:44

[turns it into a neural network module](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m48s)
00:15:48

[which basically means we'll anything](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m51s)
00:15:51

[that you inherit from an end module like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m53s)
00:15:53

[this you can pretty much insert into a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m55s)
00:15:55

[neural network as a layer or you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h15m58s)
00:15:58

[treat it as a neural network it's going](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m01s)
00:16:01

[to get all the stuff that it needs](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m02s)
00:16:02

[automatically to to work as a part of or](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m04s)
00:16:04

[a full neural network now we'll talk](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m08s)
00:16:08

[about exactly what that means today in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m10s)
00:16:10

[the next lesson right so we need to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m12s)
00:16:12

[construct the object so that means we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m18s)
00:16:18

[need to define the constructor Thunder](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m20s)
00:16:20

[in it and then importantly this is a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m22s)
00:16:22

[Python thing is if you inherit from some](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m25s)
00:16:25

[other object then you have to create the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m29s)
00:16:29

[thing you inherit from first](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m31s)
00:16:31

[so when you say super dot dunder init](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m33s)
00:16:33

[that says construct the enn module piece](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m36s)
00:16:36

[of that first right if you don't do that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m40s)
00:16:40

[then the NN dot module stuff never gets](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m43s)
00:16:43

[a chance to actually get constructed](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m46s)
00:16:46

[right so this is just like a standard](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m48s)
00:16:48

[Python oo subclass constructor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m51s)
00:16:51

[okay and if any if that's on unclear to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m55s)
00:16:55

[you then you know this is where you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m58s)
00:16:58

[definitely want to just grab a Python](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h16m59s)
00:16:59

[intro 200 because this is the standard](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m02s)
00:17:02

[approach all right so inside our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m05s)
00:17:05

[constructor we want to do the equivalent](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m07s)
00:17:07

[of an end linea all right so what n n](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m10s)
00:17:10

[dot linea is doing is it's taking our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m15s)
00:17:15

[it's taking our 28 by 28 vector so 768](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m22s)
00:17:22

[long vector and we're going to be that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m30s)
00:17:30

[going to be the input to a matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m34s)
00:17:34

[multiplication](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m36s)
00:17:36

[so we now need to create a something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m37s)
00:17:37

[with 768 rows and that's 768 and 10](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m41s)
00:17:41

[columns ok so because the input to this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m49s)
00:17:49

[is going to be a mini batch of size](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m53s)
00:17:53

[actually let's move this into a new](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h17m59s)
00:17:59

[window 768 by 10 and the input to this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m01s)
00:18:01

[is going to be a mini batch of size 64](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m11s)
00:18:11

[by 768 right so we're going to do this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m15s)
00:18:15

[matrix product ok so when we say in pie](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m21s)
00:18:21

[chart and in linea it's going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m26s)
00:18:26

[construct this matrix for us right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m31s)
00:18:31

[since we are not using that we're doing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m35s)
00:18:35

[things from scratch we need to make it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m37s)
00:18:37

[ourselves so to make it ourselves we can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m38s)
00:18:38

[say generate normal random numbers with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m40s)
00:18:40

[this dimensionality which we passed in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m45s)
00:18:45

[here 768 by 10 okay so that gives us our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m49s)
00:18:49

[our randomly initialized matrix okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m52s)
00:18:52

[then we want to add on to this you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h18m57s)
00:18:57

[we don't just want y equals ax we want y](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m04s)
00:19:04

[equals ax plus B all right so we need to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m07s)
00:19:07

[add on what we call in neural Nets of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m09s)
00:19:09

[bias vector so we create here a bias](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m12s)
00:19:12

[vector of length 10 okay again randomly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m15s)
00:19:15

[initialized and so now here are our two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m19s)
00:19:19

[randomly initialized weight tensors so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m23s)
00:19:23

[that's our constructor okay now we need](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m27s)
00:19:27

[to find for word why do we need to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m31s)
00:19:31

[define for word this is a PI torch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m33s)
00:19:33

[specific thing what's going to happen is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m35s)
00:19:35

[this is when you create a module in PI](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m38s)
00:19:38

[torch the objects that you get back](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m43s)
00:19:43

[behaves as if it's a function you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m45s)
00:19:45

[call it with parentheses which will do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m48s)
00:19:48

[it that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m50s)
00:19:50

[a moment and so you need to somehow](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m50s)
00:19:50

[define what happens when you call it as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m52s)
00:19:52

[if it's a function and the answer is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m55s)
00:19:55

[tight which calls a method called](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h19m58s)
00:19:58

[forward okay that's just that that's the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m00s)
00:20:00

[pie that the PI torch kind of approach](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m03s)
00:20:03

[that they picked right so when it calls](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m06s)
00:20:06

[forward we need to do our actual](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m09s)
00:20:09

[calculation of the output of this module](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m11s)
00:20:11

[or letter okay so here is the thing that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m13s)
00:20:13

[actually gets calculated in a logistic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m17s)
00:20:17

[regression so basically we take our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m19s)
00:20:19

[input X which gets passed to forward](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m23s)
00:20:23

[that's basically how forward works it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m28s)
00:20:28

[gets past the mini-batch and we matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m30s)
00:20:30

[multiply it by the layer one weights](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m34s)
00:20:34

[which we defined up here and then we add](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m38s)
00:20:38

[on the layer one bias which we defined](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m41s)
00:20:41

[up here okay and actually nowadays we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m45s)
00:20:45

[can define this a little bit more](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m48s)
00:20:48

[elegantly using the Python three matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m49s)
00:20:49

[multiplication operator which is the at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m55s)
00:20:55

[sign and when you when you use that I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h20m57s)
00:20:57

[think you kind of end up with something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m00s)
00:21:00

[that looks closer to what the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m02s)
00:21:02

[mathematical notation looked like and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m03s)
00:21:03

[I find that nicer okay all right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m05s)
00:21:05

[that's that's our linear layer in our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m10s)
00:21:10

[logistic regression you know a zero](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m14s)
00:21:14

[hidden layer neural net so then the next](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m16s)
00:21:16

[thing we do to that is soft next okay so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m18s)
00:21:18

[we get the output of this matrix model](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m24s)
00:21:24

[play okay who wants to tell me what the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m30s)
00:21:30

[dimensionality of my output of this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m34s)
00:21:34

[matrix model play is sorry 64 by 10](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m36s)
00:21:36

[thank you Karen I should mention for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m42s)
00:21:42

[those of you that weren't at deep](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m47s)
00:21:47

[learning class yesterday we actually](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m49s)
00:21:49

[looked at a really cool post from Karam](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m51s)
00:21:51

[who described how to do structured data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m54s)
00:21:54

[analysis with neural nets which has been](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m57s)
00:21:57

[like super popular and a whole bunch of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h21m59s)
00:21:59

[people who kind of said that they've](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m01s)
00:22:01

[read it and found it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m03s)
00:22:03

[interesting so that was really exciting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m04s)
00:22:04

[so we get this matrix of outputs and we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m09s)
00:22:09

[put this through a softmax and why do we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m13s)
00:22:13

[put it through a softmax we put it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m18s)
00:22:18

[through a softmax because in the end we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m20s)
00:22:20

[want probably you know for every image](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m22s)
00:22:22

[we want a probability that is a 0 or a 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m24s)
00:22:24

[or a 2 or 3 or 4 all right so we want a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m26s)
00:22:26

[bunch of probabilities that add up to 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m29s)
00:22:29

[and where each of those probabilities is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m31s)
00:22:31

[between 0 &amp; 1 so a softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m34s)
00:22:34

[does exactly that for us so for example](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m38s)
00:22:38

[if we weren't picking out you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m43s)
00:22:43

[numbers from nought to 10 but instead of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m45s)
00:22:45

[picking it out cat dog play an official](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m46s)
00:22:46

[building the output of that matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m48s)
00:22:48

[multiplied for one particular image](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m50s)
00:22:50

[might look like that these are just some](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m51s)
00:22:51

[random numbers and to turn that into a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m54s)
00:22:54

[softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m56s)
00:22:56

[I first go a to the power of each of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h22m57s)
00:22:57

[those numbers i sum up those eight of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m01s)
00:23:01

[the power offs and then I take each of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m06s)
00:23:06

[those eight of the power of z' and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m10s)
00:23:10

[divide it by the sum and that softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m11s)
00:23:11

[that's the definition of softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m14s)
00:23:14

[so because it was in the power of it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m16s)
00:23:16

[means it's always positive because it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m18s)
00:23:18

[was divided by the sum it means that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m20s)
00:23:20

[it's always between zero and one and it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m23s)
00:23:23

[also means because it's divided by the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m25s)
00:23:25

[sum that they always add up to one so by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m27s)
00:23:27

[applying this softmax activation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m31s)
00:23:31

[function so anytime we have a layer of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m34s)
00:23:34

[outputs which we call activations and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m38s)
00:23:38

[then we apply some function some](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m40s)
00:23:40

[nonlinear function to that that map's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m43s)
00:23:43

[1:1 scale at a one scalar like softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m47s)
00:23:47

[does we call that an activation function](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m50s)
00:23:50

[okay so the softmax activation function](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m51s)
00:23:51

[takes our outputs and turns it into](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m54s)
00:23:54

[something which behaves like a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m57s)
00:23:57

[probability right we don't strictly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h23m58s)
00:23:58

[speaking need it we could still try and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m01s)
00:24:01

[train something which where the output](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m03s)
00:24:03

[directly is the probabilities right but](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m06s)
00:24:06

[by creating using this function that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m09s)
00:24:09

[automatically makes them always behave](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m11s)
00:24:11

[like probabilities it means there's less](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m14s)
00:24:14

[for the network to learn](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m16s)
00:24:16

[so it's going to learn better alright so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m18s)
00:24:18

[generally speaking whenever we design an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m20s)
00:24:20

[architecture we try to design it in a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m23s)
00:24:23

[way where it's as easy as possible for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m26s)
00:24:26

[it to create something of the form that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m29s)
00:24:29

[we want so that's why we use softmax](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m32s)
00:24:32

[right so that's the basic steps right we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m39s)
00:24:39

[have our input which is a bunch of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m41s)
00:24:41

[images right which is here it gets](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m43s)
00:24:43

[multiplied by a weight metrics we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m46s)
00:24:46

[actually also add on a bias right to get](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m49s)
00:24:49

[a output of the linear function we put](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m54s)
00:24:54

[it through a nonlinear activation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m57s)
00:24:57

[function in this case softmax and that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h24m59s)
00:24:59

[gives us our probabilities so there](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m02s)
00:25:02

[there that all is hi torch also tends to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m07s)
00:25:07

[use the log of softmax for reasons that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m13s)
00:25:13

[don't particularly need fatherís now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m18s)
00:25:18

[it's basically a numerical stability](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m19s)
00:25:19

[convenience okay so to make this the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m22s)
00:25:22

[same as our version up here that you saw](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m25s)
00:25:25

[log softmax I'm going to use log here as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m28s)
00:25:28

[well okay so we can now instantiate this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m32s)
00:25:32

[class that is create an object of this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m38s)
00:25:38

[class so I have a question back for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m40s)
00:25:40

[probabilities where we were before](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m46s)
00:25:46

[hmm so if we were to have a photo with a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m48s)
00:25:48

[cat and a dog together would that change](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m53s)
00:25:53

[the way that that works or does it work](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m55s)
00:25:55

[in the same basic yes that's a great](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h25m57s)
00:25:57

[question so if you had a photo with a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m00s)
00:26:00

[cat and a dog together and you wanted it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m02s)
00:26:02

[to spit out both cat and dog this would](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m05s)
00:26:05

[be a very poor choice so softmax is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m08s)
00:26:08

[specifically the activation function we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m11s)
00:26:11

[use for categorical predictions where we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m13s)
00:26:13

[only ever want to predict one of those](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m16s)
00:26:16

[things right and so part of the reason](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m18s)
00:26:18

[why is that as you can see because we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m21s)
00:26:21

[using e to the right e to the slightly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m23s)
00:26:23

[bigger numbers creates much bigger](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m26s)
00:26:26

[numbers as a result of which we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m28s)
00:26:28

[generally have just one or two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m30s)
00:26:30

[large and everything else is pretty](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m32s)
00:26:32

[small right so if I like recalculate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m34s)
00:26:34

[these rounded numbers a few times you'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m36s)
00:26:36

[see like it tends to be a bunch of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m38s)
00:26:38

[zeroes and one or two high numbers right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m39s)
00:26:39

[so it's really designed to try to kind](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m42s)
00:26:42

[of make it easy to predict like this one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m46s)
00:26:46

[thing is the thing I want if you're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m50s)
00:26:50

[doing multi-label prediction so I want](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m52s)
00:26:52

[to just find all the things in this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m56s)
00:26:56

[image rather than using softmax we would](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m57s)
00:26:57

[instead use sigmoid that's a sigmoid](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h26m59s)
00:26:59

[recall it would cause each of these](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m01s)
00:27:01

[between to be between 0 &amp; 1 but they](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m03s)
00:27:03

[would no longer add to 1 it's a good](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m06s)
00:27:06

[question and like a lot of these details](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m09s)
00:27:09

[about like best practices are things](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m13s)
00:27:13

[that we cover in the deep learning](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m16s)
00:27:16

[course and we won't cover heaps of them](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m17s)
00:27:17

[here and the machine learning course](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m19s)
00:27:19

[we're more interested in the mechanics I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m20s)
00:27:20

[guess but we're trying to do them we've](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m23s)
00:27:23

[they're quick all right so now that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m27s)
00:27:27

[we've got that we can instantiate an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m31s)
00:27:31

[object of that class and of course we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m33s)
00:27:33

[want to copy it over to the GPU so we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m35s)
00:27:35

[can do computations over there again we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m37s)
00:27:37

[need an optimizer we're we talking about](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m40s)
00:27:40

[what this is shortly but you'll see here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m41s)
00:27:41

[we've called a function on our class](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m44s)
00:27:44

[called parameters but we never defined a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m46s)
00:27:46

[method called parameters and the reason](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m49s)
00:27:49

[that is going to work is because it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m52s)
00:27:52

[actually was defined Forest inside an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m53s)
00:27:53

[end up module and so an end up module](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m55s)
00:27:55

[actually automatically go through the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h27m58s)
00:27:58

[attributes we've created and finds](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m00s)
00:28:00

[anything that basically we we said this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m03s)
00:28:03

[is a parameter so the way you say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m07s)
00:28:07

[something is a parameter is you wrap it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m08s)
00:28:08

[in an end off parameter so this is just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m10s)
00:28:10

[the way that you tell PI torch this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m12s)
00:28:12

[something that I want to optimize ok so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m14s)
00:28:14

[when we created the weight matrix we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m17s)
00:28:17

[just wrapped it with an end up parameter](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m19s)
00:28:19

[it's exactly the same as a regular 5](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m21s)
00:28:21

[torch variable which we'll learn about](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m24s)
00:28:24

[shortly it's just a little flag to say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m26s)
00:28:26

[hey you should you should optimize this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m29s)
00:28:29

[and so when you call net to parameters](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m31s)
00:28:31

[on our net to object we created it goes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m34s)
00:28:34

[through everything that we created in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m37s)
00:28:37

[the constructor checks to see if any of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m38s)
00:28:38

[them are of type parameter and if so it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m40s)
00:28:40

[sets all of those being things that we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m43s)
00:28:43

[to train with the optimizer and we'll be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m45s)
00:28:45

[implementing the optimizer from scratch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m48s)
00:28:48

[later okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m49s)
00:28:49

[so having done that we can fit and we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m51s)
00:28:51

[should get basically the same answers](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h28m59s)
00:28:59

[before 91 ish so that looks good all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m01s)
00:29:01

[right so what if we actually built here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m06s)
00:29:06

[well what we've actually built as I said](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m11s)
00:29:11

[is something that can behave like a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m13s)
00:29:13

[regular function all right so I want to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m16s)
00:29:16

[show you how we can actually call this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m18s)
00:29:18

[as a function so to be able to call it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m20s)
00:29:20

[as a function we need to be able to pass](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m22s)
00:29:22

[data to it to be able to pass data to it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m25s)
00:29:25

[I'm going to need to grab a mini batch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m28s)
00:29:28

[of analyst images okay so we used for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m30s)
00:29:30

[convenience the image classifier data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m35s)
00:29:35

[from arrays method from fast AI and what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m38s)
00:29:38

[that does is it creates a PI torch data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m41s)
00:29:41

[loader for us a PI torch data loader is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m44s)
00:29:44

[something that grabs a few images and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m47s)
00:29:47

[sticks them into a mini batch that makes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m49s)
00:29:49

[them available and you can basically say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m52s)
00:29:52

[give me another mini batch pick me](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m54s)
00:29:54

[another mini batch give me another mini](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m55s)
00:29:55

[batch and so in Python we call these](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h29m57s)
00:29:57

[things generators generators are things](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m03s)
00:30:03

[where you can basically say I want](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m06s)
00:30:06

[another I want another I want another](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m08s)
00:30:08

[right there's this kind of very close](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m09s)
00:30:09

[connection between iterators and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m15s)
00:30:15

[generators are not going to worry about](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m17s)
00:30:17

[the difference between them right now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m18s)
00:30:18

[but you'll see basically to turn to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m20s)
00:30:20

[actually get hold of something which we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m25s)
00:30:25

[can say please give me another of in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m27s)
00:30:27

[order to grab something that we can we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m32s)
00:30:32

[can use to generate mini batches we have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m34s)
00:30:34

[to take our data loader and so you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m37s)
00:30:37

[ask for the training data loader from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m39s)
00:30:39

[our model data object you'll see there's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m41s)
00:30:41

[a bunch of different data loader as you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m44s)
00:30:44

[can ask for you can ask for the test](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m45s)
00:30:45

[data loader the Train date loader](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m47s)
00:30:47

[the validation loader or wintered images](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m49s)
00:30:49

[data loader and so forth so we're going](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m52s)
00:30:52

[to grab the training data loader that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m54s)
00:30:54

[was created for us this is a pice](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m57s)
00:30:57

[and plate or data loader well slightly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h30m59s)
00:30:59

[optimized by us but same idea and you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m01s)
00:31:01

[can then say this is a standard Python](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m04s)
00:31:04

[thing we can say turn that into an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m07s)
00:31:07

[iterator turn that into something where](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m09s)
00:31:09

[we can grab another one at a time from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m11s)
00:31:11

[and so once you've done that we've now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m13s)
00:31:13

[got something that we can iterate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m17s)
00:31:17

[through you can use the standard Python](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m18s)
00:31:18

[next function to grab one more thing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m21s)
00:31:21

[from that generator okay so that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m24s)
00:31:24

[returning and the X's from a mini-batch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m29s)
00:31:29

[and the Y's found our mini batch the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m32s)
00:31:32

[other way that you can use generators](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m35s)
00:31:35

[and iterators in python is with a for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m37s)
00:31:37

[loop I could also said like for you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m39s)
00:31:39

[X mini batch comma Y mini batch in data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m42s)
00:31:42

[loader and then like do something right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m46s)
00:31:46

[so when you do that it's actually behind](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m49s)
00:31:49

[the scenes it's basically syntactic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m51s)
00:31:51

[sugar for calling next lots of times](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m53s)
00:31:53

[okay so this is all standard Python](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m55s)
00:31:55

[stuff so that returns a tensor of size](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h31m59s)
00:31:59

[64 by 784 as we would expect right the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m09s)
00:32:09

[the FASTA I library we used defaults to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m14s)
00:32:14

[a mini batch size of 64 that's why it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m17s)
00:32:17

[that long these are all of the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m19s)
00:32:19

[background 0 pixels but they're not](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m22s)
00:32:22

[actually zero in this case why aren't](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m24s)
00:32:24

[they zero yeah they're normalized](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m26s)
00:32:26

[exactly right so we subtracted the mean](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m29s)
00:32:29

[divided by the standard deviation right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m31s)
00:32:31

[so there there it is so now what we want](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m35s)
00:32:35

[to do is we want to pass that into our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m38s)
00:32:38

[our logistic regression so what we might](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m44s)
00:32:44

[do is we'll go variable X M B equals](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m47s)
00:32:47

[variable okay I can take my X mini-batch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m52s)
00:32:52

[I can move it onto the GPU because](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m55s)
00:32:55

[remember my net to object is on the GPU](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h32m58s)
00:32:58

[so our data for it also has to be on the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m02s)
00:33:02

[GPU and then the second thing I do is I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m04s)
00:33:04

[have to wrap it in variable so what is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m07s)
00:33:07

[variable do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m09s)
00:33:09

[this is how we get for free automatic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m10s)
00:33:10

[differentiation hi torch can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m14s)
00:33:14

[automatically differentiate you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m17s)
00:33:17

[pretty much anything right any tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m20s)
00:33:20

[but to do so takes memory and time so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m22s)
00:33:22

[it's not going to always keep track like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m26s)
00:33:26

[to do what have any differentiation it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m29s)
00:33:29

[has to keep track of exactly how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m31s)
00:33:31

[something was calculated we added these](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m33s)
00:33:33

[things together we multiplied it by that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m34s)
00:33:34

[we then took the sign blah blah blah](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m37s)
00:33:37

[right you have to know all of the steps](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m39s)
00:33:39

[because then to do the automatic](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m40s)
00:33:40

[differentiation it has to take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m43s)
00:33:43

[derivative of each step using the chain](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m46s)
00:33:46

[rule multiply them all together right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m48s)
00:33:48

[that's slow and memory intensive so we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m50s)
00:33:50

[have to opt in to saying like okay this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m52s)
00:33:52

[particular thing we're going to be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m55s)
00:33:55

[taking the derivative of later so please](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m56s)
00:33:56

[keep track of all of those operations](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m58s)
00:33:58

[for us and so the way we opt-in is by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h33m59s)
00:33:59

[wrapping a tensor in a variable right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m02s)
00:34:02

[that's how we do it and you'll see that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m07s)
00:34:07

[it looks almost exactly like a tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m11s)
00:34:11

[but it now says variable containing this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m14s)
00:34:14

[tensor right so in pi torch a variable](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m17s)
00:34:17

[has exactly identical api to a tensor or](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m20s)
00:34:20

[actually more specifically a superset](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m24s)
00:34:24

[with the api of a tensor anything we can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m26s)
00:34:26

[do to a tensor we can do to a variable](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m29s)
00:34:29

[but it's going to keep track of exactly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m31s)
00:34:31

[what we did so we can later on take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m34s)
00:34:34

[derivative okay so we can now pass that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m37s)
00:34:37

[into our net to object remember I said](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m44s)
00:34:44

[you can treat this as if it's a function](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m49s)
00:34:49

[right so notice we're not calling dot](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m51s)
00:34:51

[forward we're just treating it as a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m55s)
00:34:55

[function and then remember we took the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h34m58s)
00:34:58

[log so to undo that I'm taking the X and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m01s)
00:35:01

[that will give me my probabilities](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m05s)
00:35:05

[okay so there's my probabilities and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m09s)
00:35:09

[it's got return something of size 64 by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m12s)
00:35:12

[10 so for each image in the mini batch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m21s)
00:35:21

[we've got ten probabilities and you'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m23s)
00:35:23

[see most probabilities are pretty close](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m26s)
00:35:26

[to zero right and a few of them are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m29s)
00:35:29

[quite a bit bigger which is exactly what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m32s)
00:35:32

[we do we're hope right is that it's like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m34s)
00:35:34

[okay it's not a zero it's not a one it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m37s)
00:35:37

[not a two it is a three it's not a four](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m39s)
00:35:39

[it's not a five and so forth so maybe](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m41s)
00:35:41

[this would be a bit easier to read if we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m44s)
00:35:44

[just grabbed like the first three of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m45s)
00:35:45

[them okay just like 10 to the negative](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m47s)
00:35:47

[the neg two five five four okay and then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m51s)
00:35:51

[suddenly here's one which is ten to Nick](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m55s)
00:35:55

[one right so you can kind of see what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h35m56s)
00:35:56

[it's trying to I was trying to do here I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m00s)
00:36:00

[mean we could call like net two dot](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m03s)
00:36:03

[forward and it will do exactly the same](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m08s)
00:36:08

[thing right but that's not how all of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m09s)
00:36:09

[the PI torch mechanics actually work](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m14s)
00:36:14

[it's actually they actually call it as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m16s)
00:36:16

[if it's a function right and so this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m18s)
00:36:18

[actually a really important idea like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m20s)
00:36:20

[because it means that when we define our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m23s)
00:36:23

[own architectures or whatever anywhere](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m26s)
00:36:26

[that you would put in a function you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m28s)
00:36:28

[could put in a layer anyway you put in a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m31s)
00:36:31

[layer you can put in a neural net anyway](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m33s)
00:36:33

[put it on your neck you can put in a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m34s)
00:36:34

[function because as far as pi torch is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m36s)
00:36:36

[concerned they're all just things that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m38s)
00:36:38

[it's going to call just like as if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m40s)
00:36:40

[they're functions so they're all like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m42s)
00:36:42

[interchangeable and this is really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m43s)
00:36:43

[important because that's how we create](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m45s)
00:36:45

[really good neural nets is by mixing and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m48s)
00:36:48

[matching lots of pieces and putting them](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m51s)
00:36:51

[all together right let me give an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m53s)
00:36:53

[example here is my logistic regression](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h36m55s)
00:36:55

[which got 91 and a bit percent accuracy](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m03s)
00:37:03

[I'm now going to turn it into a neural](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m08s)
00:37:08

[network with one hidden layer all right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m12s)
00:37:12

[and the way I'm going to do that is I'm](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m15s)
00:37:15

[going to create my more layer I'm going](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m16s)
00:37:16

[to change this so it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m21s)
00:37:21

[spits out a hundred rather than ten](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m22s)
00:37:22

[which means this one input is going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m24s)
00:37:24

[be a hundred](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m27s)
00:37:27

[rather than ten now this as it is can't](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m28s)
00:37:28

[possibly make things any better at all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m32s)
00:37:32

[yet why is this definitely not going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m34s)
00:37:34

[be better than what I had before](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m37s)
00:37:37

[yeah can somebody pass the yeah bishop](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m39s)
00:37:39

[your combination of two linear layers](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m45s)
00:37:45

[which is just the same as exactly right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m46s)
00:37:46

[so we've got two linear layers which is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m50s)
00:37:50

[just a linear layer right so to make](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m52s)
00:37:52

[things interesting I'm going to replace](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m54s)
00:37:54

[all of the negatives from the first](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m57s)
00:37:57

[layer with zeros because that's a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h37m59s)
00:37:59

[nonlinear transformation and so that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m02s)
00:38:02

[nonlinear transformation is called a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m05s)
00:38:05

[rectified linear unit okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m06s)
00:38:06

[so n n dot sequential simply is going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m11s)
00:38:11

[call each of these layers in turn for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m13s)
00:38:13

[each mini batch right so dual linear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m15s)
00:38:15

[layer replace all of the negatives with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m18s)
00:38:18

[zero do another linear layer and do it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m20s)
00:38:20

[softbank's this is now a neural network](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m22s)
00:38:22

[with one hidden layer and so let's try](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m25s)
00:38:25

[trading that instead yeah accuracies now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m29s)
00:38:29

[been up to 96% okay so the this is the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m36s)
00:38:36

[idea is that the basic techniques we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m40s)
00:38:40

[learning in this lesson like become](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m42s)
00:38:42

[powerful at the point where you start](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m45s)
00:38:45

[stacking them together okay can somebody](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m47s)
00:38:47

[pass the green box there and then yes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m50s)
00:38:50

[Daniel](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m53s)
00:38:53

[no reason it was like easier to type an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m56s)
00:38:56

[extra zero like this question of like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h38m59s)
00:38:59

[how many activations should I have a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m03s)
00:39:03

[neural network layer is kind of part of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m05s)
00:39:05

[the the scale of a deep learning](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m07s)
00:39:07

[practitioner we covered in the deep](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m09s)
00:39:09

[learning course and not in this class](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m11s)
00:39:11

[when adding that additional I guess](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m15s)
00:39:15

[transformation additional layer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m18s)
00:39:18

[additional this one here is called a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m21s)
00:39:21

[nonlinear layer or an activation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m23s)
00:39:23

[activation function direct activation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m27s)
00:39:27

[function does it matter that like if you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m30s)
00:39:30

[would have done for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m35s)
00:39:35

[like to soft Max's or is that something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m36s)
00:39:36

[you cannot do like yo you can absolutely](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m38s)
00:39:38

[use the softmax there but it it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m40s)
00:39:40

[probably not gonna give you what you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m42s)
00:39:42

[want and the reason why is that a soft](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m44s)
00:39:44

[max tends to push most of its](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m47s)
00:39:47

[activations to zero](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m49s)
00:39:49

[and an activation just be clear like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m51s)
00:39:51

[I've had a lot of questions in deep](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m54s)
00:39:54

[learning course about like what's an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m55s)
00:39:55

[activation an activation is the value](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m56s)
00:39:56

[that is calculated in a layer right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h39m59s)
00:39:59

[this is an activation right it's not a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m03s)
00:40:03

[weight a weight is not an activation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m06s)
00:40:06

[it's the value that you calculate from a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m08s)
00:40:08

[layer so soft max will tend to make most](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m11s)
00:40:11

[of its activations pretty close to zero](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m13s)
00:40:13

[and that's the opposite of what you want](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m15s)
00:40:15

[you generally want your activations to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m17s)
00:40:17

[be kind of as rich and diverse and and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m20s)
00:40:20

[used as possible so nothing to stop you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m22s)
00:40:22

[doing it but it probably won't work very](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m25s)
00:40:25

[well basically pretty much all of your](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m27s)
00:40:27

[layers will be followed by non by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m32s)
00:40:32

[nonlinear activation functions that will](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m36s)
00:40:36

[nearly always be value except for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m38s)
00:40:38

[last layer it's going to or three layers](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m41s)
00:40:41

[deep do you want to switch up these](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m51s)
00:40:51

[activation layers that's a great](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m54s)
00:40:54

[question so if I wanted to go deeper I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m57s)
00:40:57

[would just do that okay that's an outer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h40m59s)
00:40:59

[hidden layer Network so I think I'd](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m04s)
00:41:04

[heard you said that there are a couple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m10s)
00:41:10

[of different activation functions like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m12s)
00:41:12

[that rectified linear units what are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m15s)
00:41:15

[some examples and why would you use each](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m18s)
00:41:18

[yeah great question so basically like as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m22s)
00:41:22

[you add like more linear layers you kind](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m28s)
00:41:28

[of got your input comes in and you put](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m33s)
00:41:33

[it through a linear layer and then a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m36s)
00:41:36

[nonlinear layer linear layer nonlinear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m38s)
00:41:38

[layer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m41s)
00:41:41

[learning a linear layer and then the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m44s)
00:41:44

[final nonlinear layer the final](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m49s)
00:41:49

[nonlinear layer as we've discussed you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m53s)
00:41:53

[know if it's a multi category](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m55s)
00:41:55

[classification but you only ever pick](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h41m58s)
00:41:58

[one of them you would use softmax if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m01s)
00:42:01

[it's a binary classification or a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m05s)
00:42:05

[multi-label classification where you're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m07s)
00:42:07

[predicting multiple things you would use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m09s)
00:42:09

[sigmoid if it's a regression you would](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m11s)
00:42:11

[often have nothing at all right although](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m16s)
00:42:16

[we learnt in last night's DL course](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m19s)
00:42:19

[where sometimes you can use sigmoid](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m21s)
00:42:21

[there as well so they're basically the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m22s)
00:42:22

[options main options for the final layer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m25s)
00:42:25

[for the hidden layers you pretty much](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m29s)
00:42:29

[always use value right but there is a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m34s)
00:42:34

[another another one you can pick which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m49s)
00:42:49

[is kind of interesting which is called](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h42m54s)
00:42:54

[leaky value and it looks like this and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m01s)
00:43:01

[basically if it's above zero it's y](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m06s)
00:43:06

[equals x and if it's below zero it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m09s)
00:43:09

[like y equals 0.1 X okay so that's very](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m11s)
00:43:11

[similar to value but it's you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m15s)
00:43:15

[rather than being equal to 0 under X](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m18s)
00:43:18

[it's it's like something close to that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m20s)
00:43:20

[so they're the main to rally and lake](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m22s)
00:43:22

[here Lu there are various others but](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m27s)
00:43:27

[they're kind of like things that just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m35s)
00:43:35

[look very close to that so for example](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m37s)
00:43:37

[there's something called Lu which is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m39s)
00:43:39

[quite popular but like you know the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m41s)
00:43:41

[details don't matter too much](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m43s)
00:43:43

[honestly like that they're like aou is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m44s)
00:43:44

[something that looks like this but it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m46s)
00:43:46

[slightly more curvy in the middle and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m48s)
00:43:48

[it's kind of like it's not generally](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m52s)
00:43:52

[something that you so much pick based on](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m54s)
00:43:54

[the data set it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m56s)
00:43:56

[more like over time we just find better](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h43m57s)
00:43:57

[activation functions so two or three](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m01s)
00:44:01

[years ago everybody is value you know a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m03s)
00:44:03

[year ago pretty much everybody used Lake](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m06s)
00:44:06

[Erie Lu today I guess probably most](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m08s)
00:44:08

[people are starting to move towards ALU](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m10s)
00:44:10

[but honestly that the choice of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m11s)
00:44:11

[activation function doesn't matter](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m14s)
00:44:14

[terribly much actually and you know](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m15s)
00:44:15

[people have actually showed that you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m20s)
00:44:20

[use like a pretty arbitrary nonlinear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m22s)
00:44:22

[activation functions like even a sine](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m24s)
00:44:24

[wave and it still works okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m25s)
00:44:25

[so although what we're going to do today](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m36s)
00:44:36

[is showing how to create this network](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m38s)
00:44:38

[with no hidden layers to turn it into](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m44s)
00:44:44

[that Network which is 96% ish accurate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m48s)
00:44:48

[is it will be trivial right and in fact](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m53s)
00:44:53

[it's something you should probably try](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m56s)
00:44:56

[and do during the week right is to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h44m58s)
00:44:58

[create that version](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m01s)
00:45:01

[okay so now that we've got something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m08s)
00:45:08

[where we can take our network parsing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m12s)
00:45:12

[our variable and get back some](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m15s)
00:45:15

[predictions that's basically all that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m19s)
00:45:19

[happened when we called fish so we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m23s)
00:45:23

[going to see how how that that approach](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m25s)
00:45:25

[can be used to create this to cast a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m28s)
00:45:28

[gradient descent one thing to note is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m30s)
00:45:30

[that the to turn the predicted](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m33s)
00:45:33

[probabilities into a predicted like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m36s)
00:45:36

[which digit is it we would need to use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m39s)
00:45:39

[AG max unfortunately pi torch doesn't](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m42s)
00:45:42

[call it ad max instead pi torch just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m47s)
00:45:47

[calls it max and max returns two things](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m50s)
00:45:50

[it returns the actual max across this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m56s)
00:45:56

[axis so this is across the columns right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h45m59s)
00:45:59

[and the second thing it returns is the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m02s)
00:46:02

[index of that maximum right so so the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m04s)
00:46:04

[equivalent of arc max is to call max and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m08s)
00:46:08

[then get the first indexed thing okay so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m11s)
00:46:11

[there's our predictions right if this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m14s)
00:46:14

[was in numpy we would instead use MP dot](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m16s)
00:46:16

[admits okay all right so here are the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m18s)
00:46:18

[predictions from our hand created](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m26s)
00:46:26

[logistic regression and in this case](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m29s)
00:46:29

[looks like we've got all but one correct](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m32s)
00:46:32

[so the next thing we're going to try and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m36s)
00:46:36

[get rid of in terms of using libraries](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m39s)
00:46:39

[is for try to avoid using the matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m41s)
00:46:41

[multiplication operator and instead](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m43s)
00:46:43

[we're going to try and write that by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m46s)
00:46:46

[hand](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m47s)
00:46:47

[so this next part we're going to learn](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h46m58s)
00:46:58

[about something which kind of seems it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m02s)
00:47:02

[kind of it's gonna seem like a a minor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m08s)
00:47:08

[little kind of programming idea but](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m10s)
00:47:10

[actually it's going to turn out that at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m13s)
00:47:13

[least in my opinion it's the most](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m16s)
00:47:16

[important programming concept that will](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m17s)
00:47:17

[teach in this course and it's possibly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m20s)
00:47:20

[the most important programming kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m22s)
00:47:22

[concept in all of all the things you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m25s)
00:47:25

[need to build machine learning](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m28s)
00:47:28

[algorithms and it's the idea of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m30s)
00:47:30

[broadcasting and the idea I will show by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m32s)
00:47:32

[example if we create an array of 10 6](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m36s)
00:47:36

[NIC 4 and an array of 2 8 7 and then add](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m41s)
00:47:41

[the two together it adds each of the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m44s)
00:47:44

[components of those two arrays in turn](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m50s)
00:47:50

[we call that element wise so in other](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m52s)
00:47:52

[words we didn't have to write a loop](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m55s)
00:47:55

[right back in the old days we would have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m57s)
00:47:57

[to have looped through each one and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h47m59s)
00:47:59

[added them and then concatenate them](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m00s)
00:48:00

[together we don't have to do that today](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m02s)
00:48:02

[it happens for us automatically](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m04s)
00:48:04

[so in lump a we automatically get](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m06s)
00:48:06

[element wise operations we can do the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m10s)
00:48:10

[same thing with PI torch so in first day](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m18s)
00:48:18

[I would just add a little capital T to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m24s)
00:48:24

[turn something into a pipe watch tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m25s)
00:48:25

[all right and if we add those together](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m27s)
00:48:27

[exactly the same thing all right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m30s)
00:48:30

[element wise operations are pretty](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m33s)
00:48:33

[standard in these kinds of libraries](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m34s)
00:48:34

[it's interesting not just because we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m39s)
00:48:39

[don't have to write the for loop right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m43s)
00:48:43

[but it's actually much more interesting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m45s)
00:48:45

[because of the performance things that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m47s)
00:48:47

[are happening here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m48s)
00:48:48

[the first is if we were doing a for loop](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m49s)
00:48:49

[right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m52s)
00:48:52

[if we were doing a four loop that would](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h48m58s)
00:48:58

[happen in Python right even when you use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m01s)
00:49:01

[play torch it still does the for loop in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m05s)
00:49:05

[Python it has no way of like optimizing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m07s)
00:49:07

[a for loop and so a for loop in Python](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m11s)
00:49:11

[is something like 10,000 times slower](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m14s)
00:49:14

[than in C so that's your first problem](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m17s)
00:49:17

[like I remember is like 1,000 or 10,000](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m21s)
00:49:21

[the second problem then is that you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m24s)
00:49:24

[don't just want it to be optimized in C](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m29s)
00:49:29

[but you want C to take advantage of the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m31s)
00:49:31

[thing that your all of your CPUs do to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m33s)
00:49:33

[something called Cindy single](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m36s)
00:49:36

[instruction multiple data which is yours](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m38s)
00:49:38

[your CPU is capable of taking eight](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m41s)
00:49:41

[things at a time right in a vector and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m44s)
00:49:44

[adding them up to another vector with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m47s)
00:49:47

[eight things in in a single CPU](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m51s)
00:49:51

[instruction right so if you can take](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m53s)
00:49:53

[advantage of Sim D you're immediately](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m56s)
00:49:56

[eight times faster it depends on how big](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h49m58s)
00:49:58

[the data type is it might be four might](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m00s)
00:50:00

[be eight the other thing that you've got](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m02s)
00:50:02

[in your computer is you've got multiple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m04s)
00:50:04

[processes multiple cores so you've](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m06s)
00:50:06

[probably got like if this is inside](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m12s)
00:50:12

[happening on one side one core](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m14s)
00:50:14

[you've probably got about four of those](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m16s)
00:50:16

[okay so if you're using Cindy your eight](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m18s)
00:50:18

[times faster if you can use multiple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m21s)
00:50:21

[cores than your 32 times faster and then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m23s)
00:50:23

[if you're doing that in C you might be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m26s)
00:50:26

[something like 32 times per thousand](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m28s)
00:50:28

[times faster right and so the nice thing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m30s)
00:50:30

[is that when we do that it's taking](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m33s)
00:50:33

[advantage of all of these things okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m36s)
00:50:36

[better still if you do it in PI torch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m39s)
00:50:39

[and your data was created with CUDA to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m45s)
00:50:45

[stick it on the GPU then your GPU can do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m51s)
00:50:51

[about 10,000 things at a time all right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m56s)
00:50:56

[so that'll be another hundred times](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h50m58s)
00:50:58

[faster than C all right so this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m00s)
00:51:00

[critical to getting good performance is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m03s)
00:51:03

[you have to learn how to write](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m07s)
00:51:07

[Lewis code by taking advantage of these](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m10s)
00:51:10

[element-wise operations and like it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m14s)
00:51:14

[not it's a lot more than just plus I can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m17s)
00:51:17

[also use less then right and that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m21s)
00:51:21

[going to return 0 1 1 or if we go back](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m24s)
00:51:24

[to numpy false true true and so you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m28s)
00:51:28

[kind of use this to do all kinds of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m38s)
00:51:38

[things without looping so for example I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m40s)
00:51:40

[could now multiply that by a and here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m42s)
00:51:42

[are all of the values of a as long as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m45s)
00:51:45

[they're less than B or we could take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m49s)
00:51:49

[mean this is the percentage of values in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m53s)
00:51:53

[AE that are less than B all right so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h51m58s)
00:51:58

[like there's a lot of stuff you can do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m01s)
00:52:01

[with this simple idea but to take it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m02s)
00:52:02

[further](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m05s)
00:52:05

[right to take it further than just this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m06s)
00:52:06

[element wise operation we're going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m08s)
00:52:08

[have to go the next step to something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m10s)
00:52:10

[called broadcasting so let's take a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m12s)
00:52:12

[five-minute break come back at 2:17 and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m14s)
00:52:14

[we'll talk about broadcasting so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m17s)
00:52:17

[broadcasting this is the definition from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m27s)
00:52:27

[the numpy documentation of broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m35s)
00:52:35

[and I'm going to come back to it in a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m38s)
00:52:38

[moment rather than reading it now but](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m40s)
00:52:40

[let's start by looking an example of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m43s)
00:52:43

[broadcasting so a is a array with one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m46s)
00:52:46

[dimension also known as a Rank 1 tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m54s)
00:52:54

[also known as a vector we can say a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h52m57s)
00:52:57

[greater than 0 so here we have a Rank 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m02s)
00:53:02

[tensor right and a rank 0 tensor right a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m09s)
00:53:09

[rank 0 tensor is also called a scalar](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m17s)
00:53:17

[the rank 1 tensor is also called a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m20s)
00:53:20

[vector](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m23s)
00:53:23

[and we've got an operation between the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m24s)
00:53:24

[two all right now you've probably done](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m27s)
00:53:27

[it a thousand times without even](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m30s)
00:53:30

[noticing that's kind of weird right that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m31s)
00:53:31

[you've got these things of different](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m34s)
00:53:34

[ranks and different sizes so what is it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m35s)
00:53:35

[actually doing right but what it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m38s)
00:53:38

[actually doing is it's taking that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m40s)
00:53:40

[scaler and copying it here-here-here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m42s)
00:53:42

[right and then it's actually going](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m46s)
00:53:46

[element-wise tan is greater than zero](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m49s)
00:53:49

[six is greater than zero minus pore is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m54s)
00:53:54

[greater than zero you have been giving](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m57s)
00:53:57

[us back the three answers right and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h53m59s)
00:53:59

[that's called broadcasting broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m02s)
00:54:02

[means copying one or more axes of my](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m04s)
00:54:04

[tensor to allow it to be the same shape](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m10s)
00:54:10

[as the other tensor it doesn't really](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m14s)
00:54:14

[copy it though what it actually does is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m19s)
00:54:19

[it stores this kind of internal](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m23s)
00:54:23

[indicator that says pretend that this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m26s)
00:54:26

[a vector of three zeros but it actually](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m29s)
00:54:29

[just like rather than kind of going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m33s)
00:54:33

[the next row we're going to the next](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m36s)
00:54:36

[scaler it goes back to where it came](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m37s)
00:54:37

[from if you're interested in learning](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m39s)
00:54:39

[about this specifically it's they set](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m41s)
00:54:41

[the stride on that axis to be zero](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m43s)
00:54:43

[that's a minor advanced concept for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m46s)
00:54:46

[those who procures so we could do a plus](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m49s)
00:54:49

[one right it's going to broadcast the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m55s)
00:54:55

[scalar 1 to be 1 1 1 and then do element](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h54m58s)
00:54:58

[wise addition if we could do the same](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m02s)
00:55:02

[with a matrix right here's our matrix 2](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m04s)
00:55:04

[times the matrix is going to broadcast](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m07s)
00:55:07

[to to be to to to to to to to to to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m09s)
00:55:09

[and then do element wise multiplication](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m13s)
00:55:13

[right so that's our kind of most simple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m18s)
00:55:18

[version of broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m21s)
00:55:21

[so here's a slightly more complex](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m27s)
00:55:27

[version of broadcasting here's an array](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m29s)
00:55:29

[called C right so this is a rank one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m32s)
00:55:32

[tensor and here's our matrix M from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m35s)
00:55:35

[before rank two tensor we can add M plus](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m38s)
00:55:38

[C alright so what's going on here one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m43s)
00:55:43

[two three four five six seven eight nine](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m50s)
00:55:50

[that's M all right and then C 10 20 30](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h55m56s)
00:55:56

[you can see that what it's done is to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m06s)
00:56:06

[add that to each row right 11 22 33 14](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m09s)
00:56:09

[25 36 and so we can kind of figure it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m15s)
00:56:15

[seems to have done the same kind of idea](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m19s)
00:56:19

[is broadcasting a scaler it's like made](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m21s)
00:56:21

[copies of it and then it treats those](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m23s)
00:56:23

[as if it's a rank two matrix and now we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m37s)
00:56:37

[can do element wise addition that make](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m39s)
00:56:39

[sense right now that's yes can can you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m43s)
00:56:43

[pass that Devin over there thank you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m46s)
00:56:46

[so it's like by looking at this example](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m49s)
00:56:49

[it like copies it done making new rows](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m53s)
00:56:53

[so how would we want to do it if we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h56m57s)
00:56:57

[wanted to get new columns I'm so glad](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m00s)
00:57:00

[you asked so instead we would do this 10](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m02s)
00:57:02

[20 30 all right and then copy that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m18s)
00:57:18

[10 20 30 10 20 30 and now treat that as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m22s)
00:57:22

[our matrix so to get numpy to do that we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m30s)
00:57:30

[need to not pass in a vector but to pass](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m34s)
00:57:34

[in a matrix with one column a rank two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m39s)
00:57:39

[tensor right so basically it turns out](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m45s)
00:57:45

[that numpy is going to think of a rank 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m50s)
00:57:50

[tensor for these purposes as if it was a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m55s)
00:57:55

[rank two tensor which represents a row](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h57m58s)
00:57:58

[right so in other words that it is 1 by](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m01s)
00:58:01

[3 all right so we want to create a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m04s)
00:58:04

[tensor which is 3 by 1 there's a couple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m07s)
00:58:07

[of ways to do that one is to use NP](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m12s)
00:58:12

[expand imps and if you then pass in this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m16s)
00:58:16

[argument it says please insert a length](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m20s)
00:58:20

[1 axis here please so in our case we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m23s)
00:58:23

[want to turn it into a 3 by 1 so if we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m27s)
00:58:27

[said expanding c comma 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m31s)
00:58:31

[okay so if we say expanding C comma one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m38s)
00:58:38

[it changes the shape to three comma one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m42s)
00:58:42

[so if we look at what that looks like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m44s)
00:58:44

[that looks like a column okay so if we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m47s)
00:58:47

[now go that plus M you can see it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m51s)
00:58:51

[doing exactly what we hoped it would do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h58m56s)
00:58:56

[alright which is to add ten twenty](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m00s)
00:59:00

[thirty to the column ten twenty thirty](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m02s)
00:59:02

[to the column ten twenty thirty to the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m05s)
00:59:05

[column okay now because the location of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m08s)
00:59:08

[a unit axis turns out to be so important](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m12s)
00:59:12

[it's really helpful to kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m20s)
00:59:20

[experiment with creating these extra](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m22s)
00:59:22

[unit axes and know how to do it easily](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m25s)
00:59:25

[and MP dot expand ins isn't in my](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m27s)
00:59:27

[opinion the easiest way to do this the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m31s)
00:59:31

[easiest way the easiest way is to index](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m32s)
00:59:32

[into the tensor with a special index](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m37s)
00:59:37

[none and what none does is it creates a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m41s)
00:59:41

[new axis in that location of length one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m45s)
00:59:45

[right so this is going to add a new axis](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m50s)
00:59:50

[at the start of length one this is going](https://www.youtube.com/watch?v=PGC0UxakTvM#t=00h59m56s)
00:59:56

[to add a new axis at the end at length](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m03s)
01:00:03

[one or why not they're both right so if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m06s)
01:00:06

[you think about it like a tensor which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m13s)
01:00:13

[has like three things in it could be of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m16s)
01:00:16

[any rank you like right you can just add](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m20s)
01:00:20

[you know taxis all over the place and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m22s)
01:00:22

[that way we can kind of decide how we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m26s)
01:00:26

[want our broadcasting to work so there's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m29s)
01:00:29

[a pretty convenient thing in numpy](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m34s)
01:00:34

[called broadcast - and what that does is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m39s)
01:00:39

[it takes our vector and broadcasts it to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m42s)
01:00:42

[that shape and shows us what that would](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m45s)
01:00:45

[look like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m48s)
01:00:48

[right so if you ever like unsure of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m49s)
01:00:49

[what's going on in some broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m52s)
01:00:52

[operation you can save broadcast too and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m54s)
01:00:54

[so for example here we could say like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m57s)
01:00:57

[rather than three comma three we could](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h00m59s)
01:00:59

[say MJ right and see exactly what's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m00s)
01:01:00

[happening gonna happen and so that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m04s)
01:01:04

[what's gonna happen before we add it to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m06s)
01:01:06

[em right so if we said turn it into a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m08s)
01:01:08

[column that's what that looks like makes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m15s)
01:01:15

[sense so that's kind of like the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m22s)
01:01:22

[intuitive definition of broadcasting and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m25s)
01:01:25

[so now hopefully we can go back to that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m30s)
01:01:30

[numpy documentation and understand what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m32s)
01:01:32

[it means right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m36s)
01:01:36

[broadcasting describes how numpy is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m37s)
01:01:37

[going to treat arrays of different](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m39s)
01:01:39

[shapes when we do some operation right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m41s)
01:01:41

[the smaller array is broadcast across](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m43s)
01:01:43

[the larger array by smaller array they](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m46s)
01:01:46

[mean lower rank tensor basically our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m49s)
01:01:49

[broadcast across the light the higher](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m52s)
01:01:52

[rank tensor so they have compatible](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m54s)
01:01:54

[shapes it vector eise's array operation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m56s)
01:01:56

[so vectorizing generally means like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h01m59s)
01:01:59

[using sim D and stuff like that so that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m01s)
01:02:01

[multiple things happen at the same time](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m04s)
01:02:04

[all the looping occurs in C but it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m06s)
01:02:06

[doesn't actually make needless copies of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m09s)
01:02:09

[theta](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m11s)
01:02:11

[it kind of just acts as if it had okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m12s)
01:02:12

[so there's our definition now in deep](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m15s)
01:02:15

[learning you very often deal with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m19s)
01:02:19

[tensors of rank four or more and you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m21s)
01:02:21

[very often combine them with tensors of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m25s)
01:02:25

[rank one or two and trying to just rely](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m27s)
01:02:27

[on intuition to do that correctly as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m31s)
01:02:31

[nearly impossible so you really need to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m33s)
01:02:33

[know the rules so here are the rules](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m35s)
01:02:35

[okay here's my shop here's C dot shape](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m45s)
01:02:45

[so the rule are that we're going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m48s)
01:02:48

[compare the shapes of our two tensors](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m49s)
01:02:49

[element-wise we're going to look at one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m52s)
01:02:52

[at a time and we're going to start at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m54s)
01:02:54

[the end all right so look at the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m56s)
01:02:56

[trailing dimensions and then go towards](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h02m58s)
01:02:58

[the front](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m01s)
01:03:01

[okay and so two dimensions are going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m02s)
01:03:02

[be compatible when one of these two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m05s)
01:03:05

[things is true right so let's check](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m08s)
01:03:08

[right we've got our our M&amp;C compatible m](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m10s)
01:03:10

[is 3 3 c is 3 right so we're going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m14s)
01:03:14

[start at the end trailing dimensions](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m20s)
01:03:20

[first and check are they compatible](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m22s)
01:03:22

[they're compatible if the dimensions are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m23s)
01:03:23

[equal okay so these ones are equal so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m26s)
01:03:26

[they are compatible right all right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m28s)
01:03:28

[let's go to the next one uh-oh we're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m31s)
01:03:31

[missing all right C is missing something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m33s)
01:03:33

[so what happens if something is missing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m37s)
01:03:37

[as we insert a 1 okay that's the rule](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m39s)
01:03:39

[all right and so let's now check are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m43s)
01:03:43

[these compatible one of them is one yes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m45s)
01:03:45

[they're compatible okay so now you can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m48s)
01:03:48

[see why it is that numpy treats the one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m52s)
01:03:52

[dimensional array as if it is a rank two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h03m56s)
01:03:56

[tensor which is representing a row it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m01s)
01:04:01

[because we're basically inserting a one](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m04s)
01:04:04

[at the front okay so that's the rule so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m07s)
01:04:07

[for example this is something that you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m11s)
01:04:11

[very commonly have to do which is you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m17s)
01:04:17

[start with like an image there like 256](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m19s)
01:04:19

[pixels by 256 pixels by 3 channels and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m24s)
01:04:24

[you want to subtract the mean of each](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m27s)
01:04:27

[channel right so you've got 256 by 256](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m31s)
01:04:31

[by 3 and you want to subtract something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m34s)
01:04:34

[of length 3 right so yeah you can do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m36s)
01:04:36

[that absolutely because 3 &amp; 3 are](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m39s)
01:04:39

[compatible because they're the same](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m42s)
01:04:42

[right 256 and empty is compatible it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m44s)
01:04:44

[going to insert a 1 256 and empty is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m47s)
01:04:47

[compatible it's going to insert of 1](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m50s)
01:04:50

[okay so you're going to end up with this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m52s)
01:04:52

[is going to be broadcast over all of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m56s)
01:04:56

[this access and then that whole thing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h04m59s)
01:04:59

[will be broadcast over this access and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m01s)
01:05:01

[so we'll end up with a 256 by 256 by 3](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m03s)
01:05:03

[effective tensor here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m09s)
01:05:09

[right so interestingly like very few](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m13s)
01:05:13

[people in the data science or machine](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m18s)
01:05:18

[learning communities understand](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m21s)
01:05:21

[broadcasting and the vast majority of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m22s)
01:05:22

[the time for example when I see people](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m25s)
01:05:25

[doing pre-processing for computer vision](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m26s)
01:05:26

[like subtracting the mean they always](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m28s)
01:05:28

[write loose over the channels right and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m31s)
01:05:31

[I kind of think like it's it it's like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m35s)
01:05:35

[so handy to not have to do that and it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m38s)
01:05:38

[often so much faster to not have to do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m41s)
01:05:41

[that so if you get good at broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m44s)
01:05:44

[you'll have this like super useful skill](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m46s)
01:05:46

[that very very few people have and and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m49s)
01:05:49

[like it's it's it's an ancient skill you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m52s)
01:05:52

[know it goes it goes all the way back to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m55s)
01:05:55

[the days of APL so APL was from the late](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h05m58s)
01:05:58

[50s stands for a programming language](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m03s)
01:06:03

[and Kenneth Iverson wrote this paper](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m07s)
01:06:07

[called notation as a tool for thought in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m12s)
01:06:12

[which he proposed a new math notation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m17s)
01:06:17

[and he proposed that if we use this new](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m19s)
01:06:19

[math notation it gives us new tools for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m23s)
01:06:23

[thought and allows us to think things we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m26s)
01:06:26

[couldn't before and one of his ideas was](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m29s)
01:06:29

[broadcasting not as a computer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m33s)
01:06:33

[programming tool but as a piece of math](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m36s)
01:06:36

[notation and so he ended up implementing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m39s)
01:06:39

[this notation as a tool for thought as a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m43s)
01:06:43

[programming language called APL and his](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m45s)
01:06:45

[son has gone on to further develop that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m49s)
01:06:49

[into a piece of software called J which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m54s)
01:06:54

[is basically what you get when you put](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h06m58s)
01:06:58

[sixty years of very smart people working](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m00s)
01:07:00

[on this idea and with this programming](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m03s)
01:07:03

[language you can express very complex](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m06s)
01:07:06

[mathematical ideas often just where the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m09s)
01:07:09

[line of code or two and so I mean it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m11s)
01:07:11

[great that we have J but it's even](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m16s)
01:07:16

[greater that these ideas have found](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m17s)
01:07:17

[their ways into the languages we all use](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m19s)
01:07:19

[like in Python the numpy and pi torch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m21s)
01:07:21

[libraries all right these are not just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m24s)
01:07:24

[little](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m26s)
01:07:26

[kind of niche ideas is like fundamental](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m27s)
01:07:27

[ways to think about math and to do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m30s)
01:07:30

[programming let me give an example of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m32s)
01:07:32

[like this kind of notation as a tool for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m35s)
01:07:35

[thought let's let's look here we've got](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m37s)
01:07:37

[C right here we've got C none right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m44s)
01:07:44

[notice this is now up to square brackets](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m50s)
01:07:50

[right so this is kind of like a one row](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m52s)
01:07:52

[vector tensor here it is a little column](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h07m56s)
01:07:56

[so what is round ones okay what's that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m06s)
01:08:06

[gonna do ever think about it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m23s)
01:08:23

[anybody want to have a go can't even](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m34s)
01:08:34

[talk through your thinking okay can we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m36s)
01:08:36

[pass the check over there thank you yes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m38s)
01:08:38

[absolutely so take us through your](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m44s)
01:08:44

[thinking how's that going to work so the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m46s)
01:08:46

[diagonally lumens can be directly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m51s)
01:08:51

[visualized from the squares then cross](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m53s)
01:08:53

[1020 clothes 20 and 30 plus 30 and if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h08m57s)
01:08:57

[you multiply the first row for this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m01s)
01:09:01

[column you get the first row of the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m04s)
01:09:04

[matrix mm-hmm so finally we will get our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m07s)
01:09:07

[3 cross 3 matrix yeah and so to think of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m10s)
01:09:10

[this in terms of like those broadcasting](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m14s)
01:09:14

[rules we're basically taking this column](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m15s)
01:09:15

[right which is a rank 3 comma 1 right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m20s)
01:09:20

[and this kind of roll sorry have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m25s)
01:09:25

[dimension 3 comma 1 and this row which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m29s)
01:09:29

[is of dimension 1 comma 3 right and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m31s)
01:09:31

[to make these compatible with our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m36s)
01:09:36

[broadcasting rules right this one here](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m38s)
01:09:38

[has to be duplicated 3 times because it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m41s)
01:09:41

[needs to match this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m44s)
01:09:44

[okay and now this one's going to have to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m53s)
01:09:53

[be duplicated three times to match this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h09m55s)
01:09:55

[okay and so now I've got two matrices to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m02s)
01:10:02

[do an element-wise product of and so as](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m08s)
01:10:08

[you say there is that outer product](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m11s)
01:10:11

[right now the interesting thing here is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m15s)
01:10:15

[that suddenly now that this is not a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m17s)
01:10:17

[special mathematical case but just a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m20s)
01:10:20

[specific version of the general idea of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m24s)
01:10:24

[broadcasting we can do like and out a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m27s)
01:10:27

[plus or we can do an order greater than](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m30s)
01:10:30

[right or whatever right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m35s)
01:10:35

[so it's suddenly we've kind of got this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m38s)
01:10:38

[this this concept that we can use to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m40s)
01:10:40

[build new ideas and then we can start to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m44s)
01:10:44

[experiment with those new ideas and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m47s)
01:10:47

[you know interestingly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m49s)
01:10:49

[numpy actually uses this sometimes for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h10m51s)
01:10:51

[example if you want to create a grid](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m00s)
01:11:00

[this is how numpy does it all right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m05s)
01:11:05

[actually this is kind of the sorry let](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m08s)
01:11:08

[me show you this way if you want to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m11s)
01:11:11

[create a grid this is how numpy does it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m13s)
01:11:13

[it actually returns zero one two three](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m15s)
01:11:15

[four and zero one two three four one is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m18s)
01:11:18

[a column one is a row so we could say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m24s)
01:11:24

[like okay that's X grid comma Y grid and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m27s)
01:11:27

[now you could do something like row I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m33s)
01:11:33

[mean we could obviously go](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m41s)
01:11:41

[like that right and so suddenly we've](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m45s)
01:11:45

[expanded that out into a grid right and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m48s)
01:11:48

[so yeah it's kind of interesting how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h11m58s)
01:11:58

[like some of these like simple little](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m01s)
01:12:01

[concepts kind of get built on and built](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m04s)
01:12:04

[on and built on so if you lose something](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m07s)
01:12:07

[like APL or J it's this whole](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m09s)
01:12:09

[environment of layers and layers and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m12s)
01:12:12

[layers of this we don't have such a deep](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m15s)
01:12:15

[environment in numpy but you know you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m17s)
01:12:17

[can certainly see these ideas of like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m19s)
01:12:19

[broadcasting coming through in in simple](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m21s)
01:12:21

[things like how do we create a grid in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m24s)
01:12:24

[non-pay so yeah so that's that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m26s)
01:12:26

[broadcasting and so what we can do with](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m31s)
01:12:31

[this now is use this to implement matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m34s)
01:12:34

[multiplication ourselves ok now why](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m39s)
01:12:39

[would we want to do that well obviously](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m44s)
01:12:44

[we don't write matrix multiplication has](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m46s)
01:12:46

[already been handled perfectly nicely](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m49s)
01:12:49

[for us by our libraries but very often](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m52s)
01:12:52

[you'll find in all kinds of areas in in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h12m56s)
01:12:56

[machine learning and particularly in](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m01s)
01:13:01

[deep learning that there'll be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m03s)
01:13:03

[particular types of linear function that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m05s)
01:13:05

[you want to do that aren't quite done](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m10s)
01:13:10

[for you right so for example there's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m13s)
01:13:13

[like whole areas called like tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m16s)
01:13:16

[regression and tensor decomposition](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m21s)
01:13:21

[which are really being developed a lot](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m31s)
01:13:31

[at the moment and they're kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m34s)
01:13:34

[talking about like how do we take like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m35s)
01:13:35

[higher rank tensors and kind of turn](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m37s)
01:13:37

[them into combinations of rows columns](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m41s)
01:13:41

[and faces and it turns out that when you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m44s)
01:13:44

[can kind of do this you can basically](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m47s)
01:13:47

[like deal with really high dimensional](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m49s)
01:13:49

[data structures with not much memory and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m52s)
01:13:52

[not with not much computation time for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m53s)
01:13:53

[example there's a really terrific](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m56s)
01:13:56

[library called tensile e which does a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h13m57s)
01:13:57

[whole lot of this kind of stuff for you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m01s)
01:14:01

[so it's a really really important area](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m04s)
01:14:04

[it covers like all of deep learning lots](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m07s)
01:14:07

[of modern machine learning in general](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m10s)
01:14:10

[and so even though you're not going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m12s)
01:14:12

[like define matrix multiplication you're](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m15s)
01:14:15

[very likely to wanted to find some other](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m17s)
01:14:17

[slightly different tensor product you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m20s)
01:14:20

[know so it's really useful to kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m22s)
01:14:22

[understand how to do that so let's go](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m25s)
01:14:25

[back and look at our matrix and our our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m28s)
01:14:28

[2d array in 1d array rank two tensor](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m33s)
01:14:33

[rank 1 tensor and remember we can do a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m37s)
01:14:37

[matrix multiplication using the @ sign](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m39s)
01:14:39

[or the old way and PMML okay and so what](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m42s)
01:14:42

[that's actually doing when we do that is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m48s)
01:14:48

[we're basically saying ok 1 times 10](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m50s)
01:14:50

[plus 2 times 20 plus 3 times 30 is 140](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h14m55s)
01:14:55

[right and so we do that for each row and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m03s)
01:15:03

[we can go through and do the same thing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m07s)
01:15:07

[for the next one and for the next one to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m09s)
01:15:09

[get our result right you could do that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m11s)
01:15:11

[in torch as well we could make this a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m15s)
01:15:15

[little shorter](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m20s)
01:15:20

[okay same thing okay but that is not](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m31s)
01:15:31

[matrix multiplication what's that okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m42s)
01:15:42

[element wise specifically we've got a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m49s)
01:15:49

[matrix and a vector so broadcasting okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m52s)
01:15:52

[good so we've got this is element wise](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m56s)
01:15:56

[with broadcasting but notice the numbers](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h15m58s)
01:15:58

[it's created 10 40 90 are the exact](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m02s)
01:16:02

[three numbers that I needed to calculate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m05s)
01:16:05

[when I did that first piece of my matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m08s)
01:16:08

[multiplication so in other words if we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m11s)
01:16:11

[sum this over the columns which is axis](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m14s)
01:16:14

[equals 1 we get our matrix vector](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m20s)
01:16:20

[product okay so we can kind of do this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m24s)
01:16:24

[stuff without special help from our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m32s)
01:16:32

[library so now let's expand this out to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m34s)
01:16:34

[a matrix matrix product so a matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m40s)
01:16:40

[matrix product looks like this this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m44s)
01:16:44

[this great site called matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m49s)
01:16:49

[multiplication XYZ and it shows us this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m50s)
01:16:50

[is what happens when we multiply two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m55s)
01:16:55

[matrices okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h16m56s)
01:16:56

[that's what matrix multiplication is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m04s)
01:17:04

[operationally speaking so in other words](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m07s)
01:17:07

[what we just did there was we first of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m10s)
01:17:10

[all took the first column with the first](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m14s)
01:17:14

[row to get this one and then we took the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m18s)
01:17:18

[second column with the first row to get](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m23s)
01:17:23

[that one right so we're basically doing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m26s)
01:17:26

[the thing we just did the matrix vector](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m29s)
01:17:29

[product we're just doing it twice right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m32s)
01:17:32

[once with this column and once with this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m35s)
01:17:35

[column and then we concatenate the two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m42s)
01:17:42

[together okay so we can now go ahead and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m44s)
01:17:44

[do that like so M times the first column](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m49s)
01:17:49

[dot some M times the second column](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h17m56s)
01:17:56

[that's some and so there are the two](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m01s)
01:18:01

[columns of our matrix multiplication](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m03s)
01:18:03

[okay so I didn't want to like make our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m07s)
01:18:07

[code too messy so I'm not going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m11s)
01:18:11

[actually like use that but like we have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m14s)
01:18:14

[it there now if we want to we don't need](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m16s)
01:18:16

[to use torch or numpy matrix](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m19s)
01:18:19

[multiplication anymore we've got we've](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m22s)
01:18:22

[got our own that we can use using](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m24s)
01:18:24

[nothing but element wise operations](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m25s)
01:18:25

[Broadcasting and some okay so this is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m28s)
01:18:28

[our logistic regression from scratch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m39s)
01:18:39

[class again I just copied it here here's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m43s)
01:18:43

[where we instantiate the object copy to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m46s)
01:18:46

[the GPU we create an optimizer which](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m48s)
01:18:48

[we'll learn about in a moment and we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m50s)
01:18:50

[call fit okay so the goal is to now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m52s)
01:18:52

[repeat this without needing to call fit](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h18m55s)
01:18:55

[so to do that we're going to need a loop](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m01s)
01:19:01

[which grabs a mini batch of data at a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m09s)
01:19:09

[time and with each mini batch of data we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m12s)
01:19:12

[need to pass it to the optimizer and say](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m16s)
01:19:16

[please try to come up with a slightly](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m19s)
01:19:19

[better set of predictions for this mini](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m20s)
01:19:20

[batch right so as we learnt in order to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m23s)
01:19:23

[grab a mini batch of the training set at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m26s)
01:19:26

[a time we have to ask the model data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m28s)
01:19:28

[object for the training data loader we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m30s)
01:19:30

[have to wrap it an iterator to create an](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m33s)
01:19:33

[iterator or a generator and so that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m35s)
01:19:35

[gives us our our data loader](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m39s)
01:19:39

[okay so PI torch calls this a data](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m41s)
01:19:41

[loader we actually wrote our own class](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m43s)
01:19:43

[today as a loader but it's it's all it's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m45s)
01:19:45

[basically the same idea](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m47s)
01:19:47

[and so the next thing we do is we grab](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m49s)
01:19:49

[the X and the y tensor the next one from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m52s)
01:19:52

[our data loader okay wrap it in a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h19m58s)
01:19:58

[variable to say I need to be able to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m01s)
01:20:01

[take the derivative of the calculations](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m03s)
01:20:03

[using this because if I can't take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m06s)
01:20:06

[derivative then I can't get the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m08s)
01:20:08

[gradients and I can't update the weights](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m10s)
01:20:10

[all right and I need to put it on the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m11s)
01:20:11

[GPU because my module is on the GPU and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m14s)
01:20:14

[so we can now take that variable and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m19s)
01:20:19

[pass it to the objects that we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m22s)
01:20:22

[instantiated our logistic regression](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m26s)
01:20:26

[remember now module we can use it as if](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m28s)
01:20:28

[it's a function because that's how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m30s)
01:20:30

[high-touch works and that gives us a set](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m32s)
01:20:32

[of predictions as we saw on scene before](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m35s)
01:20:35

[okay so now we can check the loss and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m38s)
01:20:38

[the loss we're defined as being a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m44s)
01:20:44

[negative log likelihood loss object okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m46s)
01:20:46

[and we're going to learn about how](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m50s)
01:20:50

[that's calculated in the next lesson and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m51s)
01:20:51

[for now think of it just like a root](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m54s)
01:20:54

[mean squared error but for](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m55s)
01:20:55

[classification problems so we can call](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h20m57s)
01:20:57

[that also just like a function so you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m00s)
01:21:00

[can kind of see this it's very general](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m03s)
01:21:03

[idea in pi torch that you know kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m04s)
01:21:04

[treat everything ideally like it's a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m06s)
01:21:06

[function so in this case we have a loss](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m09s)
01:21:09

[negative log likelihood loss object we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m10s)
01:21:10

[could treat it like a function we pass](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m13s)
01:21:13

[in our predictions and we pass in our](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m15s)
01:21:15

[actuals all right again the actuals need](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m18s)
01:21:18

[to be turned into a variable and put on](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m20s)
01:21:20

[the GPU because the loss is specifically](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m23s)
01:21:23

[the thing that we actually want to take](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m26s)
01:21:26

[the derivative of right so that gives us](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m27s)
01:21:27

[our loss and there it is that's our loss](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m30s)
01:21:30

[to point four three okay so it's a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m33s)
01:21:33

[variable and because it's a variable it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m36s)
01:21:36

[knows how it was calculated all right it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m40s)
01:21:40

[knows it was calculated with this loss](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m42s)
01:21:42

[function it knows that the predictions](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m44s)
01:21:44

[were calculated with this network it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m46s)
01:21:46

[knows that this network consisted of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m50s)
01:21:50

[these operations and so we can get the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m52s)
01:21:52

[gradient automatically and so to get the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m55s)
01:21:55

[gradient](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h21m59s)
01:21:59

[recall](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m01s)
01:22:01

[I'll drop backward remember L is the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m03s)
01:22:03

[thing that contains our loss right so L](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m05s)
01:22:05

[drop backward is is something which is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m08s)
01:22:08

[added to anything that's a variable you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m11s)
01:22:11

[even called drop backward and that says](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m13s)
01:22:13

[please calculate the gradients okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m15s)
01:22:15

[and so that calculates the gradients and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m18s)
01:22:18

[stores them inside that that the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m20s)
01:22:20

[basically for each of the weights that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m25s)
01:22:25

[was used it used each of the parameters](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m29s)
01:22:29

[that was used to calculate that it's now](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m30s)
01:22:30

[stored a dot grad well we'll see it](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m33s)
01:22:33

[later](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m36s)
01:22:36

[it's basically stored the gradient right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m36s)
01:22:36

[so we can then call optimizer dot step](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m38s)
01:22:38

[and we're going to do this bit step](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m42s)
01:22:42

[manually shortly and that's the bit that](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m43s)
01:22:43

[says please make the weights a little](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m45s)
01:22:45

[bit better right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m48s)
01:22:48

[and so what optimizer dot step is doing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m49s)
01:22:49

[is it saying like okay if you had like a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m52s)
01:22:52

[really simple function like this right](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h22m55s)
01:22:55

[then what the optimizer does is it says](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m05s)
01:23:05

[okay let's pick a random starting point](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m08s)
01:23:08

[right and let's calculate the value of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m12s)
01:23:12

[the loss right so here's our parameter](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m15s)
01:23:15

[here's our loss right let's take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m17s)
01:23:17

[derivative right the derivative tells us](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m20s)
01:23:20

[which way is down so it tells us we need](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m25s)
01:23:25

[to go that direction okay and we take a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m27s)
01:23:27

[small step and then we take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m31s)
01:23:31

[derivative again and we take a small](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m34s)
01:23:34

[step derivative again take a small step](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m35s)
01:23:35

[drove it again take a small step until](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m38s)
01:23:38

[eventually we're taking such small steps](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m41s)
01:23:41

[that we stop okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m43s)
01:23:43

[so that's what gradient descent does](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m44s)
01:23:44

[okay how big a step is a small step well](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m47s)
01:23:47

[we basically take the derivative here so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m53s)
01:23:53

[let's say derivative there is like eight](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m55s)
01:23:55

[right and we multiply it by a small](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h23m57s)
01:23:57

[number like say 0.01 and that tells us](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m00s)
01:24:00

[what step size to take this small number](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m04s)
01:24:04

[here is called the learning rate and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m07s)
01:24:07

[it's the most important hyper parameter](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m10s)
01:24:10

[to set right if you pick two smaller](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m13s)
01:24:13

[learning rate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m16s)
01:24:16

[then your steps down are going to be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m17s)
01:24:17

[like tiny and it's going to take you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m20s)
01:24:20

[forever okay too big a learning rate and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m23s)
01:24:23

[your jump too far right and then you'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m26s)
01:24:26

[jump too far and your diverge rather](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m31s)
01:24:31

[than converge okay we're not going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m34s)
01:24:34

[talk about how to pick a learning rate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m37s)
01:24:37

[in this class but in the deep learning](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m39s)
01:24:39

[class we actually show you a specific](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m40s)
01:24:40

[technique that very reliably picks a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m42s)
01:24:42

[very good learning rate so that's](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m45s)
01:24:45

[basically what's happening right so we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m50s)
01:24:50

[calculate the derivatives and we call](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m52s)
01:24:52

[the optimizer that does a step in other](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m54s)
01:24:54

[words update the weights based on the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m56s)
01:24:56

[gradients and the learning rate we](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h24m58s)
01:24:58

[should hopefully find that after doing](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m03s)
01:25:03

[that we have a better loss than we did](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m05s)
01:25:05

[before so I just really ran this and got](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m07s)
01:25:07

[a loss here of 4.16](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m10s)
01:25:10

[and after one step it's now 4.0 3 okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m11s)
01:25:11

[so it worked the way we hoped it word](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m16s)
01:25:16

[based on this mini batch it updated all](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m18s)
01:25:18

[of the weights in our network to be a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m21s)
01:25:21

[little better than they were as a result](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m24s)
01:25:24

[of which our loss went down okay](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m26s)
01:25:26

[so let's turn that into a training loop](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m28s)
01:25:28

[all right we're going to go through a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m31s)
01:25:31

[hundred steps grab one more mini batch](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m34s)
01:25:34

[of data from the data loader calculate](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m37s)
01:25:37

[our predictions from our network](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m40s)
01:25:40

[calculate our loss from the predictions](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m42s)
01:25:42

[and the actuals every 10 goes we'll](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m44s)
01:25:44

[print out the accuracy just take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m48s)
01:25:48

[mean of the whether they're equal or not](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m49s)
01:25:49

[1 pi taut specific thing you have to 0](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m53s)
01:25:53

[the gradients basically you can have](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m57s)
01:25:57

[networks where like you've got lots of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h25m58s)
01:25:58

[different loss functions that you might](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m00s)
01:26:00

[want to add all of the gradients](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m02s)
01:26:02

[together right so you have to tell play](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m03s)
01:26:03

[torch like when to set the gradients](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m06s)
01:26:06

[back to zero right so this just says set](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m08s)
01:26:08

[all the gradients to zero calculate the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m11s)
01:26:11

[gradients let's quote backward and then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m13s)
01:26:13

[take one step of the optimizer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m16s)
01:26:16

[so update the weights using the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m18s)
01:26:18

[gradients and the learning rate and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m20s)
01:26:20

[once we run it you can see the loss goes](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m22s)
01:26:22

[down and the accuracy goes up](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m24s)
01:26:24

[okay so that's the basic approach and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m29s)
01:26:29

[next lesson we'll see what that does](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m36s)
01:26:36

[alright well we're looking in detail](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m41s)
01:26:41

[we're not going to look inside here as I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m43s)
01:26:43

[say we're going to basically take the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m46s)
01:26:46

[calculation of the derivative says](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m48s)
01:26:48

[that's a given right but basically](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m50s)
01:26:50

[what's happening there in any kind of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m53s)
01:26:53

[deep network you have kind of like a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h26m58s)
01:26:58

[function that's like you know a linear](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m00s)
01:27:00

[function and then you pass the output of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m02s)
01:27:02

[that into another function that might be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m05s)
01:27:05

[like a rally and you pass the output of](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m08s)
01:27:08

[that into another function that might be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m10s)
01:27:10

[another linear net Lenny Olea you pass](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m12s)
01:27:12

[that into another function that might be](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m15s)
01:27:15

[another value and so forth right so at](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m17s)
01:27:17

[these these deep networks are just](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m20s)
01:27:20

[functions of functions of functions so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m22s)
01:27:22

[you could write them mathematically like](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m24s)
01:27:24

[that right and so all backprop does is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m26s)
01:27:26

[it says let's just simplify this down to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m31s)
01:27:31

[the two version as we can say okay u](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m33s)
01:27:33

[equals f of X right and so therefore the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m39s)
01:27:39

[derivative of G of f of X is we can](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m44s)
01:27:44

[calculate with the chain rule as being G](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m47s)
01:27:47

[- you f dash X right and so you can see](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m51s)
01:27:51

[we can do the same thing for the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m57s)
01:27:57

[functions of the functions of the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h27m59s)
01:27:59

[functions and so when you apply a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m00s)
01:28:00

[function to a function of a function you](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m03s)
01:28:03

[can take the derivative just by taking](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m05s)
01:28:05

[the product of the derivatives of each](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m07s)
01:28:07

[of those layers okay and in neural](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m09s)
01:28:09

[networks we call this back propagation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m12s)
01:28:12

[okay so when you hear back propagation](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m15s)
01:28:15

[it just means use the chain rule to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m17s)
01:28:17

[calculate the derivatives and so when](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m19s)
01:28:19

[you see a neural network to find](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m22s)
01:28:22

[like here right like if it's defined](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m29s)
01:28:29

[sequentially literally all this means is](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m34s)
01:28:34

[apply this function to the input apply](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m38s)
01:28:38

[this function to that apply this](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m42s)
01:28:42

[function to that apply this function to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m44s)
01:28:44

[that right so this is just defining a](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m46s)
01:28:46

[composition of a function to a function](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m49s)
01:28:49

[to a function to a function okay and so](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m52s)
01:28:52

[yeah so although we're not going to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m56s)
01:28:56

[bother with calculating the gradients](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m58s)
01:28:58

[ourselves you can now see why it can do](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h28m59s)
01:28:59

[it right as long as it has internally](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m01s)
01:29:01

[you know a it knows like what's the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m03s)
01:29:03

[what's the derivative of ^ what's the](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m06s)
01:29:06

[derivative of sine what's the derivative](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m09s)
01:29:09

[of + and so forth then our Python code](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m11s)
01:29:11

[in here is just combining those things](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m14s)
01:29:14

[together so it just needs to know how to](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m17s)
01:29:17

[compose them together with the chain](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m21s)
01:29:21

[rule and where it goes okay okay so I](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m23s)
01:29:23

[think we can leave it there for now and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m34s)
01:29:34

[yeah and in the next class we'll go and](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m35s)
01:29:35

[we'll see how to write our own optimizer](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m39s)
01:29:39

[and then we'll have solved em mist from](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m42s)
01:29:42

[scratch ourselves see you then](https://www.youtube.com/watch?v=PGC0UxakTvM#t=01h29m45s)
01:29:45

