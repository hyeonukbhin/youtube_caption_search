okay hi everybody welcome back let's see
00:00:00.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m00s

you all here it's been another busy week
00:00:02.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m02s

of deep learning lots of cool things
00:00:09.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m09s

going on and like last week I would have
00:00:14.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m14s

to highlight a few really interesting
00:00:16.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m16s

articles that some of some of you folks
00:00:18.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m18s

have have written
00:00:20.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m20s

vitaliy wrote one of the best articles
00:00:24.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m24s

I've seen for a while I think actually
00:00:29.609
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m29s

talking about differential learning
00:00:31.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m31s

rates and stochastic gradient descent
00:00:34.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m34s

with restarts be sure to check it out if
00:00:35.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m35s

you can because what he's done I feel
00:00:39.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m39s

like he's done a great job of kind of
00:00:41.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m41s

positioning it a place that you can get
00:00:45.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m45s

a lot out of it you know regardless of
00:00:47.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m47s

your background but for those who want
00:00:49.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m49s

to go further he's also got links to
00:00:51.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m51s

like the academic papers it came from
00:00:53.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m53s

and kind of rests of showing examples of
00:00:55.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m55s

all of all the things he's talking about
00:00:58.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m58s

and I think it's a it's a particularly
00:00:59.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h00m59s

nicely done article so good kind of role
00:01:02.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m02s

model for technical communication one of
00:01:06.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m06s

the things I've liked about you know
00:01:09.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m09s

seeing people post these post these
00:01:11.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m11s

articles during the week is the
00:01:14.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m14s

discussion on the forums have also been
00:01:15.689
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m15s

like really great there's been a lot of
00:01:17.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m17s

a lot of people helping out like
00:01:19.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m19s

explaining things you know which you
00:01:22.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m22s

know maybe those parts of the post
00:01:24.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m24s

period where people have said actually
00:01:26.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m26s

that's not quite how it works and people
00:01:27.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m27s

have learnt new things that way people
00:01:29.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m29s

have come up with new ideas as a result
00:01:31.259
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m31s

as well these discussions of stochastic
00:01:32.939
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m32s

gradient descent with restarts and
00:01:37.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m37s

cyclic or learning rates just being a
00:01:39.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m39s

few of them actually Anand
00:01:40.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m40s

sahar has written another great post
00:01:42.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m42s

talking about a similar similar topic
00:01:45.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m45s

and why it works so well and again lots
00:01:49.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m49s

of great pictures and references to
00:01:51.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m51s

papers and most importantly perhaps code
00:01:54.649
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m54s

showing how it actually works
00:01:57.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h01m57s

mark Hoffman covered the same topic at
00:02:01.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m01s

kind of a nice introductory level I
00:02:05.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m05s

think really really kind of clear
00:02:07.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m07s

intuition many Cantor talk specifically
00:02:09.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m09s

about differential learning rates and
00:02:13.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m13s

why it's interesting and again providing
00:02:16.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m16s

some nice context to people not familiar
00:02:19.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m19s

with transfer learning you're not going
00:02:20.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m20s

right back to saying like or what is
00:02:22.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m22s

transfer learning why is that
00:02:23.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m23s

interesting and given that why good
00:02:25.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m25s

differential learning rates be helpful
00:02:28.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m28s

and then one thing I particularly liked
00:02:31.019
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m31s

about arjen's
00:02:34.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m34s

article was that he talked not just
00:02:35.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m35s

about the technology that we're looking
00:02:38.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m38s

at but also talked about some of the
00:02:39.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m39s

implications particularly from a
00:02:42.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m42s

commercial point of view so thinking
00:02:44.319
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m44s

about like based on some of the things
00:02:46.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m46s

we've learned about so far what are some
00:02:48.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m48s

of the implications that that has you
00:02:50.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m50s

know in real life and lots of background
00:02:52.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m52s

lots of pictures and then discussing
00:02:54.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m54s

some of the yeah some of the
00:02:58.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m58s

implications so there's been lots of
00:02:59.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h02m59s

great stuff online and thanks to
00:03:02.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m02s

everybody for all the great work that
00:03:04.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m04s

you've been doing as we talked about
00:03:06.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m06s

last week if you're kind of vaguely
00:03:09.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m09s

wondering about writing something but
00:03:12.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m12s

you're feeling a bit intimidated about
00:03:13.959
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m13s

it because you've never really written a
00:03:15.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m15s

technical post before just jump in you
00:03:16.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m16s

know it's it's it's it's a really
00:03:19.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m19s

welcoming and encouraging group I think
00:03:22.319
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m22s

to to work with
00:03:25.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m25s

so we're going to have a kind of an
00:03:30.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m30s

interesting lesson today which is we're
00:03:32.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m32s

going to cover a whole lot of different
00:03:34.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m34s

applications so we've we've spent quite
00:03:39.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m39s

a lot of time on computer vision and
00:03:41.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m41s

today we're going to try if we can to
00:03:42.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m42s

get through three totally different
00:03:45.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m45s

areas structured learning so looking at
00:03:47.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m47s

kind of how you look at so we're going
00:03:51.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m51s

to start out looking at structured
00:03:54.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m54s

learning or structured data learning by
00:03:55.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m55s

which I mean building models on top of
00:03:58.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h03m58s

things look more like database tables so
00:04:02.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m02s

kind of columns of different types of
00:04:05.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m05s

data there might be financial or
00:04:07.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m07s

geographical or whatever we're going to
00:04:09.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m09s

look at using deep learning for language
00:04:12.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m12s

natural language processing and we're
00:04:14.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m14s

going to look at using deep learning for
00:04:17.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m17s

recommendation systems and so we're
00:04:19.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m19s

going to cover these at a very high
00:04:21.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m21s

level and the focus will be on
00:04:24.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m24s

here's how to use the software to do it
00:04:28.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m28s

more then here is what's going on behind
00:04:31.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m31s

the scenes and then the next three
00:04:33.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m33s

lessons we'll be digging into the
00:04:35.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m35s

details of what's been going on behind
00:04:38.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m38s

the scenes and also coming back to
00:04:39.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m39s

looking at a lot of the details of
00:04:42.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m42s

computer vision that we've kind of
00:04:44.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m44s

skipped over so far so the focus today
00:04:46.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m46s

is really on like how do you actually do
00:04:49.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m49s

these applications and we'll kind of
00:04:52.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m52s

talk briefly about some of the concepts
00:04:54.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m54s

involved before we do I did want to talk
00:04:56.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h04m56s

about one key new concept which is
00:05:01.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m01s

dropout and you might have seen dropout
00:05:07.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m07s

mentioned a bunch of times already and
00:05:09.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m09s

got there got the impression that this
00:05:11.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m11s

is something important and indeed it is
00:05:12.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m12s

so look at dropout I'm going to look at
00:05:14.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m14s

the dog breeds current cable competition
00:05:17.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m17s

that's going on and what I've done is
00:05:22.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m22s

I've gone ahead and I've created a pre
00:05:25.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m25s

train network as per usual and I've
00:05:28.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m28s

passed in pre compute equals true and so
00:05:31.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m31s

that's going to pre compute the
00:05:33.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m33s

activations that come out of the last
00:05:36.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m36s

convolutional layer remember an
00:05:38.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m38s

activation is just a number
00:05:40.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m40s

it's a number just to remind you an
00:05:42.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m42s

activation like here is one activation
00:05:45.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m45s

it's a number and specifically the
00:05:48.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m48s

activations are calculated based on some
00:05:51.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m51s

weights also called parameters that make
00:05:53.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m53s

up kernels or filters and they get
00:05:57.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h05m57s

applied to the previous layers
00:06:00.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m00s

activations but it could well be the
00:06:02.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m02s

inputs or they could themselves be the
00:06:05.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m05s

results of other calculations okay so
00:06:07.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m07s

when we say activation keep remembering
00:06:09.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m09s

we're talking about a number that's
00:06:11.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m11s

being calculated
00:06:12.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m12s

so we've pre compute some activations
00:06:14.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m14s

and then what we do is we put on top of
00:06:17.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m17s

that a bunch of additional initially
00:06:20.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m20s

randomly generated fully connected
00:06:23.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m23s

layers so we're just going to do some
00:06:26.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m26s

matrix multiplications on top of these
00:06:27.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m27s

just like in our Excel worksheet at the
00:06:29.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m29s

very end
00:06:32.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m32s

we had this matrix that we just did a
00:06:35.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m35s

matrix multiplication but so what you
00:06:38.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m38s

can actually do is if you just type the
00:06:43.009
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m43s

name of your loner object you can
00:06:46.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m46s

actually see what's in it you can see
00:06:48.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m48s

the layers in it so when I was
00:06:50.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m50s

previously been skipping over a little
00:06:52.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m52s

bit about are we add a few layers to the
00:06:54.319
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m54s

end these are actually the layers of yet
00:06:56.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m56s

we're going to do batch norm in the last
00:06:58.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h06m58s

lesson so don't worry about that for now
00:07:01.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m01s

a linear layer simply means a matrix
00:07:02.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m02s

multiply okay so this is a matrix which
00:07:06.229
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m06s

has a 1024 rows and 512 columns and so
00:07:08.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m08s

in other words it's going to take in
00:07:13.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m13s

1024 activations and spit out 512
00:07:14.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m14s

activations then we have a rail unit
00:07:18.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m18s

which remember is just replace the
00:07:22.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m22s

negatives with 0 we'll skip over the
00:07:23.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m23s

batch norm we'll come back drop out then
00:07:26.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m26s

we have a second linear layer that takes
00:07:29.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m29s

those 512 activations from the previous
00:07:30.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m30s

linear layer and puts them through a new
00:07:33.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m33s

matrix multiply 5 12 by 120 it spits out
00:07:35.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m35s

a new 120 activations and then finally
00:07:39.259
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m39s

put that through soft mats and for those
00:07:42.229
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m42s

of you that don't remember softmax we
00:07:45.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m45s

looked at that last year last week it's
00:07:47.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m47s

this idea that we basically just take
00:07:50.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m50s

the the activation let's say the dog go
00:07:53.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m53s

e to the power of that and then divide
00:07:57.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m57s

that into the sum of e to the power of
00:07:59.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h07m59s

all the intermissions so that was the
00:08:02.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m02s

thing that adds up to one all of them
00:08:03.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m03s

add up to one and each one individually
00:08:05.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m05s

is between 0 and 1 ok so that's that's
00:08:07.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m07s

what we added on top and that's the
00:08:12.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m12s

thing when we have pre computed calls
00:08:14.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m14s

true that's the thing we trained so I
00:08:15.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m15s

wanted to talk about what this dropout
00:08:17.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m17s

is and what this key is because it's a
00:08:19.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m19s

really important thing that we get to
00:08:21.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m21s

choose so a dropout layer with P equals
00:08:24.139
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m24s

0.5 literally does this we go over to
00:08:27.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m27s

our spreadsheet and let's pick any layer
00:08:30.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m30s

with some activations and let's say ok
00:08:32.719
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m32s

I'm going to apply dropout with a P of
00:08:34.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m34s

0.5 to con true what that means is I go
00:08:37.459
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m37s

through and with a 50% chance I pick a
00:08:41.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m41s

cell right pick an activation so I kept
00:08:46.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m46s

like
00:08:48.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m48s

half of them randomly and I delete them
00:08:48.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m48s

okay that's that's what dropout is right
00:08:53.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m53s

so it's so the P equals 0.5 means what's
00:08:57.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h08m57s

the probability of deleting that cell
00:09:01.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m01s

all right so when I delete those cells
00:09:03.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m03s

if you have a log like look at the
00:09:08.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m08s

output it doesn't actually change by
00:09:11.209
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m11s

very much at all just a little bit
00:09:13.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m13s

particularly because remember it's
00:09:15.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m15s

getting through a Mac spalling layer
00:09:16.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m16s

right so it's only going to change it at
00:09:17.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m17s

all if it was actually the maximum in
00:09:19.339
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m19s

that group of four and furthermore it's
00:09:22.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m22s

just one piece of you know if it's going
00:09:25.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m25s

into a convolution rather than into a
00:09:27.529
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m27s

max Paul is just one piece of that that
00:09:29.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m29s

filter so interestingly the idea of like
00:09:32.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m32s

randomly throwing away half of the
00:09:37.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m37s

activations in a layer has a really
00:09:39.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m39s

interesting result and one important
00:09:43.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m43s

thing to mention is each mini batch we
00:09:46.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m46s

throw away a different random half of
00:09:49.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m49s

activations earlier and so what it means
00:09:53.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m53s

is it forces it to not over fit right in
00:09:55.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h09m55s

other words if there's some particular
00:10:00.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m00s

activation that's really learnt just
00:10:02.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m02s

that exact that exact dog or that exact
00:10:04.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m04s

cat right then when that gets dropped
00:10:08.899
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m08s

out the whole thing now isn't going to
00:10:11.899
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m11s

work as well it's not going to recognize
00:10:14.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m14s

that image right so it has to in order
00:10:15.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m15s

for this to work it has to try and find
00:10:18.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m18s

a representation that that actually
00:10:21.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m21s

continues to work even as random half of
00:10:25.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m25s

the activations get thrown away every
00:10:28.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m28s

time all right so it's a it's it's I
00:10:31.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m31s

guess about four years old now three or
00:10:34.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m34s

four years old and it's been absolutely
00:10:36.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m36s

critical in making modern deep learning
00:10:41.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m41s

work and the reason why is it really
00:10:44.779
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m44s

just about solve the problem of
00:10:47.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m47s

generalization for us before drop out
00:10:50.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m50s

came along if you try to train a model
00:10:52.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m52s

with lots of parameters and you were
00:10:56.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m56s

overfitting and you already tried all
00:10:59.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h10m59s

the
00:11:02.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m02s

imitation you could and you already had
00:11:02.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m02s

as much data as you could you there were
00:11:05.209
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m05s

some other things you could try but to a
00:11:08.149
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m08s

large degree you were kind of stuck okay
00:11:09.649
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m09s

and so then Geoffrey Hinton and his
00:11:12.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m12s

colleagues came up with this this
00:11:16.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m16s

dropout idea that was loosely inspired
00:11:17.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m17s

by the way the brain works and also
00:11:20.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m20s

loosely inspired by Geoffrey Hinton's
00:11:23.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m23s

experience in bank teller Hugh's
00:11:25.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m25s

apparently and yeah somehow they came up
00:11:27.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m27s

with this amazing idea of like hey let's
00:11:31.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m31s

let's try throwing things away at random
00:11:32.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m32s

and so as you could imagine if your P
00:11:35.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m35s

was like point O one then you're
00:11:40.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m40s

throwing away 1% of your activations for
00:11:43.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m43s

that layer at random it's not gonna
00:11:46.399
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m46s

randomly change things up very much at
00:11:48.889
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m48s

all so it's not really going to protect
00:11:51.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m51s

you from overfitting much at all on the
00:11:54.319
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m54s

other hand if your pain was 0.99 then
00:11:58.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h11m58s

that would be like going through the
00:12:00.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m00s

whole thing and throwing away nearly
00:12:02.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m02s

everything right and that would be very
00:12:04.759
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m04s

hard for it to overfit so that would be
00:12:08.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m08s

great for generalization but it's also
00:12:12.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m12s

going to kill your accuracy so this is
00:12:13.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m13s

kind of play off between high p-values
00:12:17.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m17s

generalized well but will decrease your
00:12:21.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m21s

training accuracy and low p-values will
00:12:24.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m24s

generalize less well that will give you
00:12:27.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m27s

a less good training accuracy so for
00:12:29.269
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m29s

those of you that have been wondering
00:12:32.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m32s

why is it that particularly early in
00:12:33.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m33s

training my validation losses better
00:12:36.139
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m36s

than my training losses but which seems
00:12:39.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m39s

otherwise really surprising hopefully
00:12:41.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m41s

some of you have been wondering why that
00:12:44.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m44s

is because on a data set that it never
00:12:45.529
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m45s

gets to see you wouldn't expect the
00:12:48.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m48s

losses to ever be that's better
00:12:50.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m50s

and the reason why is because when we
00:12:53.149
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m53s

look at the validation set we turn off
00:12:55.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m55s

dropout right so in other words when
00:12:57.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m57s

you're doing inference when you're
00:12:59.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h12m59s

trying to say is this or cat or is this
00:13:01.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m01s

a dog we certainly don't want to be
00:13:02.899
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m02s

including random drop out there right we
00:13:05.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m05s

want to be using the best model we can
00:13:07.879
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m07s

okay so that's why early in training in
00:13:10.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m10s

particular
00:13:13.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m13s

actually see that our validation
00:13:15.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m15s

accuracy and loss tends to be better if
00:13:17.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m17s

we're using dropout okay so yes you know
00:13:21.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m21s

you have to do anything to accommodate
00:13:26.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m26s

for the fact that you are throwing away
00:13:28.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m28s

some that's a great question so we don't
00:13:30.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m30s

that PI torch does so PI torch behind
00:13:35.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m35s

the scenes does two things if you say P
00:13:38.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m38s

equals point five it throws away half of
00:13:41.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m41s

the activations but it also doubles all
00:13:43.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m43s

the activations that are already there
00:13:49.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m49s

so when average the kind of the average
00:13:51.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m51s

activation doesn't change which is
00:13:53.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m53s

pretty pretty neat trick so yeah you
00:13:56.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h13m56s

don't have to worry about it basically
00:14:00.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m00s

it's it's done for you so if we say so
00:14:01.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m01s

you can pass in peas this is the this is
00:14:06.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m06s

the p value for all of the added layers
00:14:09.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m09s

to say with first AI what dropout do you
00:14:12.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m12s

want on each of the layers in these
00:14:16.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m16s

these added layers it won't change the
00:14:18.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m18s

dropout in the pre trained network like
00:14:20.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m20s

the hope is that that's already been
00:14:23.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m23s

pretty trained with some appropriate
00:14:25.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m25s

level of dropout we don't change it put
00:14:27.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m27s

on these layers that we add you can say
00:14:29.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m29s

how much and so you can see here as a
00:14:31.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m31s

T's equals 0.5 so my first dropout has
00:14:33.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m33s

0.5 my second dropout has 0.5 I remember
00:14:36.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m36s

coming to the input of this was the
00:14:40.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m40s

output of the last convolutional layer
00:14:44.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m44s

of pre-trained network and we go over it
00:14:46.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m46s

and we actually throw away half of that
00:14:48.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m48s

before you can start go through our
00:14:50.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m50s

linear layer throw away the negatives
00:14:52.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m52s

throw away half the result of that go
00:14:55.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m55s

through another linear layer and then
00:14:58.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h14m58s

pass it to our softness for minor
00:15:00.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m00s

numerical precision region reasons it
00:15:05.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m05s

turns out to be better to take the log
00:15:08.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m08s

of the softmax then softmax directly and
00:15:09.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m09s

that's why you'll have noticed that when
00:15:12.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m12s

you actually get predictions out of our
00:15:14.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m14s

models you always have to go npx both
00:15:16.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m16s

the predictions but again the details as
00:15:19.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m19s

to why aren't important so if we want to
00:15:22.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m22s

try removing dropout we could go peas
00:15:25.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m25s

equals zero all right and you'll see
00:15:28.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m28s

where else before we started with the
00:15:31.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m31s

point seven six accuracy in the first
00:15:32.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m32s

epoch now you could have point eight
00:15:34.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m34s

accuracy in the first debug alright so
00:15:36.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m36s

by not doing drop out our first teapot
00:15:38.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m38s

worked better not surprisingly because
00:15:41.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m41s

we're not throwing anything away but by
00:15:43.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m43s

the third epoch here we had eighty four
00:15:45.649
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m45s

point eight and here we have eighty four
00:15:47.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m47s

point one so it started out better and
00:15:50.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m50s

ended up worse so even after three
00:15:52.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m52s

epochs you can already see where master
00:15:54.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m54s

for overfitting right we've got point
00:15:56.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m56s

three loss on the train and point five
00:15:58.339
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h15m58s

loss on the validation yep and so if you
00:16:01.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m01s

look now you can see in the resulting
00:16:06.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m06s

model there's no drop out at all so if
00:16:09.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m09s

the P is zero we don't even add it to
00:16:12.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m12s

the model another thing to mention is
00:16:14.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m14s

you might have noticed that what we've
00:16:19.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m19s

been doing is we've been adding two
00:16:21.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m21s

linear layers right in our additional
00:16:23.709
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m23s

layers you don't have to do that by the
00:16:27.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m27s

way there's actually a parameter called
00:16:29.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m29s

extra fully connected layers that you
00:16:31.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m31s

can basically pass a list of how long do
00:16:34.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m34s

you want or how big do you want each of
00:16:38.149
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m38s

the additional fully connected layers to
00:16:40.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m40s

be and so by default well you need to
00:16:41.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m41s

have at least one right because you need
00:16:44.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m44s

something that takes the output of the
00:16:47.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m47s

convolutional layer which in this case
00:16:49.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m49s

is of size thousand twenty-four and
00:16:51.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m51s

turns it into the number of classes you
00:16:52.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m52s

have cats versus dogs would be two dog
00:16:56.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m56s

breeds would be 120 planet satellite
00:16:59.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h16m59s

seventeen whatever that's you always
00:17:02.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m02s

need one linear layer at least and you
00:17:04.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m04s

can't pick how big that is that's
00:17:07.429
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m07s

defined by your problem but you can
00:17:08.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m08s

choose what the other size is or if it
00:17:12.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m12s

happens at all so if we were to pass in
00:17:14.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m14s

an empty list and now we're saying don't
00:17:16.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m16s

add any additional mini layers just the
00:17:19.699
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m19s

one that we have to have right so here
00:17:21.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m21s

we've got P is equals zero
00:17:24.169
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m24s

extra fully connected layers is empty
00:17:25.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m25s

this is like the minimum possible kind
00:17:28.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m28s

of top model we can put on top and again
00:17:32.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m32s

like if we do that
00:17:36.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m36s

you can see above we actually end up
00:17:40.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m40s

with in this case a reasonably good
00:17:43.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m43s

result because we're not training it for
00:17:45.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m45s

very long and this particular
00:17:47.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m47s

pre-trained Network is really well
00:17:49.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m49s

suited to this particular problem
00:17:51.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m51s

yesterday so Jeremy what kind of piece
00:17:53.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m53s

should we were using by default so the
00:17:57.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h17m57s

one that's there by default for the
00:18:01.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m01s

first layer is 0.25 and for the second
00:18:05.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m05s

layer is 0.5 that seems to work pretty
00:18:09.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m09s

well for most things right so like it's
00:18:13.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m13s

it's it you don't necessarily need to
00:18:17.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m17s

change it at all
00:18:19.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m19s

basically if you find it's overfitting
00:18:20.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m20s

just start bumping it up so try first of
00:18:22.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m22s

all setting it to 0.5 that'll set them
00:18:26.179
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m26s

both to 0.5 if it still overfitting a
00:18:28.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m28s

lot try 0.7 like you can you can narrow
00:18:31.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m31s

down and like it's not that many numbers
00:18:33.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m33s

change right and if you're under fitting
00:18:38.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m38s

then you can try and making it lower
00:18:41.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m41s

it's unlikely you would need to make it
00:18:44.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m44s

much lower because like even in these
00:18:47.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m47s

dogs versus cats situations you know we
00:18:49.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m49s

don't see they have to make it lower so
00:18:54.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m54s

it's more likely to be increasing at
00:18:55.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m55s

about 0.6 0.7 but you can fiddle around
00:18:57.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h18m57s

I find these the ones that are there by
00:19:00.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m00s

defaults in work pretty well most of the
00:19:03.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m03s

time so one place I actually did
00:19:05.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m05s

increase this was in the dog breeds one
00:19:08.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m08s

I did set it them both to 0.5 when I
00:19:12.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m12s

used a bigger model so like ResNet 34
00:19:15.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m15s

has less parameters so it doesn't over
00:19:19.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m19s

fit as much but then when I started
00:19:22.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m22s

bumping pumping it up to like a resonate
00:19:23.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m23s

50 which has a lot more parameters and
00:19:25.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m25s

noticed it started overfitting so then I
00:19:28.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m28s

also increased my drop out so as you use
00:19:30.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m30s

like bigger models you'll often need to
00:19:32.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m32s

add more drama can you pass it over
00:19:35.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m35s

there please you know
00:19:38.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m38s

if we set B to 0.5 roughly what
00:19:42.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m42s

percentage is it 50%
00:19:46.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m46s

we say RP pasta
00:19:49.169
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m49s

is there a particular way in which you
00:19:52.979
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m52s

can determine if the data is being all
00:19:55.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m55s

fitted yeah you can see that the like
00:19:57.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h19m57s

here you can see that the training error
00:20:04.149
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m04s

is a loss is much lower than the
00:20:06.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m06s

validation list you can't tell if it's
00:20:08.979
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m08s

like to over fitted like zero
00:20:11.889
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m11s

overfitting is not generally optimal
00:20:16.299
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m16s

like the only way to find that out is
00:20:18.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m18s

remember the only thing you're trying to
00:20:19.899
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m19s

do is to get this number low right the
00:20:21.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m21s

validation loss number low so in the end
00:20:23.229
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m23s

you kind of have to play around with a
00:20:26.379
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m26s

few different things and see which thing
00:20:28.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m28s

ends up getting the validation loss low
00:20:29.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m29s

but you kind of get a feel overtime for
00:20:32.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m32s

your particular problem what does
00:20:35.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m35s

overfitting what does too much River
00:20:37.419
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m37s

fitting look like great so so that's
00:20:38.919
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m38s

dropout and we're going to be using that
00:20:45.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m45s

a lot and remember it's there by default
00:20:47.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m47s

service here another question
00:20:49.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m49s

oh so I have two questions so one is so
00:20:51.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m51s

when it says the dropout rate is 0.5 it
00:20:56.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h20m56s

does it like you know I delete each cell
00:21:01.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m01s

with a probability of 0.5 or does it
00:21:04.299
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m04s

just pick 50% randomly I mean I know
00:21:07.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m07s

both effectively is the 4-month yeah
00:21:10.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m10s

okay okay a second question is why does
00:21:12.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m12s

the average activation matter well it
00:21:16.149
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m16s

matters because the remember if you look
00:21:19.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m19s

the Excel spreadsheet that the result of
00:21:22.779
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m22s

this cell for example is equal to these
00:21:27.269
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m27s

nine multiplied by each of these nine
00:21:36.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m36s

right and add it up so if we deleted
00:21:40.139
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m40s

half of these then that would also cause
00:21:42.999
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m42s

this number to half which would cause
00:21:45.999
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m45s

like everything else after that to
00:21:48.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m48s

change and so if you change what it
00:21:50.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m50s

means you know like you then you're
00:21:53.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m53s

changing something that used to say like
00:21:55.029
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m55s

Oh fluffy ears are fluffy if this is
00:21:56.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m56s

greater than point six now it's only
00:21:59.139
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h21m59s

fluffy if it's greater than point three
00:22:01.029
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m01s

like we're changing the meaning of
00:22:02.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m02s

everything so you
00:22:03.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m03s

here is to delete things without
00:22:05.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m05s

changing where are you using a linear
00:22:07.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m07s

activation for one of the earlier
00:22:14.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m14s

activations why are we using when you
00:22:16.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m16s

yeah why that particular activation
00:22:19.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m19s

because that's what this set of layers
00:22:21.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m21s

is so we've with the the pre-trained
00:22:23.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m23s

network is or is the convolutional net
00:22:26.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m26s

work and that's pre computed so we don't
00:22:28.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m28s

see it so what that spits out is it's a
00:22:31.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m31s

vector so the only choice we have is to
00:22:35.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m35s

use linear layers at this point okay can
00:22:37.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m37s

we have different level of dropout by
00:22:42.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m42s

layer yes absolutely how to do that
00:22:44.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m44s

great so so you can absolutely have
00:22:47.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m47s

different dropout by layer and that's
00:22:51.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m51s

why this is actually called peas so you
00:22:53.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m53s

could pass in an array here so if I went
00:22:56.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m56s

0 comma 0.2 for example and then extra
00:22:58.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h22m58s

fully connecting it I might add 512
00:23:03.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m03s

right then that's going to be 0 drop out
00:23:05.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m05s

before the first of them and point to
00:23:08.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m08s

drop out before the second of them yes
00:23:10.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m10s

requests and I must admit I don't have a
00:23:13.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m13s

great intuition even after doing this
00:23:16.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m16s

for a few years for like when should
00:23:19.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m19s

earlier or later layers have different
00:23:22.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m22s

amounts of dropping out it's still
00:23:25.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m25s

something I kind of play with and I
00:23:28.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m28s

can't quite find rules of thumb so if
00:23:30.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m30s

some of you come up with some good rules
00:23:32.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m32s

of thumb I'd love to hear about them I
00:23:34.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m34s

think if in doubt you can use the same
00:23:36.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m36s

drop out and every fully connected layer
00:23:40.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m40s

the other thing you can try is often
00:23:42.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m42s

people only put drop out on the very
00:23:45.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m45s

last linear layer so there'd be the two
00:23:47.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m47s

things to try
00:23:49.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m49s

so Jeremy why do you monitor the log
00:23:53.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m53s

loss the loss instead of the accuracy
00:23:57.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h23m57s

going up well because the loss is the
00:24:00.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m00s

only thing that we can see for both the
00:24:03.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m03s

validation set in the training set so
00:24:08.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m08s

it's nice to be able to compare them
00:24:10.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m10s

also as we learn about later the loss is
00:24:13.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m13s

the thing that we're actually optimizing
00:24:18.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m18s

so it's it's kind of a little more it's
00:24:21.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m21s

a little easier to monitor that and
00:24:25.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m25s

understand what that means
00:24:27.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m27s

can you pass it over there so with the
00:24:29.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m29s

drop out we're kind of adding some
00:24:35.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m35s

random noise every iteration right you
00:24:37.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m37s

know so that means that we don't do as
00:24:39.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m39s

much learning yeah that's right so it
00:24:42.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m42s

doesn't seem to impact the learning rate
00:24:49.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m49s

enough thrive ever noticed it I I would
00:24:51.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m51s

say you're probably right in theory it
00:24:54.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m54s

might but not enough that it's ever
00:24:56.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m56s

affected me okay so let's talk about
00:24:58.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h24m58s

this structured data problem and so to
00:25:06.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m06s

remind you we were looking at kegels
00:25:10.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m10s

rossmann competition which is a German
00:25:13.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m13s

chain of supermarkets I believe and you
00:25:17.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m17s

can find this in lesson three Russman
00:25:21.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m21s

and the main data set is the one where
00:25:23.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m23s

we were looking to say at a particular
00:25:30.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m30s

store how much did they sell okay and
00:25:32.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m32s

there's a few big key piece of
00:25:36.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m36s

information one is what was the date
00:25:38.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m38s

another was were they open
00:25:40.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m40s

did they have a promotion on was it a
00:25:42.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m42s

holiday in that state and was it a
00:25:46.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m46s

holiday as for school a state holiday
00:25:48.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m48s

there wasn't a school holiday yeah and
00:25:50.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m50s

then we had some more information about
00:25:53.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m53s

stores like what for this store what
00:25:54.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m54s

kind of stuff did they tend to sell what
00:25:57.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m57s

kind of store are they how far away the
00:25:59.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h25m59s

competition and so forth so with the
00:26:01.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m01s

data
00:26:04.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m04s

set like this there's really two main
00:26:05.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m05s

kinds of column there's columns that we
00:26:07.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m07s

think of as categorical they have a
00:26:09.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m09s

number of levels
00:26:11.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m11s

so the assortment column is categorical
00:26:12.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m12s

and it has levels such as a B and C
00:26:16.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m16s

where else something like competition
00:26:20.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m20s

distance we will call continuous it has
00:26:23.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m23s

a number attached to it where
00:26:26.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m26s

differences or ratios even if that
00:26:27.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m27s

number have some kind of meaning and so
00:26:29.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m29s

we need to deal with these two things
00:26:32.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m32s

quite differently okay so anybody who's
00:26:34.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m34s

done any machine learning of any kind
00:26:37.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m37s

will be familiar with using continuous
00:26:40.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m40s

columns if you've done any linear
00:26:42.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m42s

regression for example you can just like
00:26:44.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m44s

modify them by parameters for instance
00:26:46.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m46s

categorical columns we're going to have
00:26:49.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m49s

to think about a little bit more we're
00:26:51.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m51s

not going to go through the data
00:26:54.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m54s

cleaning we're going to assume that
00:26:55.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m55s

that's a feature Engineering we're going
00:26:57.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m57s

to assume all that's been done and so
00:26:59.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h26m59s

basically at the end of that we have a
00:27:03.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m03s

list of columns and the in this case I
00:27:06.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m06s

didn't do any of the thinking around the
00:27:10.799
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m10s

feature engineering or dedicating myself
00:27:14.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m14s

this is all directly from the
00:27:16.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m16s

third-place winners of this competition
00:27:18.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m18s

and so they came up with all of these
00:27:21.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m21s

different columns that they found useful
00:27:24.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m24s

and so you'll notice the list here is a
00:27:28.169
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m28s

list of the things that we're going to
00:27:33.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m33s

treat as categorical variables numbers
00:27:35.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m35s

like year a month and day although we
00:27:39.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m39s

could treat them as continuous like they
00:27:44.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m44s

the different you know differences
00:27:46.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m46s

between 2000 and 2003 is meaningful we
00:27:48.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m48s

don't have to right and you'll see
00:27:52.179
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m52s

shortly how how categorical variables
00:27:54.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h27m54s

are treated but basically if we decide
00:28:00.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m00s

to make something a categorical variable
00:28:02.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m02s

what we're telling our neural net down
00:28:04.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m04s

the track is that for every different
00:28:06.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m06s

level of say year you know 2000 2001
00:28:08.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m08s

2002 you can treat it totally
00:28:12.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m12s

differently where else if we say it's
00:28:14.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m14s

continuous its
00:28:16.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m16s

have to come up with some kind of like
00:28:18.419
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m18s

function some kind of smooth ish
00:28:20.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m20s

function right and so often even for
00:28:22.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m22s

things like a year that actually are
00:28:26.249
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m26s

continuous but they don't actually have
00:28:28.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m28s

many distinct levels it often works
00:28:30.629
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m30s

better to treat it as categorical so
00:28:33.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m33s

another good example day of week right
00:28:36.899
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m36s

so like day of week between naught &amp; 6
00:28:39.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m39s

it's a number and it means something
00:28:42.919
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m42s

motifs between 3 &amp; 5 is two days and has
00:28:45.119
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m45s

meaning but if you think about like how
00:28:48.239
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m48s

word sales in a strawberry buy a day of
00:28:50.039
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m50s

week it could well be that like you know
00:28:54.119
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m54s

Saturdays and Sundays are over here and
00:28:56.609
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m56s

Fridays are over here and Wednesdays are
00:28:58.499
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h28m58s

over here like each day is going to
00:29:00.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m00s

behave kind of qualitatively differently
00:29:02.759
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m02s

right so by saying this is the
00:29:05.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m05s

categorical variable as you'll see we're
00:29:07.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m07s

going to let the neural-net do that
00:29:10.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m10s

right so this thing where we get where
00:29:13.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m13s

we say which are continuous in which a
00:29:15.629
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m15s

categorical to some extent this is the
00:29:18.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m18s

modeling decision you get to make now if
00:29:20.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m20s

something is coded in your data is like
00:29:24.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m24s

a B and C or you know Jeremy and you
00:29:28.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m28s

knit or whatever you actually you're
00:29:31.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m31s

going to have to call that categorical
00:29:34.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m34s

right there's no way to treat that
00:29:35.999
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m35s

directly as a continuous variable on the
00:29:37.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m37s

other hand if it starts out as a
00:29:40.649
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m40s

continuous variable like age or day of
00:29:42.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m42s

week you get to decide whether you want
00:29:45.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m45s

to treat it as continuous or categorical
00:29:49.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m49s

okay so summarize if it's categorical
00:29:50.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m50s

and data it's going to have to be
00:29:53.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m53s

categorical in the model if it's
00:29:55.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m55s

continuous in the data you get to pick
00:29:57.179
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m57s

whether to make it continuous or
00:29:59.609
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h29m59s

categorical in the model so in this case
00:30:01.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m01s

again what I just did whatever the
00:30:05.429
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m05s

third-place winners of this competition
00:30:07.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m07s

did these are the ones that they decided
00:30:08.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m08s

to use as categorical these were the
00:30:11.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m11s

ones they decided to use as continuous
00:30:12.779
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m12s

and you can see that basically the
00:30:14.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m14s

continuous ones are all of the ones
00:30:18.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m18s

which are actual floating-point numbers
00:30:20.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m20s

like competition distance actually has a
00:30:23.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m23s

decimal place to it right and
00:30:26.009
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m26s

temperature actually has a decimal place
00:30:27.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m27s

to it so these would be very hard to
00:30:29.759
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m29s

make
00:30:31.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m31s

categorical because they have many many
00:30:32.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m32s

levels right like if it's like five
00:30:34.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m34s

digits of floating-point then
00:30:37.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m37s

potentially there will be as many levels
00:30:39.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m39s

as there are as there are roads and by
00:30:41.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m41s

the way the word we use to say how many
00:30:46.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m46s

levels are in a category we use the word
00:30:48.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m48s

cardinality right so if you see me say
00:30:50.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m50s

cardinality example the cardinality of
00:30:52.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m52s

the day of week variable is 7 because
00:30:54.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m54s

there are 7 different days of the week
00:30:57.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h30m57s

do you have a heuristic for one to have
00:31:02.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m02s

been continuous variables or do you ever
00:31:04.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m04s

in variables I don't ever been
00:31:06.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m06s

continuous variables so yeah so one
00:31:07.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m07s

thing we could do with like max
00:31:13.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m13s

temperature is group it into nought to
00:31:14.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m14s

10 10 to 20 20 to 30 and then call that
00:31:17.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m17s

categorical interestingly a paper just
00:31:20.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m20s

came out last week in which a group of
00:31:23.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m23s

researchers found that sometimes bidding
00:31:27.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m27s

can be helpful but it literally came out
00:31:29.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m29s

in the last week and until that time I
00:31:32.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m32s

haven't seen anything in deep learning
00:31:33.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m33s

saying that so I haven't I haven't
00:31:35.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m35s

looked at it myself until this week I
00:31:37.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m37s

would have said it's a bad idea now I
00:31:39.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m39s

have to think differently I guess maybe
00:31:41.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m41s

it is sometimes so if you're using year
00:31:43.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m43s

as a category what happens when you run
00:31:52.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m52s

the model of a year it's never seen so
00:31:55.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m55s

your training will get there yeah the
00:31:57.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h31m57s

short answer is it will be treated as an
00:32:00.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m00s

unknown category and so pandas which is
00:32:03.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m03s

the underlying data frame thinking we're
00:32:06.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m06s

using with categories as a special
00:32:09.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m09s

category called unknown and if it stays
00:32:11.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m11s

a category it hasn't seen before it gets
00:32:13.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m13s

treated as unknown so for AB deep
00:32:15.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m15s

learning model unknown will just be
00:32:20.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m20s

another category
00:32:22.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m22s

if our data set training the data set
00:32:25.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m25s

doesn't have a category and test has
00:32:29.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m29s

unknown how will it did you know just
00:32:32.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m32s

paper this unknown category it's still
00:32:36.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m36s

predict it will predict something right
00:32:39.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m39s

like it will just have the value 0 barn
00:32:41.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m41s

scenes and if there's been any unknowns
00:32:44.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m44s

of any kind in the training set then it
00:32:46.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m46s

off learnt a way to predict unknown if
00:32:48.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m48s

it hasn't it's going to have some random
00:32:52.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m52s

vector and so that's a interesting
00:32:54.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m54s

detail around training that we probably
00:32:58.019
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h32m58s

want to talk about in this part of the
00:33:00.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m00s

course but we can certainly talk about
00:33:01.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m01s

on the forum
00:33:02.669
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m02s

okay so we've got our categorical and
00:33:05.529
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m05s

continuous variable lists defined in
00:33:08.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m08s

this case there was eight hundred
00:33:11.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m11s

thousand rows so eight hundred thousand
00:33:13.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m13s

dates basically by Storz and so you can
00:33:16.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m16s

now take all of these columns look
00:33:21.919
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m21s

through each one and replace it in the
00:33:26.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m26s

data frame where the version where you
00:33:29.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m29s

say take it and change its type to
00:33:31.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m31s

category okay and so that just that just
00:33:33.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m33s

a panda's things so I'm not going to
00:33:37.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m37s

teach you
00:33:39.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m39s

pandas there's plenty of books so
00:33:40.669
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m40s

particularly with McKinney's books book
00:33:42.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m42s

on python for data analysis is great but
00:33:44.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m44s

hopefully it's intuitive as to what's
00:33:48.379
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m48s

going on even if you haven't seen the
00:33:49.729
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m49s

specific syntax before so we're going to
00:33:51.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m51s

turn that column into a categorical
00:33:53.299
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m53s

column and then for the continuous
00:33:55.879
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m55s

variables we're going to make them all
00:33:58.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h33m58s

32-bit floating-point and for the reason
00:34:00.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m00s

for that is that pipe torch expects
00:34:03.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m03s

everything to be 32-bit floating-point
00:34:07.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m07s

okay so like some of these include like
00:34:09.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m09s

1 0 things like I can't see them
00:34:13.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m13s

straight away but anyway so much yeah
00:34:19.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m19s

like was there a promo was was a holiday
00:34:21.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m21s

and so that'll become the floating point
00:34:23.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m23s

values 1 and 0 for instance ok so I try
00:34:25.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m25s

to do as much of my work as possible
00:34:33.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m33s

on small data sets for when I'm working
00:34:35.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m35s

with images that generally means
00:34:39.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m39s

resizing the images to like 64 by 64 or
00:34:40.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m40s

128 by 128 we can't do that with
00:34:44.539
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m44s

structured data so instead I tend to
00:34:48.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m48s

take a sample so I randomly pick a few
00:34:49.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m49s

rows so I start running with a sample
00:34:52.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m52s

and I can use exactly the same thing
00:34:55.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m55s

that we've seen before for getting a
00:34:57.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m57s

validation set we can use the same way
00:34:59.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h34m59s

to get some random random row numbers to
00:35:01.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m01s

use in a random sample okay so this is
00:35:04.609
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m04s

just a bunch of random numbers
00:35:07.609
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m07s

and then okay so that's going to be a
00:35:13.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m13s

size 150,000 rather than 800 40,000 and
00:35:15.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m15s

so my data that before I go any further
00:35:21.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m21s

it basically looks like this you can see
00:35:23.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m23s

I've got some boolean x' here I've got
00:35:25.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m25s

some integers here of various different
00:35:28.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m28s

scales here's my year 2014 and I've got
00:35:32.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m32s

some letters here so even though I said
00:35:37.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m37s

please call that a pandas category
00:35:40.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m40s

pandas still displays that in the
00:35:43.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m43s

notebook as strings right it's just
00:35:45.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m45s

stored in internally differently so then
00:35:49.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m49s

the first day our library has a special
00:35:52.859
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m52s

little function called processed data
00:35:55.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m55s

frame and process data frame takes a
00:35:56.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m56s

data frame and you tell it what's my
00:35:59.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h35m59s

dependent variable right and it does a
00:36:02.339
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m02s

few different things the first thing is
00:36:05.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m05s

it's pulled out that dependent variable
00:36:06.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m06s

and puts it into a separate variable
00:36:08.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m08s

okay and deletes it from the original
00:36:10.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m10s

data frame so DF now does not have the
00:36:13.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m13s

sales column in where else Y just
00:36:16.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m16s

contains a sales column something else
00:36:18.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m18s

that it does is it does scaling so
00:36:22.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m22s

neural nets really like to have the
00:36:25.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m25s

input data to all be somewhere around
00:36:28.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m28s

zero with a standard deviation of
00:36:31.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m31s

somewhere around one all right so we can
00:36:33.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m33s

always take our data and subtract the
00:36:35.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m35s

mean and divide by the standard
00:36:39.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m39s

deviation to make that happen so that's
00:36:41.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m41s

what do see a littles true that's and it
00:36:43.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m43s

actually returns a special object which
00:36:46.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m46s

keeps track of what mean and standard
00:36:48.359
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m48s

deviation did it use for that
00:36:50.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m50s

normalizing so you can then do the same
00:36:51.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m51s

thing to the test set later it also
00:36:53.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m53s

handles missing values so missing values
00:36:57.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h36m57s

and categorical variables just become
00:37:01.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m01s

the ID 0 and then all the other
00:37:04.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m04s

categories become 1 2 3 4 5 4 that
00:37:07.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m07s

categorical variable for continuous
00:37:09.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m09s

variables
00:37:12.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m12s

it replaces the missing value with the
00:37:13.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m13s

median and creates a new column that's a
00:37:17.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m17s

boolean and just says is this missing or
00:37:21.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m21s

not and I'm gonna skip over this pretty
00:37:23.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m23s

quickly because we talked about this in
00:37:24.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m24s

detail
00:37:26.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m26s

the machine learning course okay so if
00:37:27.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m27s

you've got any questions about this part
00:37:29.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m29s

that would be a good place to go it's
00:37:31.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m31s

nothing deep learning specific there so
00:37:34.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m34s

you can see afterwards year 2014 for
00:37:36.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m36s

example has become year two okay because
00:37:39.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m39s

these categorical variables have all
00:37:42.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m42s

been replaced with with contiguous
00:37:43.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m43s

integers starting at zero and the reason
00:37:47.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m47s

for that is later on we're going to be
00:37:50.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m50s

putting them into a matrix right and so
00:37:52.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m52s

we wouldn't want the matrix to be 2014
00:37:55.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m55s

rows long when it could just be two rows
00:37:57.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m57s

one there so that's the basic idea there
00:37:59.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h37m59s

and you'll see that the AC for example
00:38:02.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m02s

has been replaced in the same way with
00:38:06.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m06s

one and three okay so we now have a data
00:38:08.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m08s

frame which does not contain the
00:38:13.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m13s

dependent variable and where everything
00:38:15.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m15s

is a number okay and so that's that
00:38:17.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m17s

that's where we need to get to to do
00:38:20.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m20s

deep learning and all of the stage about
00:38:21.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m21s

that as I said we talked about in detail
00:38:23.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m23s

in the machine learning course nothing
00:38:26.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m26s

deep learning specific about any of it
00:38:27.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m27s

this is exactly what we throw into our
00:38:29.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m29s

random forests as well so another thing
00:38:32.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m32s

we talk about a lot in the machine
00:38:36.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m36s

learning core of course is validation
00:38:38.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m38s

sets in this case we need to predict the
00:38:39.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m39s

next two weeks of sales right it's not
00:38:44.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m44s

like pick a random set of sales but we
00:38:47.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m47s

have to pick the next two weeks of sales
00:38:50.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m50s

that was what the cattle competition
00:38:52.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m52s

folks told us to do and therefore I'm
00:38:54.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m54s

going to create a validation set which
00:38:57.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m57s

is the last two weeks of my training set
00:38:59.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h38m59s

right to try and make it as similar to
00:39:03.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m03s

the test set as possible and we just
00:39:05.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m05s

posted actually Rachel wrote this thing
00:39:08.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m08s

last week about creating validation sets
00:39:09.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m09s

so if you go too fast at AI you can
00:39:13.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m13s

check it out we'll put that in the
00:39:15.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m15s

lesson wiki as well but it's basically a
00:39:17.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m17s

summary of a recent machine learning
00:39:20.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m20s

lesson that we did the videos are
00:39:23.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m23s

available for that as well and this is
00:39:27.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m27s

kind of a written a written summary of
00:39:28.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m28s

it okay
00:39:30.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m30s

so yeah so Rachel and I spend a lot of
00:39:35.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m35s

time thinking about kind of you know how
00:39:38.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m38s

do you need to think about validation
00:39:40.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m40s

sets and training sets and test sets and
00:39:41.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m41s

so forth and that's all there but again
00:39:43.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m43s

nothing deep learning specific so let's
00:39:46.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m46s

get straight to the deep learning action
00:39:48.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m48s

okay so in this particular competition
00:39:50.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m50s

as always with any competition or any
00:39:55.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m55s

kind of machine learning project you
00:39:58.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h39m58s

really need to make sure you have a
00:40:01.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m01s

strong understanding of your metric how
00:40:02.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m02s

are you going to be judged here and in
00:40:06.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m06s

this case you know Carol makes it easy
00:40:08.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m08s

they tell us how we're going to be
00:40:09.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m09s

judged and so we're going to be judged
00:40:10.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m10s

on the roots mean squared percentage
00:40:12.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m12s

error right so we're gonna say like oh
00:40:14.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m14s

you predicted three it was actually
00:40:17.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m17s

three point three so you were can sent
00:40:21.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m21s

out and then we're gonna average all
00:40:24.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m24s

those percents right and remember I
00:40:25.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m25s

warned you that you are gonna need to
00:40:28.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m28s

make sure you know logarithms really
00:40:33.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m33s

well right and so in this case from you
00:40:35.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m35s

know we're basically being saying your
00:40:37.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m37s

prediction divided by the actual the
00:40:40.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m40s

mean of that right is the thing that we
00:40:43.359
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m43s

care about and so we don't have a metric
00:40:46.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m46s

in play torch called root mean squared
00:40:52.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m52s

percent error we could actually easily
00:40:54.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m54s

create it by the way if you look at the
00:40:56.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m56s

source code you'll see like it's you
00:40:59.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h40m59s

know a line of code but easiest deal
00:41:01.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m01s

would be to realize that that if you
00:41:03.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m03s

have that right then you could replace a
00:41:08.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m08s

with like log of a dash and be with like
00:41:12.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m12s

log of B dash and then you can replace
00:41:16.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m16s

that whole thing with a subtraction
00:41:19.359
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m19s

that's just the rule of loaves right and
00:41:22.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m22s

so if you don't know that rule then
00:41:26.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m26s

don't make sure you go look it up
00:41:28.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m28s

because it's super helpful but it means
00:41:30.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m30s

in this case all we need to do is to
00:41:32.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m32s

take the log of our data which I
00:41:35.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m35s

actually did earlier in this notebook
00:41:39.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m39s

and when you take the log of the data
00:41:42.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m42s

getting the root mean squared error will
00:41:44.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m44s

actually get you there
00:41:46.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m46s

means great percent error for free okay
00:41:47.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m47s

but then when we want to like print out
00:41:50.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m50s

our it means percent error we actually
00:41:53.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m53s

have to go e ^ it again right and then
00:41:56.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h41m56s

we can actually return the percent
00:42:00.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m00s

difference so that's all that's going on
00:42:02.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m02s

here it's again not really deep learning
00:42:04.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m04s

specific at all so here we finally get
00:42:06.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m06s

to the deep learning alright so as per
00:42:11.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m11s

usual like you'll see everything we look
00:42:14.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m14s

at today looks exactly the same as
00:42:16.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m16s

everything we've looked at so far which
00:42:18.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m18s

is first we create a model data object
00:42:20.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m20s

something that has a validation set
00:42:22.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m22s

training set and optional test set built
00:42:25.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m25s

into it from that we will get a learner
00:42:28.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m28s

we will then optionally called learner
00:42:30.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m30s

dot LR find real then called learner dot
00:42:33.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m33s

fetch it'll be all the same parameters
00:42:37.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m37s

and everything that you've seen many
00:42:39.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m39s

times before okay so the difference
00:42:41.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m41s

though is obviously we're not going to
00:42:43.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m43s

go image classify a data dot from CSV or
00:42:45.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m45s

dot from paths we need to get some
00:42:50.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m50s

different kind of model data and so for
00:42:52.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m52s

stuff that is in rows and columns we use
00:42:55.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m55s

columnar model data but this will return
00:42:57.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h42m57s

an object with basically the same API
00:43:00.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m00s

that you're familiar with and rather
00:43:02.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m02s

than from paths or from CSV this is from
00:43:05.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m05s

data frame okay so this gets passed a
00:43:09.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m09s

few things the path here is just used
00:43:12.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m12s

for it to know where should it store
00:43:15.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m15s

like model files or stuff like that
00:43:17.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m17s

right this is just basically saying
00:43:20.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m20s

where do you want to store anything that
00:43:22.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m22s

you saved later this is the list of the
00:43:23.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m23s

indexes of the rows that we want to put
00:43:27.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m27s

in the validation set we created earlier
00:43:29.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m29s

here's our data frame okay and then look
00:43:31.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m31s

here's this is where we did the log
00:43:39.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m39s

right so I took the the Y that came out
00:43:41.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m41s

of property F our dependent variable I
00:43:44.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m44s

logged it and I call that yl all right
00:43:46.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m46s

so we tell it when we create our model
00:43:49.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m49s

data we need to tell it that's our
00:43:52.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m52s

dependent variable okay so so far we've
00:43:53.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m53s

got most of the stuff from the
00:43:56.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m56s

validation set which is what's our
00:43:57.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m57s

independent variables
00:43:59.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h43m59s

how dependent variables and then we have
00:44:01.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m01s

to tell it which things do we want
00:44:03.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m03s

traded as categorical right because
00:44:05.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m05s

remember by this time everything's a
00:44:08.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m08s

number
00:44:13.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m13s

right so it could do the whole things
00:44:15.299
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m15s

it's continuous it would just be totally
00:44:17.999
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m17s

meaningless right so we need to tell it
00:44:19.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m19s

which things do we want to treat as
00:44:22.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m22s

categories and so here we just pass in
00:44:24.239
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m24s

that list of names that we used before
00:44:26.729
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m26s

okay and then a bunch of the parameters
00:44:30.469
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m30s

are the same as the ones you're used to
00:44:33.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m33s

for example you can set the batch size
00:44:35.969
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m35s

yeah so after we do that we've got a
00:44:37.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m37s

little standard model data object but
00:44:43.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m43s

there's a trained DL attribute there's a
00:44:46.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m46s

Val DL attribute a trained es attribute
00:44:49.979
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m49s

of LDS attribute it's got a length it's
00:44:52.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m52s

got all the stuff exactly like it did in
00:44:55.259
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m55s

all of our image based data objects okay
00:44:57.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h44m57s

so now we need to create the the model
00:45:04.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m04s

or create the learner and so to skip
00:45:06.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m06s

ahead a little bit we're basically going
00:45:09.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m09s

to pass in something that looks pretty
00:45:12.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m12s

familiar we're going to be passing thing
00:45:14.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m14s

from our model from our model data
00:45:16.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m16s

create a learner that is suitable for it
00:45:18.709
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m18s

and will basically be passing in a few
00:45:21.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m21s

other bits of information which will
00:45:24.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m24s

include how much dropout to use at the
00:45:26.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m26s

very start how many how many activations
00:45:29.459
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m29s

to have in each layer
00:45:33.689
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m33s

how much dropout to use at the later
00:45:34.799
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m34s

layers but then there's a couple of
00:45:37.889
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m37s

extra things that we need to learn about
00:45:40.529
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m40s

and specifically it's this thing called
00:45:41.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m41s

embeddings so this is really the key new
00:45:44.689
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m44s

concept we have to learn about all right
00:45:50.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m50s

so all we're doing basically is we're
00:45:53.519
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m53s

going to take our let's forget about
00:45:58.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h45m58s

categorical variables for a moment and
00:46:02.249
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m02s

just think about the continuous
00:46:04.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m04s

variables for our continuous variables
00:46:05.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m05s

all we're going to do is we're going to
00:46:08.699
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m08s

grab them all
00:46:11.759
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m11s

okay so for our continuous variables
00:46:16.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m16s

we're basically going to say like okay
00:46:18.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m18s

here's a big list of all of our
00:46:20.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m20s

continuous variables like the minimum
00:46:23.799
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m23s

temperature and the maximum temperature
00:46:25.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m25s

and the distance to the nearest
00:46:27.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m27s

competitor and so forth right and so
00:46:29.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m29s

here's just a bunch of floating-point
00:46:32.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m32s

numbers and so basically what the neuron
00:46:34.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m34s

that's going to do is going to take that
00:46:36.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m36s

that 1d array or or vector or to be very
00:46:38.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m38s

DL like rank one tensor or means the
00:46:44.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m44s

same thing
00:46:49.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m49s

okay so we're going to take our egg one
00:46:49.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m49s

tensor and let's put it through a matrix
00:46:51.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m51s

multiplication so let's say this has got
00:46:54.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m54s

like I don't know 20 continuous
00:46:56.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m56s

variables and then we can put it through
00:46:59.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h46m59s

a matrix which must have 20 rows that's
00:47:01.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m01s

how matrix multiplication works and then
00:47:05.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m05s

we can decide how many columns we want
00:47:07.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m07s

right so maybe we decided 100 right and
00:47:09.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m09s

so that matrix model captions going to
00:47:12.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m12s

spit out a new length 100 rank 1 tensor
00:47:14.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m14s

okay
00:47:20.339
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m20s

that's that's what that's what a linear
00:47:21.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m21s

that's what a matrix product does and
00:47:23.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m23s

that's the definition of a linear layer
00:47:26.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m26s

indeed what okay and so then the next
00:47:28.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m28s

thing we do is we can put that through a
00:47:32.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m32s

rail you right which means we throw away
00:47:34.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m34s

the negatives okay and now we can put
00:47:36.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m36s

that through another matrix product okay
00:47:39.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m39s

so this is going to have to have a
00:47:42.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m42s

hundred rows by definition and we can
00:47:43.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m43s

have as many columns as we like and so
00:47:47.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m47s

let's say maybe this was the last layer
00:47:49.089
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m49s

so the next thing we're trying to do is
00:47:51.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m51s

to predict sales so there's just one
00:47:53.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m53s

value we're trying to predict for sales
00:47:57.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m57s

so we could put it through a matrix
00:47:59.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h47m59s

product that just had one column and
00:48:01.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m01s

that's going to spit out a single number
00:48:02.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m02s

all right so that's like that's kind of
00:48:05.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m05s

like a one layer neural net if you like
00:48:09.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m09s

now in practice you know we wouldn't
00:48:14.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m14s

make it one layer so we would actually
00:48:17.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m17s

have leg
00:48:19.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m19s

you know maybe we'd have 50 here and so
00:48:23.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m23s

then that gives us a 50 long vector and
00:48:26.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m26s

then maybe we then put that into our
00:48:30.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m30s

final 50 by one and that's if it's out a
00:48:34.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m34s

single number and one reason I would
00:48:40.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m40s

have to change that there was to point
00:48:42.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m42s

out you know rally you would never put
00:48:43.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m43s

rally you in the last layer
00:48:46.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m46s

I could never want to throw away the
00:48:48.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m48s

negatives because that the softmax let's
00:48:49.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m49s

go back to the softness the soft max
00:48:54.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m54s

needs negatives in it because it's the
00:48:56.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m56s

negatives that are the things that allow
00:48:59.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h48m59s

it to create low probabilities that's
00:49:00.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m00s

minor detail but it's useful to remember
00:49:04.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m04s

okay so basically
00:49:06.119
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m06s

so basically a simple view of a fully
00:49:13.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m13s

connected euro net is something that
00:49:19.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m19s

takes in as an input a rank one tensor
00:49:22.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m22s

it's bits it's through a linear layer an
00:49:26.529
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m26s

activation layer another linear layer
00:49:31.119
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m31s

softmax and that's the output okay and
00:49:36.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m36s

so we could obviously decide to add more
00:49:43.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m43s

linear layers we could decide maybe to
00:49:46.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m46s

add dropout all right so these are some
00:49:50.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m50s

of the decisions that we need we get to
00:49:53.509
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m53s

make right but we there's not that much
00:49:55.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m55s

we can do right there's not much really
00:49:58.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m58s

crazy architecture stuff to do so when
00:49:59.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h49m59s

we come back to image models later in
00:50:02.839
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m02s

the course we're going to learn about
00:50:06.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m06s

all the weird things that go on and like
00:50:07.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m07s

resonates and inception networks and but
00:50:09.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m09s

in these fully connected networks
00:50:12.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m12s

they're really pretty simple they're
00:50:14.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m14s

just in dispersed
00:50:15.799
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m15s

linear layers that is matrix products
00:50:17.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m17s

and activation functions like value and
00:50:19.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m19s

a soft mix at the edge and if it's not
00:50:23.089
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m23s

classification which actually ours is
00:50:27.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m27s

not classification in this case we're
00:50:29.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m29s

trying to predict sales there isn't even
00:50:30.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m30s

a soft mix right we don't want it to be
00:50:33.259
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m33s

between 0 and 1 ok so we can just throw
00:50:35.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m35s

away the last activation altogether if
00:50:39.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m39s

we have time we can talk about a slight
00:50:43.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m43s

trick we can do there but for now we can
00:50:45.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m45s

think of it that way so that was all
00:50:48.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m48s

assuming that everything was continuous
00:50:51.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m51s

right but what about categorical right
00:50:53.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m53s

so we've got like day of week right and
00:50:56.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h50m56s

we're going to treat it as categorical
00:51:04.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m04s

practice like Saturday Sunday Monday
00:51:06.019
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m06s

that should be 6
00:51:11.259
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m11s

ready okay how do we feed that in
00:51:15.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m15s

because I want to find a way of getting
00:51:19.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m19s

that in so that we still end up with a
00:51:21.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m21s

wreck one tends to refloat and so the
00:51:22.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m22s

trick is this we create a new little
00:51:26.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m26s

matrix of with seven rows and as many
00:51:28.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m28s

columns as we choose right so let's pick
00:51:35.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m35s

four all right so here's our seven rows
00:51:38.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m38s

and four columns right and basically
00:51:43.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m43s

what we do is let's add our categorical
00:51:48.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m48s

variables to the end so let's say the
00:51:52.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m52s

first row was Sunday right then what we
00:51:53.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m53s

do is we do a lookup into this matrix we
00:51:57.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h51m57s

say oh here's sunday we do and look up
00:52:00.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m00s

into here and we grab this row and so
00:52:02.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m02s

this matrix we basically fill with
00:52:06.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m06s

floating-point numbers so we're going to
00:52:08.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m08s

end up grabbing little subset of for
00:52:10.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m10s

floating-point numbers at Sunday's
00:52:15.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m15s

particular for floating-point numbers
00:52:18.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m18s

and so that way we convert Sunday into a
00:52:20.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m20s

rank 1 tensor of for floating-point
00:52:26.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m26s

numbers and initially those four numbers
00:52:29.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m29s

are random all right and in fact this
00:52:31.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m31s

whole thing we initially start out
00:52:34.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m34s

random okay but then we're going to put
00:52:37.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m37s

that through our neural net right so we
00:52:41.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m41s

basically then take those four numbers
00:52:44.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m44s

and we remove sunday instead we add our
00:52:46.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m46s

four numbers on here right so we've
00:52:50.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m50s

turned our categorical thing into a
00:52:52.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m52s

floating-point vector and so now we can
00:52:54.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m54s

just put that throughout neural net just
00:52:58.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h52m58s

like before and at the very end we found
00:53:01.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m01s

out the loss and then we can figure out
00:53:03.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m03s

which direction is down and do gradient
00:53:05.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m05s

descent in that direction and eventually
00:53:09.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m09s

that will find its way back to this
00:53:11.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m11s

little list of four numbers and it'll
00:53:13.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m13s

say okay those random numbers weren't
00:53:16.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m16s

very good this one needs to go up a bit
00:53:18.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m18s

that one is to go up a bit that one is
00:53:20.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m20s

to go down a bit that one is to go up a
00:53:21.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m21s

bit and so will actually update our
00:53:23.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m23s

original those four numbers in that
00:53:26.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m26s

match
00:53:28.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m28s

and we'll do this again and again and
00:53:29.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m29s

again and so this this matrix will stop
00:53:31.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m31s

looking random and it will start looking
00:53:34.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m34s

more and more like like the exact four
00:53:36.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m36s

numbers that happen to work best for
00:53:38.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m38s

Sunday the exact four numbers that
00:53:40.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m40s

happen to work best for Friday and so
00:53:42.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m42s

forth
00:53:44.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m44s

and so in other words this matrix is
00:53:45.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m45s

just another bunch of weights in our
00:53:48.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m48s

neural net all right and so matrices of
00:53:52.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m52s

this type are called embedding matrices
00:53:56.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h53m56s

so an embedding matrix is something
00:54:03.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m03s

where we start out with an integer
00:54:06.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m06s

between zero and the maximum number of
00:54:10.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m10s

levels of that category we literally
00:54:13.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m13s

index into a matrix to find a particular
00:54:17.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m17s

row so if it was the level was one we
00:54:20.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m20s

take the first row we grab that road and
00:54:23.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m23s

we append it to all of our continuous
00:54:27.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m27s

variables and so we now have a new
00:54:30.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m30s

vector of continuous variables and when
00:54:34.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m34s

we can do the same thing so let's say
00:54:37.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m37s

zip code right so we could like have an
00:54:39.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m39s

embedding matrix let's say there are
00:54:41.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m41s

5,000 zip codes it would be 5,000 rows
00:54:44.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m44s

long as wide as we decide maybe it's 50
00:54:46.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m46s

wide and so we'd say ok here's 9 4 0 0 3
00:54:49.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m49s

that zip code is index number 4 you know
00:54:55.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m55s

matrix ordered out and we'd find the
00:54:58.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m58s

fourth row regret those 50 numbers and
00:54:59.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h54m59s

append those on to our big vector and
00:55:02.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m02s

then everything after that is just the
00:55:05.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m05s

same we just put it through our linear
00:55:07.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m07s

layer a linear layer whatever what are
00:55:08.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m08s

those 4 numbers represent that's a great
00:55:13.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m13s

question and we'll learn more about that
00:55:16.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m16s

when we look at collaborative filtering
00:55:19.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m19s

but now they represent no more or no
00:55:20.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m20s

less than any other parameter in a
00:55:24.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m24s

neural net you know they're just they're
00:55:26.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m26s

just parameters that we're learning that
00:55:30.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m30s

happen to end up giving us a good loss
00:55:32.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m32s

we will discover later that these
00:55:35.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m35s

particular parameters often however are
00:55:37.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m37s

human interpretive all and quote can
00:55:39.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m39s

quite interesting but that's a side
00:55:41.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m41s

effect of them it's not fundamental
00:55:44.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m44s

they're just for random numbers for now
00:55:47.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m47s

that we're that we're learning or sets
00:55:49.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m49s

of four random numbers to have a good
00:55:52.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m52s

heuristic for at the dimensionality of
00:55:57.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m57s

embedding matrix so why four here I sure
00:55:59.359
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h55m59s

do so what I first of all did was I made
00:56:03.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m03s

a little list of every categorical
00:56:12.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m12s

variable and its cardinality okay so
00:56:15.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m15s

they're they allow so there's a hundred
00:56:19.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m19s

and there's a thousand plus different
00:56:20.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m20s

stores
00:56:22.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m22s

apparently in Rothman's Network
00:56:24.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m24s

there are eight days of the week that's
00:56:27.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m27s

because there are seven days of the week
00:56:29.089
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m29s

plus one left over for unknown even if
00:56:30.319
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m30s

there were no missing values in the
00:56:33.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m33s

original data I always still set aside
00:56:35.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m35s

one just in case there's a missing or an
00:56:37.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m37s

unknown or something different in the
00:56:39.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m39s

test set again for years but there's
00:56:41.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m41s

actually three plus room for an unknown
00:56:44.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m44s

and so forth right so what I do my rule
00:56:46.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m46s

of thumb is this take the cardinality
00:56:51.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m51s

with the variable divide it by two but
00:56:55.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h56m55s

don't make it bigger than 50 okay so
00:57:00.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m00s

these are my embedding matrices so my
00:57:04.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m04s

store matrix so there has to have a
00:57:06.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m06s

thousand one hundred and sixteen rows
00:57:10.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m10s

cuz I need to look up right to find his
00:57:12.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m12s

store number three and then it's been a
00:57:15.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m15s

return back a rank one tensor of length
00:57:17.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m17s

fifty day of week it's going to look up
00:57:20.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m20s

into which one of the eight and
00:57:23.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m23s

returning the thing of length four so
00:57:25.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m25s

what you typically build on embedding
00:57:31.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m31s

metrics for each categorical feature yes
00:57:33.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m33s

yeah so that's what I've done here so
00:57:36.279
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m36s

I've said for see in categorical
00:57:38.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m38s

variables see how many categories there
00:57:43.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m43s

are and then for each of those things
00:57:47.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m47s

create one of these and then this is
00:57:53.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m53s

called embedding sizes and then you may
00:57:56.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m56s

have noticed that that's actually the
00:57:59.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h57m59s

first thing that we pass to get learner
00:58:01.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m01s

and so that tells it for every
00:58:03.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m03s

categorical variable that's the
00:58:05.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m05s

embedding matrix to use for that
00:58:07.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m07s

variable that is behind you listen
00:58:08.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m08s

yes traffic aggression so besides our
00:58:11.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m11s

random initialization and there are
00:58:16.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m16s

other ways to actually initialize
00:58:19.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m19s

embedding yes or no there's two ways one
00:58:20.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m20s

is random
00:58:25.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m25s

the other is pre-trained and we'll
00:58:26.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m26s

probably talk about pre-trained more
00:58:29.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m29s

later in the course but the basic idea
00:58:31.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m31s

though is if somebody else at Rossmann
00:58:33.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m33s

had already trained a neural net just
00:58:35.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m35s

like you you would use a pre trained net
00:58:37.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m37s

from imagenet to look at pictures of
00:58:39.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m39s

cats and dogs if somebody else is
00:58:41.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m41s

pre-trained a network to predict cheese
00:58:43.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m43s

sales in ruspin you may as well start
00:58:45.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m45s

with their embedding matrix of stores to
00:58:48.589
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m48s

predict liquor sales in Rossmann and
00:58:50.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m50s

this is what happens for example at
00:58:53.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m53s

Pinterest and Institute they both use
00:58:56.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m56s

this technique instacart uses it for
00:58:59.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h58m59s

routing their shoppers Pinterest uses it
00:59:02.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m02s

for deciding what to display on a web
00:59:04.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m04s

page when you go there and they have
00:59:06.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m06s

embedding matrices of products in
00:59:09.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m09s

instigates case of stores that get
00:59:12.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m12s

shared in the organization so people
00:59:15.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m15s

don't have to train you once
00:59:18.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m18s

so for the embedding sighs why wouldn't
00:59:23.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m23s

you just use like open hot scheme and
00:59:28.339
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m28s

just well what is the advantage of doing
00:59:31.039
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m31s

this they're supposed to just do it well
00:59:33.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m33s

good question so so we could easily as
00:59:36.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m36s

you point out have instead of passing in
00:59:39.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m39s

these four numbers record instead of
00:59:43.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m43s

passed in seven numbers all zeroes but
00:59:46.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m46s

one of them is one and that also is a
00:59:50.359
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m50s

list of floats and that would totally
00:59:52.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m52s

work and that's how generally speaking
00:59:55.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=00h59m55s

categorical variables have been used in
01:00:00.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m00s

statistics for many years it's called
01:00:03.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m03s

dummy variables the problem is that in
01:00:05.299
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m05s

that case the concept of sundae could
01:00:09.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m09s

only ever be associated with a single
01:00:13.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m13s

floating-point number right and so it
01:00:15.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m15s

basically gets this kind of linear
01:00:19.549
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m19s

behavior it says like sunday is more or
01:00:21.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m21s

less of a single thing yeah worth
01:00:24.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m24s

noticing directions it's saying like now
01:00:27.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m27s

sunday is a concept in four dimensional
01:00:29.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m29s

space right and so what we tend to find
01:00:31.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m31s

happen is that these embedding vectors
01:00:34.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m34s

tend to get these kind of rich semantic
01:00:38.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m38s

concepts so for example if it turns out
01:00:42.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m42s

that weekends kind of have a different
01:00:45.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m45s

behavior you'll tend to see that
01:00:50.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m50s

Saturday and Sunday will have like some
01:00:52.309
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m52s

particular number higher or more likely
01:00:54.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m54s

it turns out that certain days of the
01:00:57.349
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m57s

week are associated with higher sales of
01:00:59.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h00m59s

certain kinds of goods that you kind of
01:01:06.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m06s

can't go without I don't know like gas
01:01:09.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m09s

or milk see where else there might be
01:01:11.029
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m11s

other products like like wine for
01:01:14.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m14s

example like wine that tend to be
01:01:18.799
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m18s

associated with like the days before
01:01:23.779
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m23s

weekends or holidays right so there
01:01:26.029
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m26s

might be kind of a column which is like
01:01:28.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m28s

to what extent is this day of the week
01:01:31.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m31s

kind of associated with people going out
01:01:35.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m35s

you know so basically yeah by by having
01:01:37.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m37s

this higher dimensionality dektor rather
01:01:41.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m41s

than just a single number it gives the
01:01:44.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m44s

deep Learning Network a chance to learn
01:01:46.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m46s

these rich representations and so this
01:01:49.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m49s

idea of an embedding is actually what's
01:01:53.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m53s

called a distributed representation it's
01:01:56.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m56s

kind of the fun most fundamental concept
01:01:58.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h01m58s

of neural networks this is the idea that
01:02:01.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m01s

a concept in a neural network has a kind
01:02:03.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m03s

of a a high dimensional representation
01:02:06.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m06s

and often it can be hard to interpret
01:02:10.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m10s

because the idea is like each of these
01:02:12.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m12s

numbers in this vector doesn't even have
01:02:14.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m14s

to have just one meaning you know it
01:02:17.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m17s

could mean one thing if this is low and
01:02:19.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m19s

that one's high and something else if
01:02:21.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m21s

that one's high and that one's low
01:02:22.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m22s

because it's going through this kind of
01:02:23.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m23s

rich nonlinear function right and so
01:02:25.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m25s

it's this it's this rich representation
01:02:29.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m29s

that allows it to learn such such such
01:02:33.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m33s

interesting relationships I'm kind of oh
01:02:36.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m36s

another question sure I'll speak louder
01:02:41.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m41s

so are there he's in a meeting so I get
01:02:44.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m44s

the the fundamental of be like the word
01:02:50.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m50s

vector were to Vic vector algebra even
01:02:52.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m52s

run on this thing are the embedding
01:02:55.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m55s

suited suitable for certain types of
01:02:57.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h02m57s

variables like or are these only
01:03:00.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m00s

suitable for there are different
01:03:02.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m02s

categories that that the embeddings are
01:03:05.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m05s

suitable for an embedding is suitable
01:03:07.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m07s

for any categorical variable okay so so
01:03:09.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m09s

the only thing it it can't really work
01:03:13.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m13s

well at all four would be something that
01:03:16.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m16s

is too high cardinality so I'm like in
01:03:18.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m18s

other words we had like whatever it was
01:03:20.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m20s

six hundred thousand rows if you had a
01:03:22.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m22s

variable with six hundred thousand
01:03:24.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m24s

levels that's just not a useful
01:03:26.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m26s

categorical variable you could packetize
01:03:29.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m29s

it I guess but yeah in general like you
01:03:33.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m33s

can see here that the the third place
01:03:36.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m36s

getters in this competition really
01:03:38.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m38s

decided that everything that was not too
01:03:41.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m41s

high cardinality they put them all as
01:03:45.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m45s

categorical very
01:03:47.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m47s

and I think that's a good rule of thumb
01:03:47.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m47s

you know if you can make a categorical
01:03:49.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m49s

variable you may as well because that
01:03:51.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m51s

way it can learn this rich distributed
01:03:54.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m54s

representation where else if you leave
01:03:56.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m56s

it as continuous you know the most it
01:03:58.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h03m58s

can do is to kind of try and find a know
01:04:00.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m00s

a single functional form that fits it
01:04:03.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m03s

well after question so you were saying
01:04:05.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m05s

that you are kind of increasing the
01:04:10.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m10s

dimension but actually in most cases we
01:04:12.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m12s

will use a one holding column which has
01:04:15.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m15s

even a bigger dimension that so in a way
01:04:18.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m18s

you are also reducing but in the most
01:04:22.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m22s

reach I think that's very good yeah it
01:04:24.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m24s

like yes you know you can figure this
01:04:27.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m27s

one hot encoding which actually is high
01:04:31.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m31s

dimensional but it's not meaningfully
01:04:33.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m33s

high dimensional because everything set
01:04:36.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m36s

one is easy right I'm saying that also
01:04:37.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m37s

because even this will reduce the amount
01:04:39.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m39s

of memory and things like this that you
01:04:41.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m41s

have to write you're absolutely right
01:04:43.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m43s

and and so we may as well go ahead and
01:04:46.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m46s

actually destroyed like what's going on
01:04:49.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m49s

with the matrix algebra behind the
01:04:51.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m51s

scenes see this if this doesn't quite
01:04:52.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m52s

make sense you can kind of skip over it
01:04:54.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m54s

but for some people I know this really
01:04:56.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m56s

helps if we started out with something
01:04:58.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h04m58s

saying this is Sunday right we could
01:05:01.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m01s

represent this as a one hot encoded
01:05:06.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m06s

vector right and so Sunday you know
01:05:08.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m08s

maybe was position here so that would be
01:05:12.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m12s

a 1 and then the rest of zeros okay and
01:05:15.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m15s

then we've got our embedding matrix
01:05:19.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m19s

right with eight rows and in this case
01:05:23.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m23s

four columns
01:05:27.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m27s

one way to think of this actually is a
01:05:32.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m32s

matrix product right so I said you could
01:05:35.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m35s

think of this as like looking up the
01:05:38.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m38s

number one you know and finding like its
01:05:40.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m40s

index in the array but if you think
01:05:43.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m43s

about it that's actually identical to
01:05:46.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m46s

doing a matrix product between a one-pot
01:05:49.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m49s

encoded vector and the embedding matrix
01:05:51.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m51s

like you're going to go zero times this
01:05:54.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m54s

row one times this row zero times this
01:05:58.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h05m58s

row and so it's like a one hot embedding
01:06:01.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m01s

matrix product is identical to during
01:06:04.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m04s

the lookup and so some people in the bad
01:06:08.569
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m08s

old days actually implemented embedding
01:06:13.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m13s

matrices by doing a one hot encoding and
01:06:15.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m15s

then a matrix product and in fact a lot
01:06:18.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m18s

of like machine learning methods still
01:06:21.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m21s

kind of do that but as you know that was
01:06:23.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m23s

kind of alluding to it's that's terribly
01:06:27.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m27s

inefficient so all of the modern
01:06:29.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m29s

libraries implement this as taking take
01:06:31.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m31s

an integer and do a lookup into an array
01:06:34.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m34s

but the nice thing about realizing that
01:06:37.069
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m37s

is actually a matrix product
01:06:39.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m39s

mathematically is it makes it more
01:06:40.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m40s

obvious how the gradients are going to
01:06:42.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m42s

flow so when we do stochastic gradient
01:06:45.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m45s

descent it's we can think of it as just
01:06:46.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m46s

another linear layer okay does it say
01:06:49.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m49s

that's like somewhat minor detail but
01:06:52.819
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m52s

hopefully for some of you it helps could
01:06:55.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m55s

you touch on using dates and times this
01:06:59.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h06m59s

category course and how that affects
01:07:02.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m02s

seasonality yeah absolutely that's a
01:07:03.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m03s

great question did I cover dates it all
01:07:06.049
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m06s

remember no okay so I cover dates in a
01:07:09.109
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m09s

lot of detail in the machine learning
01:07:15.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m15s

course but it's worth briefly mentioning
01:07:16.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m16s

here there's a fast AI function called
01:07:18.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m18s

add date part which takes a data frame
01:07:26.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m26s

and column in that column name needs to
01:07:29.779
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m29s

be a date it removes unless you squat
01:07:33.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m33s

drop equals false it optionally removes
01:07:36.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m36s

the column from the data frame and
01:07:39.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m39s

replaces it with lots of column
01:07:41.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m41s

representing all of the useful
01:07:43.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m43s

information about that date like day of
01:07:45.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m45s

week day of month month of year year is
01:07:48.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m48s

at the start of the quarter is at the
01:07:51.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m51s

end of the quarter basically everything
01:07:52.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m52s

that pandas gives us and so that way we
01:07:54.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m54s

end up when we look at our list of
01:07:59.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h07m59s

features where you can see them here
01:08:03.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m03s

right yeah month week data etc so these
01:08:04.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m04s

all get created for us by a date pad so
01:08:08.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m08s

we end up with you know this eight long
01:08:13.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m13s

embedding matrix so I guess eight rows
01:08:19.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m19s

by four column embedding matrix for day
01:08:23.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m23s

of week and conceptually that allows us
01:08:26.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m26s

or allows our model to create some
01:08:29.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m29s

pretty interesting time series models
01:08:32.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m32s

all right like it can if there's
01:08:34.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m34s

something that has a seven day period
01:08:36.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m36s

cycle that kind of goes up on Mondays
01:08:40.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m40s

and down on Wednesdays but only for
01:08:43.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m43s

dairy and only in Berlin it can totally
01:08:45.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m45s

do that but it has all the information
01:08:48.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m48s

it needs to do that so this turns out to
01:08:50.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m50s

be a really fantastic way to deal with
01:08:54.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m54s

time series so I'm really glad you asked
01:08:57.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m57s

the question you just need to make sure
01:08:59.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h08m59s

that that the the cycle indicator in
01:09:01.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m01s

your time series exists as a column so
01:09:05.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m05s

if you didn't have a column there called
01:09:08.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m08s

day of week it would be very very
01:09:10.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m10s

difficult for the neural network to
01:09:12.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m12s

somehow learn to do like a divide mod
01:09:15.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m15s

seven and then somehow look that up in
01:09:18.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m18s

an omitting matrix like it not
01:09:20.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m20s

impossible but really hard it would use
01:09:22.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m22s

lots of computation wouldn't do it very
01:09:25.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m25s

well
01:09:26.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m26s

so an example of the kind of thing that
01:09:27.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m27s

you need to think about might be
01:09:29.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m29s

holidays for example you know or if you
01:09:33.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m33s

are doing something in you know sales of
01:09:36.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m36s

beverages in San Francisco you probably
01:09:39.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m39s

want a list of like when weather that
01:09:42.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m42s

when is the ball game on at AT&amp;T Park
01:09:44.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m44s

because that's going to impact how many
01:09:47.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m47s

people that are drinking beer in Soma
01:09:49.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m49s

right so you need to make sure that the
01:09:51.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m51s

kind of the basic indicators or
01:09:54.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m54s

or periodicity x' or whatever there and
01:09:57.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m57s

your data and as long as they are the
01:09:59.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h09m59s

neuron it's going to learn to use them
01:10:01.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m01s

so I'm kind of trying to skip over some
01:10:03.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m03s

of the non deep learning parts alright
01:10:06.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m06s

so the key thing here is that we've got
01:10:12.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m12s

our model data that came from the data
01:10:15.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m15s

frame we tell it how big to make the
01:10:17.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m17s

embedding matrices we also have to
01:10:19.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m19s

tailor of the columns in that data frame
01:10:23.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m23s

how many of those categorical variables
01:10:26.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m26s

or how many of them are continuous
01:10:30.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m30s

variables so the actual parameter is
01:10:32.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m32s

number of continuous variables so you
01:10:34.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m34s

can here you can see we just pass in how
01:10:37.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m37s

many columns are there - how many
01:10:39.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m39s

categorical variables are there so then
01:10:41.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m41s

that way the the neural net knows how to
01:10:43.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m43s

create something that puts the
01:10:47.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m47s

continuous variables over here and the
01:10:49.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m49s

categorical variables over there the
01:10:51.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m51s

embedding matrix has its own drop out
01:10:55.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m55s

alright so this is the dropout to apply
01:10:57.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h10m57s

to the embedding matrix this is the
01:11:00.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m00s

number of activations in the first
01:11:02.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m02s

linear player the number of activations
01:11:04.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m04s

in the second linear layer the dropout
01:11:06.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m06s

in the first linear player the drop out
01:11:08.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m08s

for the second linear layer this bit we
01:11:10.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m10s

won't worry about for now and then
01:11:12.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m12s

finally is how many outputs do we want
01:11:14.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m14s

to create okay so this is the output of
01:11:16.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m16s

the last mini layer and obviously it's
01:11:19.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m19s

one because we want to predict a single
01:11:20.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m20s

number which is sales okay so after that
01:11:22.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m22s

we now have a learner where we can call
01:11:28.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m28s

LR find and we get the standard looking
01:11:30.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m30s

shape and we can say what amount do we
01:11:32.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m32s

want to use and we can then go ahead and
01:11:35.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m35s

start training using exactly the same
01:11:39.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m39s

API we've seen before so this is all
01:11:41.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m41s

identical you can pass in I'm not sure
01:11:45.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m45s

if you've seen this before custom
01:11:49.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m49s

metrics what this does is it just says
01:11:51.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m51s

please print out a number at the end of
01:11:54.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m54s

every epoch by calling this function
01:11:56.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m56s

this is a function we defined a little
01:11:58.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h11m58s

bit earlier which was the root means
01:12:01.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m01s

bread percentage error first of all
01:12:03.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m03s

going either the power of our sales
01:12:05.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m05s

because our sales were
01:12:08.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m08s

originally logged so this doesn't change
01:12:10.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m10s

the training at all it just it's just
01:12:12.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m12s

something to print out so we trained
01:12:15.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m15s

that for a while and you know we've got
01:12:18.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m18s

some benefits that the original people
01:12:22.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m22s

that built this don't have specifically
01:12:25.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m25s

we've got things like cyclic all muscle
01:12:28.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m28s

learning rate stochastic gradient
01:12:31.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m31s

descent with restarts and so it's
01:12:33.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m33s

actually interesting to have a look and
01:12:35.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m35s

compare although our validation set
01:12:37.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m37s

isn't identical to the test set it's
01:12:42.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m42s

very similar it's a two-week period that
01:12:45.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m45s

is at the end of the training data and
01:12:47.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m47s

so our numbers should be similar and if
01:12:49.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m49s

we look at what we get point oh nine
01:12:52.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m52s

seven and compare that to the
01:12:54.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m54s

leaderboard public leaderboard you can
01:12:58.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h12m58s

see we're kind of sort of look in the
01:13:06.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m06s

top actually that's interesting there is
01:13:12.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m12s

a big difference between the public and
01:13:16.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m16s

private leaderboard it would have it
01:13:18.179
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m18s

would have been right at the top of the
01:13:20.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m20s

private leaderboard but only in the top
01:13:21.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m21s

thirty or forty on the public
01:13:24.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m24s

leaderboards so not quite sure but you
01:13:25.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m25s

can see like we're certainly in the top
01:13:27.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m27s

end of this competition I actually tried
01:13:30.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m30s

running the third place to get his code
01:13:35.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m35s

and their final result was over a point
01:13:37.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m37s

one so I actually think that we're
01:13:41.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m41s

trippy compared to private leaderboard
01:13:44.219
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m44s

but I'm not sure so anyway so you can
01:13:46.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m46s

see they're basically there's a
01:13:50.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m50s

technique for dealing with time series
01:13:51.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m51s

and structured data and you know
01:13:55.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m55s

interestingly the group that that used
01:13:58.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h13m58s

this technique they actually wrote a
01:14:01.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m01s

paper about it that's linked in this
01:14:02.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m02s

notebook when you compare it to the
01:14:04.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m04s

folks that won this competition and came
01:14:08.369
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m08s

second they did the other folks did way
01:14:11.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m11s

more feature engineering like the
01:14:13.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m13s

winners of this competition were
01:14:16.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m16s

actually subject matter experts in
01:14:18.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m18s

logistics sales forecasting and so they
01:14:20.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m20s

had their own code to create lots and
01:14:23.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m23s

lots of features and talking to the
01:14:25.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m25s

folks at Pinterest who built their very
01:14:28.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m28s

similar model for recommendations for
01:14:31.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m31s

Pinterest they say the same thing which
01:14:33.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m33s

is that when they switched from gradient
01:14:35.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m35s

boosting machines to deep learning they
01:14:36.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m36s

did like way way way less feature
01:14:39.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m39s

engineering it was a much much simpler
01:14:43.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m43s

model and requires much less maintenance
01:14:45.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m45s

and so this is like one of the big
01:14:47.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m47s

benefits of using this approach to deep
01:14:50.219
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m50s

learning you can get state of the at
01:14:51.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m51s

results but with a lot less work yes
01:14:53.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h14m53s

are you using any time series in any of
01:15:01.989
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m01s

these fits indirectly absolutely using
01:15:05.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m05s

what we just saw we have a day of week
01:15:11.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m11s

month of year all that stuff our columns
01:15:13.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m13s

and most of them are being treated as
01:15:16.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m16s

categories so we're building a
01:15:18.969
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m18s

distributed representation of January
01:15:21.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m21s

we're building a distributed
01:15:23.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m23s

representation of Sunday we're building
01:15:24.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m24s

a distributed representation of
01:15:26.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m26s

Christmas
01:15:27.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m27s

so we're not using any plastic time
01:15:28.719
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m28s

series techniques all we're doing is
01:15:33.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m33s

true fully connected layers in a neural
01:15:36.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m36s

net better metrics
01:15:39.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m39s

that's what exactly exactly yeah so the
01:15:42.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m42s

embedding matrix is able to deal with
01:15:45.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m45s

this stuff like day of week periodicity
01:15:47.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m47s

and so forth in a way richer way than
01:15:50.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m50s

any standard time series technique I've
01:15:54.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m54s

ever come across
01:15:58.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m58s

one last question the matrix in the
01:15:58.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h15m58s

earlier models we did CNN did not pass
01:16:03.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m03s

it during the fig we passed it when the
01:16:06.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m06s

data was when we got the data so we're
01:16:10.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m10s

not passing anything to fit just the
01:16:14.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m14s

learning rate and the number of cycles
01:16:17.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m17s

in this case we're passing in metrics is
01:16:18.989
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m18s

not a printout some extra stuff there is
01:16:21.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m21s

a difference in the we're calling data
01:16:24.969
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m24s

get learner
01:16:27.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m27s

so with the imaging approach we just go
01:16:28.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m28s

learner dot trained and pass at the data
01:16:35.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m35s

but in for these kinds of models in fact
01:16:38.969
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m38s

for a lot of the models the model that
01:16:43.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m43s

we build depends on the data in this
01:16:46.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m46s

case we actually need to know like what
01:16:49.239
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m49s

embedding matrices do we have and stuff
01:16:51.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m51s

like that so in this case it's actually
01:16:54.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m54s

the data object that creates the learner
01:16:56.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m56s

so yeah it is it is a bit upside down to
01:16:59.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h16m59s

what we've seen before
01:17:01.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m01s

yeah so just to summarize or maybe I'm
01:17:04.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m04s

confused
01:17:09.329
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m09s

so in this case what we are doing is
01:17:10.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m10s

that we have some kind of structured
01:17:14.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m14s

data did feature engineering we got some
01:17:16.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m16s

columnar database or something
01:17:20.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m20s

embedding matrix for the categorical
01:17:32.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m32s

variables so the continuous we just put
01:17:35.699
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m35s

them straight feature engineering yeah
01:17:38.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m38s

then to map it to deep learning I just
01:17:46.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m46s

have to figure out which one I can great
01:17:49.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m49s

question
01:17:54.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m54s

so yes exactly if you want to use this
01:17:54.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m54s

on your own data set step one is list
01:17:57.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h17m57s

the categorical variable names list the
01:18:01.769
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m01s

continuous variable names put it in a
01:18:04.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m04s

data frame pandas dataframe step two is
01:18:07.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m07s

to create a list of which row indexes do
01:18:11.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m11s

you want in your validation set step
01:18:17.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m17s

three is to call this line of code using
01:18:20.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m20s

this except like these exact you can
01:18:25.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m25s

just copy and paste it step four is to
01:18:27.749
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m27s

create your list of how big you want
01:18:31.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m31s

each embedding matrix to be and then
01:18:33.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m33s

step 5 is to call get loner you can use
01:18:37.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m37s

these exact parameters to start with and
01:18:41.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m41s

if it over fits or under fits you can
01:18:44.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m44s

fiddle with them and then the final step
01:18:46.229
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m46s

is to call fit so yeah almost all of
01:18:48.239
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m48s

this code will be nearly identical
01:18:53.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m53s

have a couple of questions one is how is
01:18:59.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h18m59s

data element ation can be used in this
01:19:04.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m04s

case and the second one is why whatever
01:19:07.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m07s

dropouts doing in here
01:19:12.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m12s

okay so data augmentation I have no idea
01:19:14.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m14s

I mean that's a really interesting
01:19:16.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m16s

question
01:19:17.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m17s

I think it's gotta be domain-specific
01:19:21.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m21s

I've never seen any paper or anybody in
01:19:22.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m22s

industry doing data augmentation with
01:19:25.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m25s

structured data and deep blow so I don't
01:19:27.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m27s

think it can be done I just haven't seen
01:19:29.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m29s

it done
01:19:31.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m31s

what is dropout doing exactly the same
01:19:32.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m32s

as before so at each point we have the
01:19:36.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m36s

output of each of these linear layers is
01:19:45.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m45s

just a rank one tensor and so dropout is
01:19:48.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m48s

going to go ahead and say let's throw
01:19:52.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m52s

away half of the activations and the
01:19:54.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m54s

very first dropout imbedding drop out
01:19:58.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h19m58s

literally goes through the embedding
01:20:00.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m00s

matrix and says let's throw away half
01:20:01.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m01s

the activations that's it okay let's
01:20:07.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m07s

take a break and let's come back at five
01:20:12.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m12s

past eight okay thanks everybody so now
01:20:16.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m16s

we're gonna move into something equally
01:20:30.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m30s

exciting actually before I do I just
01:20:34.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m34s

been sure that I had a good question
01:20:36.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m36s

during the break which was what's the
01:20:38.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m38s

downside
01:20:41.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m41s

like like almost no one's using this why
01:20:42.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m42s

not and and basically I think the answer
01:20:49.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m49s

is like as we discussed before no one in
01:20:53.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m53s

academia almost is working on this
01:20:55.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m55s

because it's not something that people
01:20:57.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m57s

really publish on and as a result there
01:20:59.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h20m59s

haven't been really great examples where
01:21:04.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m04s

people could look at and say oh here's a
01:21:06.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m06s

technique that works well so let's have
01:21:07.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m07s

our company implement it but perhaps
01:21:10.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m10s

equally importantly until now with this
01:21:12.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m12s

fast AI library there hasn't been any
01:21:16.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m16s

way to do it conveniently if you wanted
01:21:18.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m18s

to implement one of these models you had
01:21:23.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m23s

to write all the custom code yourself
01:21:25.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m25s

where else now as we discussed it's you
01:21:28.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m28s

know sick
01:21:30.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m30s

it's basically a six step process you
01:21:33.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m33s

know involving about you know not much
01:21:36.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m36s

more than six lines of code so the
01:21:39.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m39s

reason I mentioned this is to say like I
01:21:43.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m43s

think there are a lot of big commercial
01:21:44.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m44s

and scientific opportunities to use this
01:21:47.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m47s

to solve problems that previously
01:21:51.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m51s

haven't been solved very well before so
01:21:53.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m53s

like I'll be really interested to hear
01:21:57.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m57s

if some of you try this out you know
01:21:59.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h21m59s

maybe on like old cattle competitions
01:22:02.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m02s

you might find like oh I would have won
01:22:06.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m06s

this if I'd use this technique that
01:22:08.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m08s

would be interesting or if you've got
01:22:09.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m09s

some data set you work with at work
01:22:11.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m11s

without some kind of model that you've
01:22:13.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m13s

been doing to the GBM or a random forest
01:22:15.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m15s

does this help you know the thing I I'm
01:22:17.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m17s

still somewhat new to this I've been
01:22:22.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m22s

doing this for basically since the start
01:22:25.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m25s

of the year was when I started working
01:22:28.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m28s

on these structured deep learning models
01:22:29.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m29s

so I haven't had enough opportunity to
01:22:31.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m31s

know where might it fail it's worked for
01:22:34.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m34s

nearly everything I've tried it with so
01:22:37.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m37s

far but yeah I think this class is the
01:22:39.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m39s

first time that there's going to be like
01:22:43.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m43s

more than half a dozen people fulfilled
01:22:46.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m46s

who actually are working on this so I
01:22:48.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m48s

think you know as a group we're gonna
01:22:50.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m50s

hopefully learn a lot and build some
01:22:51.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m51s

interesting things and this would be a
01:22:54.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m54s

great thing if you're thinking of
01:22:55.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m55s

writing a post about something or here's
01:22:56.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m56s

an area that there's a couple of that
01:22:59.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h22m59s

there's a poster in staccato about what
01:23:02.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m02s

they did Pinterest has a an O'Reilly a a
01:23:04.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m04s

video about what they did that's about
01:23:09.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m09s

it and there's two academic papers both
01:23:11.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m11s

about Carroll competition victories one
01:23:15.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m15s

from Yoshi Joshua Ben geo and his group
01:23:17.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m17s

they won a taxi destination forecasting
01:23:21.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m21s

competition and then also the one linked
01:23:25.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m25s

for this rossmann competition so yeah
01:23:28.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m28s

there's some background on that
01:23:33.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m33s

alright so language natural language
01:23:33.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m33s

processing is the area which is kind of
01:23:38.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m38s

like the most up-and-coming area
01:23:44.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m44s

moaning it's kind of like two or three
01:23:47.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m47s

years behind computer vision in deep
01:23:48.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m48s

learning it was kind of like the the
01:23:52.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m52s

second area that deep learning started
01:23:54.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m54s

getting really popular in and you know
01:23:57.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m57s

computer vision got to the point where
01:23:59.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h23m59s

it was like clear state of the art for
01:24:03.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m03s

most computer vision things maybe in
01:24:06.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m06s

like 2014 you know and in some things in
01:24:07.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m07s

like 2012 in NLP we're still at the
01:24:10.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m10s

point where for a lot of things deep
01:24:14.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m14s

learning is now the state of the art but
01:24:17.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m17s

not quite everything but as you'll see
01:24:18.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m18s

the state of kind of the software and
01:24:21.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m21s

some of the concepts is much less mature
01:24:25.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m25s

than it is for computer vision so in
01:24:28.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m28s

general none of the stuff we talked
01:24:32.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m32s

about
01:24:33.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m33s

after computer vision is going to be as
01:24:34.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m34s

like settled as the computer vision and
01:24:36.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m36s

stuff was so NLP one of the interesting
01:24:39.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m39s

things is in the last few months some of
01:24:42.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m42s

the good ideas from computer vision have
01:24:45.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m45s

started to spread into NLP for the first
01:24:47.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m47s

time and we've seen some really big
01:24:49.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m49s

advances so a lot of the stuff you'll
01:24:51.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m51s

see in NLP is is pretty new so I'm going
01:24:52.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m52s

to start with a particular kind of NLP
01:24:57.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h24m57s

problem and one of the things refined in
01:25:01.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m01s

NLP is like there are particular
01:25:03.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m03s

problems you can solve and they have
01:25:04.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m04s

particular names and so there's a
01:25:06.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m06s

particular kind of problem in NLP called
01:25:08.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m08s

language modeling and language modeling
01:25:10.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m10s

has a very specific definition that
01:25:13.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m13s

means build a model we're given a few
01:25:15.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m15s

words of a sentence can you predict what
01:25:19.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m19s

the next word is going to be so if
01:25:21.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m21s

you're using your mobile phone and
01:25:24.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m24s

you're typing away and you press space
01:25:26.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m26s

and then it says like this is what the
01:25:28.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m28s

next word might be like SwiftKey does
01:25:30.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m30s

this like really well and SwiftKey
01:25:33.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m33s

actually uses deep learning for this
01:25:35.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m35s

that's that's a language model okay so
01:25:36.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m36s

it has a very specific meaning when we
01:25:40.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m40s

say language modeling we mean a model
01:25:41.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m41s

that can predict the next word of a
01:25:44.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m44s

sentence
01:25:46.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m46s

so let me give you an example I
01:25:48.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m48s

downloaded about 18 months worth of
01:25:49.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m49s

papers from archive so for those of you
01:25:54.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m54s

that don't know what archive is the most
01:25:57.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h25m57s

popular preprint server in this
01:26:01.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m01s

community and various others and has you
01:26:03.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m03s

know lots of academic papers and so I
01:26:07.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m07s

grabbed the abstracts and the topics for
01:26:10.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m10s

each and so here's an example so the
01:26:14.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m14s

category of this particular paper what
01:26:16.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m16s

computer CSMA is computer science and
01:26:18.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m18s

networking and then the summary let the
01:26:21.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m21s

abstract of the paper they're seeing the
01:26:24.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m24s

exploitation of mm-wave bands is one of
01:26:26.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m26s

the key enabler for 5g mobile bla bla
01:26:28.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m28s

bla okay so here's like an example piece
01:26:30.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m30s

of text from my language model so I
01:26:35.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m35s

trained a language model on this
01:26:39.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m39s

archived data set that I downloaded and
01:26:41.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m41s

then I built a simple little test which
01:26:44.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m44s

basically you would pass it some like
01:26:46.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m46s

priming text so you'd say like Oh
01:26:50.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m50s

imagine you started reading a document
01:26:53.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m53s

that said category is computer science
01:26:54.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m54s

networking and the summary is algorithms
01:26:57.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h26m57s

that and then I said please write an
01:27:00.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m00s

archive abstract so it said that if it's
01:27:04.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m04s

networking
01:27:07.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m07s

algorithms that use the same network as
01:27:08.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m08s

a single node I'm not able to achieve
01:27:11.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m11s

the same performance as a traditional
01:27:13.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m13s

network based routing algorithms in this
01:27:14.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m14s

paper we propose a novel routing scheme
01:27:16.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m16s

but okay so it it's learnt by reading
01:27:18.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m18s

archive papers that somebody who is
01:27:22.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m22s

playing algorithms that where the word
01:27:24.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m24s

cat CSM ie came before it is going to
01:27:27.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m27s

talk like this and remember it started
01:27:31.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m31s

out not knowing English at all right it
01:27:34.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m34s

actually started out with an embedding
01:27:36.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m36s

matrix for every word in English that
01:27:38.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m38s

was random okay and by reading lots of
01:27:41.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m41s

archive papers it weren't what kind of
01:27:44.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m44s

words followed others so then I tried
01:27:46.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m46s

what if we said cat computer science
01:27:48.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m48s

computer vision summary algorithms that
01:27:51.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m51s

use the same data to perform image
01:27:55.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m55s

specification are increasingly being
01:27:58.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h27m58s

used to
01:28:00.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m00s

proves the performance of image
01:28:01.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m01s

classification algorithms and this paper
01:28:02.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m02s

we propose a novel method for image
01:28:04.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m04s

specification using a deeper
01:28:06.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m06s

convolutional neural network parentheses
01:28:07.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m07s

CNN so you can see like it's kind of
01:28:09.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m09s

like almost the same sentence as back
01:28:12.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m12s

here but things have just changed into
01:28:15.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m15s

this world of computer vision rather
01:28:17.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m17s

than networking so I tried something
01:28:20.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m20s

else which is like okay category
01:28:22.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m22s

computer vision and I created the
01:28:24.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m24s

world's shortest ever abstract that
01:28:26.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m26s

words and then I said title on and the
01:28:28.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m28s

title of this is going to be on that
01:28:32.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m32s

performance object learning for image
01:28:35.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m35s

classification in OS is end of string so
01:28:36.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m36s

that's like end of title what if it is
01:28:39.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m39s

networking summary algorithms title on
01:28:42.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m42s

the performance of wireless networks as
01:28:44.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m44s

opposed to towards computer vision
01:28:47.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m47s

towards a new approach to image
01:28:50.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m50s

specification networking towards then
01:28:52.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m52s

you approach to the analysis of wireless
01:28:55.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m55s

networks so like I find this
01:28:57.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h28m57s

mind-blowing right I started out with
01:29:00.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m00s

some random matrices which had like
01:29:02.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m02s

literally no no pre-trade anything
01:29:06.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m06s

I fed at 18 months worth of archived
01:29:09.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m09s

articles and it learnt not only how to
01:29:12.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m12s

write English pretty well but also after
01:29:15.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m15s

you say something's a convolutional
01:29:19.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m19s

neural network you should then use
01:29:20.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m20s

parentheses to say what it's called and
01:29:22.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m22s

furthermore that the kinds of things
01:29:24.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m24s

people talk could say create algorithms
01:29:27.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m27s

for in computer vision are performing
01:29:28.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m28s

image classification and in networking
01:29:31.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m31s

are achieving the same performance as
01:29:33.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m33s

traditional network based routing
01:29:37.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m37s

algorithms so like a language model is
01:29:38.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m38s

can be like incredibly deep and subtle
01:29:42.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m42s

right and so we're going to try and
01:29:47.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m47s

build that but actually not because we
01:29:49.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m49s

care about this at all we're going to
01:29:52.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m52s

build it because we're going to try and
01:29:55.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m55s

create a pre-trained model what we're
01:29:56.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m56s

actually going to try and do is take
01:29:58.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h29m58s

IMDB movie reviews and figure out
01:30:00.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m00s

whether they're positive or negative so
01:30:04.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m04s

if you think about it this is a lot like
01:30:07.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m07s

cats vs. dogs
01:30:08.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m08s

that's a classification algorithm
01:30:09.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m09s

but rather than an image we're going to
01:30:12.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m12s

have the text of a review so I'd really
01:30:14.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m14s

like to use a pre-trained Network
01:30:18.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m18s

like I would at least my connect to
01:30:19.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m19s

start with a network that knows how to
01:30:22.179
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m22s

read English right and so my view was
01:30:24.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m24s

like okay to know how to read English
01:30:29.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m29s

means you should be able to like predict
01:30:31.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m31s

the next word of a sentence so what if
01:30:33.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m33s

we pre train a language model and then
01:30:36.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m36s

use that pre-trained language model and
01:30:39.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m39s

then just like in computer vision stick
01:30:42.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m42s

some new layers on the end and ask it
01:30:44.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m44s

instead of - predicting the next word in
01:30:46.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m46s

the sentence instead predict whether
01:30:48.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m48s

something is positive or negative so
01:30:51.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m51s

when I started working on this this was
01:30:54.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m54s

actually a new idea unfortunately in the
01:30:57.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m57s

last couple of months I've been doing it
01:30:59.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h30m59s

you know a few people have actually
01:31:01.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m01s

couple people started publishing this
01:31:02.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m02s

and so this has moved from being a
01:31:04.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m04s

totally new idea to being a you know
01:31:06.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m06s

somewhat new idea so so this idea of
01:31:08.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m08s

creating a language model making that
01:31:14.219
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m14s

the pre-trained model for a
01:31:17.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m17s

classification model is what we're going
01:31:18.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m18s

to learn to do now and so the idea is
01:31:21.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m21s

we're really kind of trying to leverage
01:31:23.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m23s

exactly what we learnt in our computer
01:31:25.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m25s

vision work which is how do we do fine
01:31:28.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m28s

tuning to create powerful classification
01:31:30.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m30s

models yes you know so why don't you
01:31:32.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m32s

think that doing just directly what you
01:31:36.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m36s

want to do doesn't work better well
01:31:40.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m40s

because it doesn't just turns out it
01:31:44.219
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m44s

doesn't empirically and the reason it
01:31:47.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m47s

doesn't is a number of things first of
01:31:50.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m50s

all as we know fine-tuning a pre-trained
01:31:54.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m54s

network is really powerful right so if
01:31:58.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h31m58s

we can get it to learn some related
01:32:01.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m01s

tasks first then we can use all that
01:32:04.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m04s

information to try and help it on the
01:32:06.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m06s

second task the other reason is IMDB
01:32:09.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m09s

movie reviews you know up to a thousand
01:32:15.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m15s

words long
01:32:18.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m18s

they're pretty big and so after reading
01:32:19.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m19s

a thousand words knowing nothing about
01:32:22.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m22s

how English is structured or even what
01:32:24.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m24s

the concept of a word is or punctuation
01:32:27.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m27s

or whatever at the end of this thousand
01:32:30.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m30s

integers you know they end up being
01:32:33.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m33s

integers all you get is a 1 or a 0
01:32:35.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m35s

positive or negative and so trying to
01:32:37.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m37s

like learn the entire structure of
01:32:40.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m40s

English and then how it expresses
01:32:42.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m42s

positive and negative sentiments from a
01:32:44.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m44s

single number is just too much to expect
01:32:45.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m45s

so by building a language model first we
01:32:48.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m48s

can try to build a neural network that
01:32:51.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m51s

kind of understands the English of movie
01:32:53.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m53s

reviews and then we hope that some of
01:32:56.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m56s

the things that's learnt about are going
01:32:59.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h32m59s

to be useful in deciding whether
01:33:02.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m02s

something's a positive or a negative
01:33:03.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m03s

nutrition that's a great question you
01:33:05.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m05s

can pass that thanks is this similar to
01:33:07.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m07s

the car RNN yeah this is somewhat
01:33:12.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m12s

similar to our Olympic apathy so the
01:33:18.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m18s

famous car as in CH AR AR and in try to
01:33:21.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m21s

predict the next letter given a number
01:33:25.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m25s

of previous letters language models
01:33:28.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m28s

generally work at a word level they
01:33:30.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m30s

don't have to and doing things that a
01:33:33.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m33s

word level turns out to be can be quite
01:33:35.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m35s

a bit more powerful and we're going to
01:33:38.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m38s

focus on word level modeling in this
01:33:40.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m40s

course to what extent are these
01:33:42.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m42s

generated words actually copies of what
01:33:46.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m46s

it found in the in the training data set
01:33:50.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m50s

or are these completely random things
01:33:53.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m53s

that it actually learned and how do we
01:33:56.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m56s

know how to distinguish between those
01:33:57.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m57s

two yeah I mean these are awkward
01:33:59.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h33m59s

questions the the words are definitely
01:34:01.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m01s

words we've seen before the work because
01:34:04.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m04s

it's not at a character level so it can
01:34:05.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m05s

only give us the word it seen before the
01:34:07.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m07s

sentences there's a number of kind of
01:34:09.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m09s

rigorous ways of doing it but I think
01:34:13.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m13s

the easiest is to get a sense of like
01:34:14.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m14s

well here are two like different
01:34:16.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m16s

categories where it's kind of created
01:34:19.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m19s

very similar concepts but mixing them up
01:34:21.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m21s

in just the right way like it it would
01:34:25.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m25s

be very hard to to do what we've seen
01:34:27.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m27s

here just by like speeding back things
01:34:30.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m30s

at scene before but you could of course
01:34:33.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m33s

actually go back and check you know
01:34:35.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m35s

have you seen that sentence before or
01:34:37.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m37s

like a stream distance - have you seen a
01:34:39.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m39s

similar sentence before in this case oh
01:34:41.329
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m41s

and of course another way to do it is
01:34:45.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m45s

the length most importantly when we
01:34:47.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m47s

train the language model as we'll see
01:34:49.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m49s

we'll have a validation set and so we're
01:34:51.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m51s

trying to predict the next word of
01:34:53.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m53s

something that's never seen before
01:34:55.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m55s

and so if it's good at doing that it
01:34:57.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m57s

should be good at generating text in
01:34:59.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h34m59s

this case the purpose the purpose is not
01:35:01.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m01s

to generate text that was just a fun
01:35:04.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m04s

example and so I'm not really gonna
01:35:06.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m06s

study that too much but you know you're
01:35:08.059
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m08s

during the week turtley can like you can
01:35:10.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m10s

totally build your you know Great
01:35:13.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m13s

American Novel generator or whatever
01:35:16.699
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m16s

there are actually some tricks to to
01:35:19.269
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m19s

using language models to generate text
01:35:22.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m22s

that I'm not using here they're pretty
01:35:24.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m24s

simple we can talk about them on the
01:35:27.469
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m27s

forum if you like but my focus is
01:35:28.849
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m28s

actually on classification so I think
01:35:31.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m31s

that's the thing which is incredibly
01:35:34.039
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m34s

powerful like text classification I
01:35:37.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m37s

don't know you're a hedge fund you want
01:35:41.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m41s

to like read every article as soon as it
01:35:44.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m44s

comes out through writers or Twitter or
01:35:46.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m46s

whatever and immediately identify things
01:35:49.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m49s

which in the past have caused you know
01:35:51.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m51s

massive market drops that's a
01:35:54.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m54s

classification model or you want to
01:35:56.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h35m56s

recognize all of the customer service
01:36:00.219
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m00s

queries which tend to be associated with
01:36:03.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m03s

people who who leave your you know who
01:36:06.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m06s

cancel their contracts in the next
01:36:09.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m09s

month's that's a classification problem
01:36:12.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m12s

so like it's a really powerful kind of
01:36:14.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m14s

thing for data journalism Activision
01:36:16.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m16s

that activism more promise so forth
01:36:21.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m21s

right like I'm trying to class documents
01:36:25.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m25s

into whether they're part of legal
01:36:29.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m29s

discovery or not part of legal discovery
01:36:30.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m30s

okay so you get the idea so in terms of
01:36:33.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m33s

stuff we're importing we're importing a
01:36:39.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m39s

few new things here one of the bunch of
01:36:40.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m40s

things we're importing is torch text
01:36:44.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m44s

torch text is PI torches like
01:36:47.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m47s

LP library and so fast AI is designed to
01:36:51.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m51s

work hand in hand with torch text as
01:36:55.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m55s

you'll see and then there's a few text
01:36:57.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h36m57s

specific sub bits of faster fast AI that
01:37:01.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m01s

we'll be using so we're going to be
01:37:03.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m03s

working with the IMDB large movie review
01:37:06.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m06s

data set it's very very well studied in
01:37:09.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m09s

academia you know lots and lots of
01:37:12.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m12s

people over the years have studied this
01:37:16.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m16s

data set
01:37:19.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m19s

fifty thousand reviews highly polarized
01:37:20.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m20s

reviews either positive or negative each
01:37:23.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m23s

one has been classified by sentiment
01:37:26.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m26s

okay so we're going to try our first of
01:37:29.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m29s

all however to create a language model
01:37:32.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m32s

so we're going to ignore the sentiment
01:37:33.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m33s

entirely all right so just like the dogs
01:37:35.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m35s

and cats Cree trainer model to do one
01:37:37.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m37s

thing and then fine tune it to do
01:37:39.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m39s

something else because this kind of idea
01:37:41.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m41s

in NLP is is so so so new there's
01:37:44.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m44s

basically no models you can download for
01:37:48.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m48s

this so we're going to have to create
01:37:50.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m50s

their own right so having downloaded the
01:37:52.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m52s

data you can use the link here we do the
01:37:57.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m57s

usual stuff of saying the path to
01:37:59.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h37m59s

training and validation path and as you
01:38:01.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m01s

can see it looks pretty pretty
01:38:05.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m05s

traditional compared to a vision there's
01:38:06.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m06s

a directory of training there's a
01:38:08.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m08s

directory of tests we don't actually
01:38:10.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m10s

have separate test and validation in
01:38:12.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m12s

this case and just like in envision the
01:38:14.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m14s

training directory has a bunch of files
01:38:19.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m19s

in it in this case not representing
01:38:22.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m22s

images but representing movie reviews so
01:38:25.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m25s

we could cat one of those files and here
01:38:28.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m28s

we learn about the classic zombie garand
01:38:32.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m32s

movie I have to say with a name like
01:38:36.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m36s

zombie gedan and an atom bomb on the
01:38:38.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m38s

front cover I was expecting a flat-out
01:38:41.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m41s

chop-socky fun coup rent it if you want
01:38:43.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m43s

to get stoned on a Friday night and
01:38:49.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m49s

laugh with your buddies don't rent it if
01:38:50.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m50s

you're an uptight weenie or want a
01:38:52.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m52s

zombie movie or lots of fresh eating I
01:38:54.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m54s

think I'm going to enjoy zombie getting
01:38:55.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m55s

so alright so we've learned something
01:38:58.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h38m58s

today
01:39:00.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m00s

all right so we can just use standard
01:39:02.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m02s

UNIX stuff to see like how many words
01:39:04.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m04s

are in the data set so the training set
01:39:06.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m06s

we've got seventeen and a half million
01:39:08.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m08s

words test set we've got 5.6 million
01:39:12.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m12s

words so he is these are this is IMDB so
01:39:15.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m15s

IMDB is random people this is not New
01:39:24.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m24s

York Times listed review as far as I
01:39:27.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m27s

know okay so before we can do anything
01:39:29.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m29s

with text we have to turn it into a list
01:39:38.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m38s

of tokens token is basically like a word
01:39:40.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m40s

right so we're going to try and turn
01:39:43.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m43s

this eventually into a list of numbers
01:39:45.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m45s

so the first step is to turn it into a
01:39:47.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m47s

list of words
01:39:49.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m49s

that's called tokenization in NLP NLP
01:39:49.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m49s

has a huge lot of jargon that will we'll
01:39:52.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m52s

learn over time
01:39:55.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m55s

one thing that's a bit tricky though
01:39:57.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m57s

when we're doing tokenization is here
01:39:59.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h39m59s

I've I've tokenized that review and then
01:40:02.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m02s

joined it back up with spaces and you'll
01:40:05.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m05s

see here that wasn't has become two
01:40:07.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m07s

tokens which makes perfect sense right
01:40:10.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m10s

was is two things right dot dot dot has
01:40:12.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m12s

become one token right where else lots
01:40:19.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m19s

of exclamation marks has become lots of
01:40:22.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m22s

tokens so like a good tokenizer
01:40:24.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m24s

will do a good job of recognizing like
01:40:27.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m27s

pieces of it in your sentence each
01:40:30.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m30s

separate piece of punctuation will be
01:40:33.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m33s

separated and each part of a multi-part
01:40:35.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m35s

word will be separated as appropriate so
01:40:39.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m39s

Spacey is I think it's an Australian
01:40:43.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m43s

develop piece of software actually that
01:40:45.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m45s

does lots of you know P stuff it's got
01:40:47.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m47s

the best tokenizer I know and so past AI
01:40:50.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m50s

is designed to work well with the Spacey
01:40:53.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m53s

tokenizer as is torch text so here's an
01:40:55.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m55s

example of tokenization alright so what
01:40:58.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h40m58s

we do with torch text is we basically
01:41:02.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m02s

have to start out by creating something
01:41:05.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m05s

called a field and a field is a
01:41:07.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m07s

definition of how to pre-process some
01:41:09.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m09s

text and so here's an example with the
01:41:12.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m12s

definition of a field
01:41:14.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m14s

it says I want to lowercase a text and I
01:41:15.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m15s

want to tokenize it with the function
01:41:19.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m19s

called Spacey tokenize okay so it hasn't
01:41:21.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m21s

done anything yet we're just telling you
01:41:24.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m24s

when we do do something this is what to
01:41:26.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m26s

do and so that we're going to store that
01:41:28.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m28s

description of what to do in a thing
01:41:30.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m30s

called capital text and so this is this
01:41:32.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m32s

is none of this but this is not fast AI
01:41:37.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m37s

specific at all this is part of torch
01:41:39.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m39s

text you can go to the torch text
01:41:40.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m40s

website read the docs there's not lots
01:41:42.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m42s

of Doc's yet this is all very very new
01:41:44.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m44s

so probably the best information you'll
01:41:46.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m46s

find about it is in this lesson but
01:41:49.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m49s

there's some more information on this
01:41:51.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m51s

site all right so what we can now do is
01:41:54.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m54s

go ahead and create the usual fast AI
01:41:57.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h41m57s

model data object okay and so to create
01:42:01.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m01s

the model data object we have to provide
01:42:05.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m05s

a few bits of information but you have
01:42:07.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m07s

to say what's the training set so the
01:42:08.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m08s

path to the text files the validation
01:42:10.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m10s

set and the test set in this case just
01:42:14.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m14s

to keep things simple I don't have a
01:42:17.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m17s

separate validation and test set so I'm
01:42:18.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m18s

going to pass in the validation set for
01:42:20.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m20s

both of those two things right
01:42:22.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m22s

so now we can create our model data
01:42:24.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m24s

object as per usual the first thing you
01:42:26.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m26s

give it as a path the second thing we
01:42:29.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m29s

give it is the torch text field
01:42:32.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m32s

definition of how to pre-process that
01:42:34.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m34s

text the third thing we give it is the
01:42:36.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m36s

dictionary or the list of all of the
01:42:39.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m39s

files we have trained validation tests
01:42:42.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m42s

as per usual we can pass in a batch size
01:42:45.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m45s

and then we've got a special special
01:42:47.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m47s

couple of extra things here one is very
01:42:50.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m50s

commonly used in NLP minimum frequency
01:42:54.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m54s

what this says is in a moment we're
01:42:57.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h42m57s

going to be replacing every one of these
01:43:01.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m01s

words with an integer which basically
01:43:03.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m03s

will be a unique index for every word
01:43:05.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m05s

and this basically says if there are any
01:43:08.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m08s

words that occur less than 10 times just
01:43:10.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m10s

call it unknown right don't think of it
01:43:14.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m14s

as a word but we'll see that indeed more
01:43:17.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m17s

detail in a moment
01:43:19.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m19s

we're going to see this in more detail
01:43:21.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m21s

as well be PTT stands for back prop
01:43:23.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m23s

through time and this is where we define
01:43:26.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m26s

how long a sentence will we stick on the
01:43:28.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m28s

GPU at once so we're going to break them
01:43:33.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m33s

up in this case we're going to break
01:43:35.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m35s

them up into sentences of 70 tokens or
01:43:37.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m37s

less on the whole so we're going to see
01:43:41.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m41s

all this in a moment
01:43:44.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m44s

okay so after building our model data
01:43:45.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m45s

object right what it actually does is
01:43:48.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m48s

it's going to fill this text field with
01:43:51.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m51s

an additional attribute called vocab and
01:43:55.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m55s

this is a really important and LP
01:43:58.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h43m58s

concept I'm sorry there's so many NLP
01:44:00.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m00s

concepts we just have to throw at you
01:44:02.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m02s

kind of quickly but we'll see them a few
01:44:03.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m03s

times right the vocab is the vocabulary
01:44:05.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m05s

and the vocabulary in NLP has a very
01:44:09.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m09s

specific meaning it is what is the list
01:44:12.719
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m12s

of unique words that appear in this text
01:44:15.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m15s

so every one of them is going to get a
01:44:17.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m17s

unique in this so let's take a look
01:44:19.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m19s

right here is text vocab dot I to s this
01:44:22.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m22s

dancer this is all torch text not faster
01:44:26.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m26s

hide text upper cap dot int 2 string
01:44:29.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m29s

Maps the integer 0 to unknown the
01:44:32.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m32s

integer 1 the padding unit 2 to desert
01:44:37.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m37s

then in comma dot and of 2 and so forth
01:44:39.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m39s

right so this is the first 12 elements
01:44:43.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m43s

of the array of the vocab from the IMDB
01:44:47.429
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m47s

movie review and it's been sorted by
01:44:52.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m52s

frequency and except for the first two
01:44:55.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m55s

special ones so for example we can then
01:44:57.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h44m57s

go backwards
01:45:00.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m00s

s2i string to int here is the it's in
01:45:00.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m00s

position 0 1 2 so stream to end the is 2
01:45:05.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m05s

so the vocab lets us take a word and map
01:45:09.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m09s

it to an integer or take an integer and
01:45:14.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m14s

that a tour word right and so that means
01:45:17.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m17s

that we can then take the first 12
01:45:20.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m20s

tokens for example of our text and turn
01:45:24.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m24s

them into twelve inch so for example
01:45:27.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m27s

here is of the agency 7 2
01:45:32.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m32s

and here you can see 7/2 right so we're
01:45:35.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m35s

going to be working in this form did you
01:45:40.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m40s

have a question deputy plus that back
01:45:44.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m44s

there you know is it a common tyranny
01:45:45.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m45s

stemming or limit izing not really no
01:45:49.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m49s

generally tokenization is is what we
01:45:53.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m53s

want like with a language model we you
01:45:56.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h45m56s

know to keep it as general as possible
01:46:00.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m00s

we want to know what's coming next and
01:46:01.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m01s

so like whether its future tense or past
01:46:03.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m03s

tense or plural or seem to learn like we
01:46:06.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m06s

don't really know which things are going
01:46:08.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m08s

to be interesting in which ant so it
01:46:10.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m10s

seems that it's generally best to kind
01:46:15.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m15s

of leave it alone as much as possible be
01:46:18.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m18s

the short answer you know having said
01:46:21.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m21s

that as I say this is all pretty new so
01:46:25.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m25s

if there are some particular areas that
01:46:27.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m27s

some researcher maybe is already
01:46:29.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m29s

discovered that some other kinds of
01:46:30.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m30s

pre-processing you're helpful you know I
01:46:32.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m32s

wouldn't be surprised not to know about
01:46:35.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m35s

it so we Abdullah we know you don't
01:46:37.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m37s

natural language is in context important
01:46:41.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m41s

context is very important so individual
01:46:43.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m43s

words no no we're not looking worth this
01:46:50.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m50s

is this look this is I just don't get
01:46:52.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m52s

some of the big premises of this like
01:46:54.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m54s

they're there in order yeah so just
01:46:57.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m57s

because we replaced I with the number 12
01:46:59.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h46m59s

these are still in that order
01:47:02.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m02s

yeah there is a different way of dealing
01:47:05.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m05s

with natural language called a bag of
01:47:09.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m09s

words and bag of words you through throw
01:47:11.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m11s

away the order in the context and in the
01:47:13.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m13s

machine learning course we'll be
01:47:15.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m15s

learning about working with bag of words
01:47:16.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m16s

representation z' but my belief is that
01:47:18.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m18s

they are no longer useful or in the
01:47:21.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m21s

verge of becoming no longer useful we're
01:47:24.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m24s

starting to learn how to use deep
01:47:26.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m26s

learning to use context properly now but
01:47:28.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m28s

it's kind of for the first time it's
01:47:33.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m33s

really like only in the last few months
01:47:35.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m35s

right so I mentioned that we've got two
01:47:38.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m38s

numbers batch size and B PTT back crop
01:47:40.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m40s

through time so this is kind of subtle
01:47:44.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m44s

so we've got some big long piece of text
01:47:52.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m52s

okay so we've got some big long piece of
01:47:58.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h47m58s

text you know here's our sentence it's a
01:48:00.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m00s

bunch of words right and actually what
01:48:02.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m02s

happens in a language model is even
01:48:07.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m07s

though we have lots of movie reviews
01:48:09.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m09s

they actually all get concatenated
01:48:10.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m10s

together into one big block of text
01:48:13.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m13s

right so it's basically predict the next
01:48:15.490
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m15s

word in this huge long thing which is
01:48:18.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m18s

all of the IMDB movie reviews
01:48:21.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m21s

concatenated together so this thing is
01:48:23.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m23s

you know what do we say it was like tens
01:48:25.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m25s

of millions of words long and so what we
01:48:28.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m28s

do is we split it up into batches first
01:48:31.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m31s

right so these like aerial spits into
01:48:37.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m37s

batches right and so if we said we want
01:48:39.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m39s

a batch size of 64 we actually break the
01:48:43.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m43s

whatever it was sixty million words into
01:48:47.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m47s

64 sections right and then we take each
01:48:50.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m50s

one of the 64 sections and we move it
01:48:56.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h48m56s

like underneath the previous one I
01:49:04.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m04s

didn't do a great job of that
01:49:07.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m07s

all right move it underneath so we end
01:49:10.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m10s

up with a matrix which is
01:49:16.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m16s

you
01:49:25.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m25s

sixty-four actually I think we've moved
01:49:28.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m28s

them across twice so it's actually I
01:49:32.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m32s

think just transpose it we end up with
01:49:34.409
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m34s

the matrix it's like 64 columns wide and
01:49:36.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m36s

the length let's say the original was 64
01:49:40.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m40s

million right then the length is like 10
01:49:44.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m44s

million long right so each of these
01:49:48.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m48s

represents one sixty-fourth with our
01:49:51.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m51s

entire IMDB refused it all right and so
01:49:55.679
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m55s

that's our starting point so then what
01:49:59.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h49m59s

we do is we then grab a little chunk of
01:50:02.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m02s

this at a time and those chunk lengths
01:50:06.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m06s

are approximately equal to be PTT which
01:50:09.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m09s

I think we had equal to 70 so he
01:50:14.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m14s

basically grab a little 70 long section
01:50:15.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m15s

and that's the first thing we check into
01:50:20.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m20s

our GPU that's a batch right so a batch
01:50:22.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m22s

is always of length of width 64 or batch
01:50:26.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m26s

size and each bit is a sequence of
01:50:29.909
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m29s

length up to 70 so let me show you all
01:50:33.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m33s

right so here if I go take my train data
01:50:37.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m37s

loader I know if you folks have tried
01:50:41.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m41s

playing with this yet but you can take
01:50:44.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m44s

any data loader wrap it with inner -
01:50:45.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m45s

turn it into an iterator and then call
01:50:48.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m48s

next on it to grab a batch of data just
01:50:50.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m50s

as if you were a neural net you get
01:50:54.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m54s

exactly what the neuron that gets and
01:50:55.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m55s

you can see here we get back a 75 by 64
01:50:57.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h50m57s

sensor right so it's 64 wide right and I
01:51:03.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m03s

said it's approximately 70 high and but
01:51:08.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m08s

not exactly and that's actually kind of
01:51:13.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m13s

interesting a really neat trick that
01:51:16.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m16s

torch text does is they randomly change
01:51:18.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m18s

the backprop through time number every
01:51:22.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m22s

time so each epoch it's getting slightly
01:51:25.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m25s

different bits of text this is kind of
01:51:28.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m28s

like in computer vision we randomly
01:51:33.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m33s

shuffle the images we can't randomly
01:51:35.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m35s

shuffle the words right because we
01:51:38.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m38s

needed to be in the right order so
01:51:41.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m41s

instead we randomly move their
01:51:42.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m42s

breakpoints a little bit okay so this is
01:51:44.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m44s

the equivalent so in other words this
01:51:46.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m46s

this here is of length 75 right there's
01:51:54.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m54s

a there's an ellipsis in the middle and
01:51:59.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h51m59s

that represents the first 75 words of
01:52:01.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m01s

the first review right where else this
01:52:05.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m05s

75 here represents the first 75 words of
01:52:07.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m07s

this of the second of the 64 segments
01:52:12.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m12s

let's it have to go in like 10 million
01:52:15.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m15s

words to find that one right and so
01:52:17.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m17s

here's the first 75 words of the last of
01:52:20.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m20s

those 64 segments okay and so then what
01:52:23.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m23s

we have down here is the next sequence
01:52:27.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m27s

right so 51 there's 51 6 1 5 there's 6 1
01:52:35.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m35s

5 25 is 25 right and in this case it
01:52:41.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m41s

actually is of the same size it's also
01:52:46.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m46s

75 plus 64
01:52:48.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m48s

but for minor technical reasons it's
01:52:50.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m50s

being flattened out into a single vector
01:52:52.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m52s

but basically it's exactly the same at
01:52:54.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m54s

this matrix but it's just moved down by
01:52:58.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h52m58s

one because we're trying to predict the
01:53:01.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m01s

next word right so that all happens for
01:53:05.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m05s

us right if we ask for and this is the
01:53:08.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m08s

first date I know if you ask for a
01:53:11.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m11s

language model data object then it's
01:53:13.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m13s

going to create these batches of batch
01:53:17.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m17s

size width by B PTT height bits of our
01:53:20.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m20s

language corpus along with the same
01:53:26.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m26s

thing shuffled along by one word right
01:53:29.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m29s

and so we're always going to try and
01:53:32.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m32s

predict the next word
01:53:34.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m34s

yes
01:53:37.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m37s

so why don't you instead of just
01:53:40.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m40s

arbitrarily choosing 64 why don't you
01:53:44.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m44s

choose like like 64 is a large number
01:53:49.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m49s

maybe like stood by sentences and make
01:53:52.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m52s

it a large number and then padded with
01:53:56.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m56s

zero or something if you you know so
01:53:58.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h53m58s

that you actually have a one full
01:54:03.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m03s

sentence per line basically wouldn't
01:54:04.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m04s

that make more sense not really because
01:54:07.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m07s

remember we're using columns right so
01:54:09.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m09s

each of our columns is of length about
01:54:10.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m10s

10 million right so although it's true
01:54:12.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m12s

that those columns aren't always exactly
01:54:15.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m15s

finishing on a full stop there's so damn
01:54:17.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m17s

long we don't care because they're like
01:54:20.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m20s

10 million won and we're trying to also
01:54:23.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m23s

line contains multiple cents incentive
01:54:27.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m27s

column contains more costumes and sorry
01:54:30.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m30s

yeah it's of length about 10 million and
01:54:33.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m33s

it contains many many many many many
01:54:35.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m35s

sentences because remember the first
01:54:38.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m38s

thing we did was take all thing and
01:54:40.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m40s

split it into 64 groups
01:54:42.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m42s

okay great so um I found this you know
01:54:47.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m47s

pertaining to this question this thing
01:54:53.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m53s

about like what's in this language model
01:54:55.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m55s

matrix a little mind-bending for quite a
01:54:58.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h54m58s

while so don't worry if it takes a while
01:55:01.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m01s

and you have to ask a thousand questions
01:55:04.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m04s

on the forum that's fine right but go
01:55:05.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m05s

back and listen to what I just said in
01:55:10.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m10s

this lecture again go back to that bit
01:55:11.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m11s

where I showed you splitting it up to 64
01:55:13.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m13s

and moving them around and try it with
01:55:14.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m14s

some sentences in Excel or something and
01:55:16.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m16s

see if you can do a better job of
01:55:18.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m18s

explaining it than I did okay because
01:55:21.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m21s

this is like how torch text works and
01:55:23.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m23s

then what fast AI adds on is this idea
01:55:27.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m27s

of like kind of how to build a a
01:55:30.159
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m30s

language model out of it well they'll
01:55:31.869
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m31s

actually a lot of that stolen from torch
01:55:34.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m34s

text as well like there's some times
01:55:35.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m35s

where torch text starts and fast AI ends
01:55:37.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m37s

is or vice versa trees a little saddle
01:55:39.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m39s

they really work closely together okay
01:55:42.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m42s

so now that we have a model data object
01:55:46.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m46s

that can feed us batches we can go ahead
01:55:51.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m51s

and create a model right and so in this
01:55:55.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m55s

case we're going to create an embedding
01:55:58.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h55m58s

matrix and our vocab we can see how big
01:56:01.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m01s

a vocab was let's have a look back here
01:56:05.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m05s

so we can see here in the model data
01:56:09.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m09s

object there are four thousand six
01:56:13.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m13s

hundred and two kind of pieces that
01:56:15.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m15s

we're going to go through that's
01:56:19.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m19s

basically equal to the number of the
01:56:20.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m20s

total length of everything divided by
01:56:24.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m24s

batch size times B PTT and this one I
01:56:26.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m26s

wanted to show you NT I've got the
01:56:29.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m29s

definition up here number of unique
01:56:32.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m32s

tokens NT is the number of tokens that's
01:56:34.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m34s

the size of our vocab so we've got three
01:56:36.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m36s

thirty four thousand nine hundred and
01:56:39.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m39s

forty five unique words and notice the
01:56:40.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m40s

unique words that had to appear at least
01:56:44.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m44s

ten times okay because otherwise they've
01:56:46.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m46s

been replaced with the length of the
01:56:49.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m49s

data set is one
01:56:56.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m56s

because as far as the language model is
01:56:58.389
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m58s

concerned there's only one thing which
01:56:59.860
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h56m59s

is the whole corpus all right and then
01:57:02.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m02s

that thing has I hear it is twenty point
01:57:05.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m05s

six million words you know right
01:57:08.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m08s

so those thirty four thousand hundred
01:57:12.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m12s

and forty five things are used to create
01:57:15.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m15s

an embedding matrix of number of rows is
01:57:17.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m17s

equal to thirty four nine four five
01:57:22.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m22s

right and so the first one represents
01:57:28.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m28s

UNK the second one represents pad the
01:57:31.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m31s

third one was dot the fourth one was
01:57:36.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m36s

comma with one under sketching was there
01:57:38.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m38s

and so forth right and so each one of
01:57:41.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m41s

these gets an embedding vector so this
01:57:44.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m44s

is literally identical to what we did
01:57:48.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m48s

before the brick right this is a
01:57:50.469
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m50s

categorical variable it's just a very
01:57:53.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m53s

high cardinality categorical variable
01:57:56.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m56s

and furthermore it's the only variable
01:57:58.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h57m58s

right this is pretty standard in NLP you
01:58:00.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m00s

have a variable which is a word right
01:58:03.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m03s

you have a single categorical variable
01:58:07.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m07s

single column basically and it's it's of
01:58:09.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m09s

thirty four thousand nine hundred forty
01:58:13.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m13s

five cardinality categorical variable
01:58:16.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m16s

and so we're going to create an
01:58:19.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m19s

embedding matrix for it so M size is the
01:58:20.949
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m20s

size of the omitting vector 200 okay
01:58:25.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m25s

so that's going to be length 200 a lot
01:58:28.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m28s

bigger than our previous embedding
01:58:31.119
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m31s

vectors not surprising because a word
01:58:32.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m32s

has a lot more nuance to it than the
01:58:34.719
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m34s

concept of Sunday right or Russ means
01:58:37.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m37s

Berlin's door or whatever right so it's
01:58:42.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m42s

generally an embedding size for a word
01:58:45.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m45s

will be somewhere between about 50 and
01:58:47.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m47s

about 600 okay so I've kind of done some
01:58:49.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m49s

in the middle we then have to say as per
01:58:52.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m52s

usual how many activations do you want
01:58:56.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m56s

in your layers so we're going to use 500
01:58:58.659
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h58m58s

and then how many layers do you want in
01:59:01.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m01s

your neural net we're going to use three
01:59:02.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m02s

okay this is a minor technical detail it
01:59:04.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m04s

turns out
01:59:10.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m10s

that we're going to learn later about
01:59:11.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m11s

the atom optimizer that basically the
01:59:13.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m13s

defaults for it don't work very well
01:59:16.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m16s

with these kinds of models so you just
01:59:17.700
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m17s

have to change some of these you know
01:59:19.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m19s

basically any time you're doing NLP you
01:59:21.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m21s

should probably include this mine
01:59:24.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m24s

because it works pretty well so having
01:59:27.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m27s

done that we can now again take our
01:59:31.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m31s

model data object and grab a model out
01:59:34.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m34s

of it and we can pass in a few different
01:59:36.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m36s

things
01:59:38.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m38s

what optimization function do we want
01:59:38.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m38s

how big an embedding do we want
01:59:41.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m41s

how many hidden activate how many
01:59:43.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m43s

activations number of Hitler how many
01:59:45.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m45s

layers and how much drop out of many
01:59:47.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m47s

different kinds so this language model
01:59:51.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m51s

we're going to use is a very recent
01:59:55.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m55s

development called AWD LS TM by Steven
01:59:56.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=01h59m56s

marady who's a NLP research based in San
02:00:00.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m00s

Francisco and his main contribution
02:00:03.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m03s

really was to show like how to put drop
02:00:05.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m05s

out all over the place in in these NLP
02:00:09.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m09s

models so we're not going to worry now
02:00:13.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m13s

we'll do this in the last lecture is
02:00:15.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m15s

worrying about like what all that like
02:00:17.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m17s

what is the architecture and what are
02:00:18.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m18s

all these dropouts
02:00:20.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m20s

for now just know is the same as per
02:00:21.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m21s

usual if you try to build an NLP model
02:00:24.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m24s

and draw underfitting
02:00:26.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m26s

and decrease all of these dropouts if
02:00:28.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m28s

you're overfitting then increase all of
02:00:31.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m31s

these dropouts in roughly this ratio
02:00:33.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m33s

okay that's that's my rule of thumb and
02:00:36.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m36s

again this is such a recent paper nobody
02:00:39.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m39s

else is working on this model anyway so
02:00:44.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m44s

there's not a lot of guidance but I
02:00:45.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m45s

found this these ratios worked well it's
02:00:47.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m47s

what Stephens been using as well there's
02:00:50.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m50s

another kind of way we can avoid
02:00:53.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m53s

overfitting that we'll talk about in the
02:00:55.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m55s

last class again for now this one
02:00:57.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m57s

actually works totally reliably so all
02:00:59.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h00m59s

of your NLP models probably want this
02:01:02.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m02s

particular line of code and then this
02:01:04.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m04s

point we're going to talk about at the
02:01:09.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m09s

end last lecture as well you can always
02:01:10.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m10s

improve this basically what it says is
02:01:12.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m12s

when you do when you look at your
02:01:17.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m17s

gradients and you multiply them by the
02:01:20.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m20s

learning rate and you decide how much to
02:01:21.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m21s

update you
02:01:23.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m23s

or weights by this is clip them like
02:01:24.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m24s

literally like sit like don't let them
02:01:29.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m29s

be more than 0.3 and this is quite a
02:01:32.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m32s

cool little trick right because like if
02:01:36.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m36s

you're learning rates pretty high and
02:01:41.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m41s

you kind of don't want to get in that
02:01:43.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m43s

situation we talked about where you're
02:01:45.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m45s

kind of got this kind of thing where you
02:01:49.110
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m49s

go
02:01:51.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m51s

you know rather than little snippets
02:01:54.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m54s

that little step instead you go like Oh
02:01:55.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m55s

too big Oh too big right with gradient
02:01:57.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h01m57s

clipping it kind of goes this far and
02:02:01.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m01s

it's like oh my goodness I'm going too
02:02:03.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m03s

far I'll stop and that's basically what
02:02:05.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m05s

gradient flipping does so anyway so
02:02:07.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m07s

these are a bunch of parameters the
02:02:12.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m12s

details don't matter too much right now
02:02:14.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m14s

you can just deal these and then we can
02:02:15.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m15s

go ahead and call fit with exactly the
02:02:19.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m19s

same parameters as usual so Jeremy um
02:02:23.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m23s

there are all this other work embedding
02:02:30.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m30s

things like like worked vague and glow
02:02:35.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m35s

so I have two questions about that one
02:02:38.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m38s

is how are those different from these
02:02:41.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m41s

and the second question why don't you
02:02:44.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m44s

initialize them with one of those yeah
02:02:47.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m47s

so so basically that's a great question
02:02:50.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m50s

so basically people have pre trained
02:02:54.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m54s

these embedding matrices before to do
02:02:57.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h02m57s

various other tasks they're not called
02:03:00.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m00s

pre-trained models they're just a pre
02:03:02.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m02s

trained embedding matrix and you can
02:03:04.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m04s

download them and as unit says they have
02:03:06.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m06s

names like word to Veck and love and
02:03:09.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m09s

they're literally just a matrix there's
02:03:11.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m11s

no reason we couldn't download them
02:03:15.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m15s

really it's just like kind of I found
02:03:17.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m17s

that building a whole pre-trained model
02:03:24.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m24s

in this way didn't seem to benefit much
02:03:27.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m27s

if at all from using pre trained word
02:03:30.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m30s

vectors where else using a whole
02:03:32.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m32s

pre-trained language model made a much
02:03:33.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m33s

bigger difference so I can remember what
02:03:36.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m36s

a big those of you who saw word Tyvek it
02:03:38.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m38s

made a big splash when it came out
02:03:40.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m40s

I mean I'm finding this technique of
02:03:43.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m43s

pre-trained language models seems much
02:03:46.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m46s

more powerful basically but I think we
02:03:48.990
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m48s

can combine both to make them a little
02:03:51.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m51s

better still what what is the model that
02:03:52.740
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m52s

you have used like how can I know that
02:03:57.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m57s

architecture of the model
02:03:58.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h03m58s

so we'll be learning about the model
02:04:01.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m01s

architecture in the last lesson and for
02:04:03.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m03s

now it's a recurrent neural network
02:04:05.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m05s

using something called an LS TN long
02:04:08.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m08s

short-term memory okay so so if they had
02:04:10.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m10s

lots of details that we're skipping over
02:04:18.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m18s

but you know you can do all this without
02:04:20.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m20s

any of those details we go ahead and fit
02:04:22.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m22s

the model I found that this language
02:04:25.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m25s

model took quite a while to fit so I
02:04:28.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m28s

kind of like ran it for a while
02:04:29.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m29s

noticed it was still under fitting safer
02:04:31.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m31s

it was up to ran it a bit more longer
02:04:34.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m34s

cycle length saved it again it still was
02:04:37.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m37s

kind of under fitting you know run it
02:04:40.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m40s

again and kind of finally got to the
02:04:43.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m43s

point where it's like kind of honestly I
02:04:45.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m45s

kind of ran out of patience so I just
02:04:47.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m47s

like saved it at that point and I did
02:04:49.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m49s

the same kind of tests that we looked at
02:04:54.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m54s

before so I was like oh it wasn't quite
02:04:55.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m55s

expecting but I realized it anyway the
02:04:58.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m58s

best and the most like okay let's see
02:04:59.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h04m59s

how that goes the best performance with
02:05:01.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m01s

one movie were I say okay it looks like
02:05:03.090
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m03s

the language models working pretty well
02:05:05.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m05s

so I've pre-trained a language model and
02:05:07.610
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m07s

so now I want to use it fine tune it to
02:05:13.470
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m13s

do classification sentiment
02:05:16.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m16s

classification now obviously if I'm
02:05:18.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m18s

gonna use a pre trained model I need to
02:05:20.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m20s

use exactly the same vocab but the the
02:05:22.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m22s

word the still needs to map for the
02:05:25.050
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m25s

number two so that I can look up the
02:05:27.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m27s

vector that right so that's why I first
02:05:29.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m29s

of all load back up my my field object
02:05:33.510
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m33s

the thing with the vocab in right now in
02:05:37.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m37s

this case if I ran it straight
02:05:40.410
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m40s

afterwards this is unnecessary it's
02:05:42.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m42s

already in memory but this means I can
02:05:44.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m44s

come back to this later right in a new
02:05:46.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m46s

session basically I can then go ahead
02:05:49.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m49s

and say okay I've never got one more
02:05:55.140
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m55s

field right in addition to my field
02:05:56.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m56s

which represents the reviews I've also
02:05:59.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h05m59s

got a field which represents the label
02:06:02.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m02s

okay and the details are too important
02:06:04.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m04s

here now this time I need to not treat
02:06:08.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m08s

the whole thing as one
02:06:12.240
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m12s

big piece of text but every review is
02:06:13.739
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m13s

separate because each one has a
02:06:16.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m16s

different sentiment attached to it but
02:06:18.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m18s

it so happens that torch text already
02:06:20.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m20s

has a data set that does that for IMDB
02:06:22.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m22s

so I just used IMDB built into torch
02:06:25.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m25s

text so basically once we've done all
02:06:29.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m29s

that we end up with something where we
02:06:32.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m32s

can like grab for a particular example
02:06:33.989
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m33s

or you can grab its label positive and
02:06:36.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m36s

here's some of the text this is another
02:06:39.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m39s

great Tom Berenger movie all right so
02:06:41.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m41s

this is all not nothing faster I
02:06:45.950
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m45s

specific here we'll come back to it in
02:06:48.989
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m48s

the last lecture but torch text Docs can
02:06:50.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m50s

help understand what's going on all you
02:06:53.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m53s

need to know is that once you've used
02:06:55.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m55s

this special tox torch text thing called
02:06:57.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h06m57s

splits to grab a Spitz object you can
02:07:00.390
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m00s

passed it straight into faster a text
02:07:03.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m03s

data from splits and that basically
02:07:06.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m06s

converts a torch text object into a fast
02:07:08.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m08s

AI object we can train on so as soon as
02:07:12.270
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m12s

you've done that you can just go ahead
02:07:15.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m15s

and say get model right and that gets us
02:07:17.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m17s

our learner and then we can load into it
02:07:20.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m20s

the pre trained model the language model
02:07:23.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m23s

right and so we can now take that
02:07:26.960
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m26s

pre-trained language model and use the
02:07:29.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m29s

stuff that we're kind of familiar with
02:07:32.580
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m32s

right so we can make sure all that you
02:07:34.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m34s

know all its at the last layers frozen
02:07:37.350
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m37s

training a bit unfreeze it train it a
02:07:39.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m39s

bit and the nice thing is once you've
02:07:42.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m42s

got a pre trained language model it
02:07:44.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m44s

actually trains super fast you can see
02:07:47.430
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m47s

here it's like a couple of minutes for
02:07:49.020
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m49s

epoch and it only took me to get my is
02:07:51.360
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m51s

my best one here and he took me like 10
02:07:55.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m55s

a box so it's like 20 minutes to train
02:07:57.210
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m57s

this bit it's really fast and I ended up
02:07:59.910
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h07m59s

with 94.5% so how gone is 94.5% well it
02:08:03.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m03s

so happens that actually one of Steven
02:08:10.590
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m10s

verities colleagues James Bradbury
02:08:14.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m14s

recently created a paper looking at the
02:08:15.600
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m15s

state at like
02:08:21.450
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m21s

they tried to create a new state of the
02:08:22.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m22s

art for a bunch of NLP things and one of
02:08:23.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m23s

the things that looked at was IMDB and
02:08:25.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m25s

they actually have here a list of the
02:08:28.720
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m28s

current world's best for IMDB and even
02:08:31.330
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m31s

with stuff that is highly specialized
02:08:36.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m36s

for sentiment analysis the best anybody
02:08:38.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m38s

had previously come up with 94.1 so in
02:08:40.750
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m40s

other words this technique getting 94.5
02:08:44.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m44s

it's literally better than anybody has
02:08:47.980
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m47s

created in the world before as far as we
02:08:51.850
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m51s

know or as far as James Bradbury knows
02:08:55.120
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m55s

so so when I say like there are big
02:08:57.130
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h08m57s

opportunities to use this I mean like
02:09:01.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m01s

this is a technique that nobody else
02:09:03.190
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m03s

currently has access to which you know
02:09:05.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m05s

you could like you know whatever iBM has
02:09:08.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m08s

in what CERN or whatever any big company
02:09:12.070
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m12s

has you know that they're advertising
02:09:14.440
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m14s

unless they have some secret sauce that
02:09:17.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m17s

they're not publishing which they don't
02:09:19.540
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m19s

right because people get you know if
02:09:21.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m21s

they have a better thing they publish it
02:09:23.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m23s

then you now have access to a better
02:09:24.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m24s

text classification method then has ever
02:09:27.370
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m27s

existed before so I really hope that you
02:09:29.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m29s

know you can try this out and see how
02:09:32.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m32s

you go there may be some things it works
02:09:34.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m34s

really well on and others that it
02:09:39.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m39s

doesn't work as well and I don't know I
02:09:40.630
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m40s

think this kind of sweet spot here that
02:09:42.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m42s

we had about 25,000 you know short to
02:09:46.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m46s

medium size documents if you don't have
02:09:50.320
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m50s

at least that much text it may be hard
02:09:52.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m52s

to train a different language model but
02:09:55.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m55s

having said that there's a lot more we
02:09:57.550
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m57s

do here right and we won't be able to do
02:09:59.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h09m59s

it in part 1 of this course but in part
02:10:01.660
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m01s

2 that for example we could start like
02:10:03.310
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m03s

training language models that look at
02:10:06.160
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m06s

like you know lots and lots of medical
02:10:08.680
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m08s

journals and then we could like make a
02:10:11.230
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m11s

downloadable medical language model that
02:10:13.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m13s

then anybody could use to like fine tune
02:10:15.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m15s

on like a prostate cancer subset of
02:10:18.220
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m18s

medical literature for instance like
02:10:21.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m21s

there's so much we could do it's kind of
02:10:23.970
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m23s

exciting and then you know to the next
02:10:26.830
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m26s

point we could also combine this with
02:10:28.810
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m28s

like pre-trained word vectors it's like
02:10:30.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m30s

even without trying that hard like
02:10:32.890
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m32s

you know we even without use like we
02:10:36.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m36s

could have pre-trained a Wikipedia say
02:10:39.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m39s

corpus language model and then
02:10:41.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m41s

fine-tuned it into a IMDB language model
02:10:43.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m43s

and then fine tune that into an IBM IMDB
02:10:47.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m47s

sentiment analysis model and we would
02:10:49.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m49s

have got something better than this so
02:10:51.640
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m51s

like this I really think this is the tip
02:10:54.489
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m54s

of the iceberg and I was talking there's
02:10:56.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h10m56s

a really fantastic researcher called
02:11:00.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m00s

Sebastian Reuter who is basically the
02:11:02.920
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m02s

only NLP researcher I know who's been
02:11:05.770
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m05s

really really writing a lot about
02:11:07.989
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m07s

pre-training and fine tuning and
02:11:10.620
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m10s

transfer learning and NLP and I was
02:11:13.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m13s

asking him like why isn't this happening
02:11:15.250
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m15s

more and his view was it's because there
02:11:17.290
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m17s

isn't the software to make it easy you
02:11:20.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m20s

know so I'm actually going to share this
02:11:23.380
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m23s

lecture with with him tomorrow because
02:11:25.570
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m25s

you know it feels like there's you know
02:11:29.800
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m29s

hopefully gonna be a lot of stuff coming
02:11:32.560
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m32s

out now that we're making it really easy
02:11:34.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m34s

to do this ok we're kind of out of time
02:11:36.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m36s

so what I'll do is I'll quickly look at
02:11:43.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m43s

collaborative filtering introduction and
02:11:45.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m45s

then we'll finish it next time but
02:11:48.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m48s

collaborative filtering there's very
02:11:50.530
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m50s

very little new to learn
02:11:52.060
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m52s

we've basically learned everything we're
02:11:53.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m53s

gonna need so collaborative filtering
02:11:55.900
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m55s

will will cover this quite quickly next
02:11:59.500
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h11m59s

week and then we're going to do a really
02:12:02.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m02s

deep dive into collaborative filtering
02:12:04.030
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m04s

next week where we're going to learn
02:12:06.280
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m06s

about like we're actually going to from
02:12:09.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m09s

scratch learn how to do mr. plastic
02:12:10.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m10s

gradient descent how to create loss
02:12:13.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m13s

functions how they work exactly
02:12:15.969
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m15s

and then we'll grow from there and will
02:12:18.100
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m18s

gradually build back up to really deeply
02:12:19.690
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m19s

understand what's going on in the
02:12:22.180
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m22s

structured models and then what's going
02:12:25.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m25s

on in confidence and then finally what's
02:12:27.340
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m27s

going on in recurrent neural networks
02:12:28.930
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m28s

and hopefully we'll be able to build
02:12:30.520
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m30s

them all from scratch
02:12:32.080
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m32s

ok so this is kind of a gonna be really
02:12:33.790
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m33s

important this movie lens data set
02:12:36.400
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m36s

because we've got a user to learn a lot
02:12:38.200
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m38s

of like really foundational theory and
02:12:39.730
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m39s

kind of math behind it so the movie lens
02:12:43.420
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m43s

data set this is basically what it looks
02:12:46.780
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m46s

like
02:12:49.870
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m49s

it contains a bunch of ratings it says
02:12:50.260
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m50s

user number one watched movie number 31
02:12:52.840
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m52s

and they gave it a rating of two and a
02:12:56.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m56s

half at this particular time and then
02:12:58.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h12m58s

they watched movie 102 nine and they
02:13:02.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m02s

gave it a rating of three and they
02:13:05.289
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m05s

watched reading one one's really one one
02:13:06.460
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m06s

seven two and they gave it a rating
02:13:08.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m08s

before okay and so forth okay so this is
02:13:09.099
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m09s

the ratings table this is really the
02:13:12.519
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m12s

only one that matters and our goal will
02:13:13.929
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m13s

be for some use that we haven't seen
02:13:17.559
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m17s

before so for some user movie
02:13:19.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m19s

combination we haven't seen before we
02:13:22.599
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m22s

have to predict if they'll like it right
02:13:24.429
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m24s

and so this is how recommendation
02:13:26.650
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m26s

systems are built this is how like
02:13:28.449
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m28s

Amazon besides what books to recommend
02:13:30.039
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m30s

how Netflix decides what movies to
02:13:31.809
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m31s

recommend and so forth
02:13:33.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m33s

to make it more interesting we'll also
02:13:36.480
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m36s

actually download a list of movies so
02:13:39.010
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m39s

each movie we're actually gonna have the
02:13:41.170
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m41s

title and so for that question earlier
02:13:42.760
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m42s

about like what's actually going to be
02:13:44.710
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m44s

in these embedding matrices how do we
02:13:46.239
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m46s

interpret them we're actually going to
02:13:47.829
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m47s

be able to look and see how that's
02:13:49.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m49s

working so basically this is kind of
02:13:51.699
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m51s

like what we're creating this is kind of
02:13:54.880
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m54s

crosstab of users by movies alright and
02:13:57.670
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h13m57s

so feel free to look ahead during the
02:14:02.079
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m02s

week you'll see basically as per usual
02:14:03.940
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m03s

collaborative data set from CSP model
02:14:06.150
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m06s

data docket learner learn it and we're
02:14:09.639
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m09s

done and don't be surprised to hear when
02:14:12.579
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m12s

we then take that and we can kick the
02:14:14.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m14s

benchmarks it seems to be better than
02:14:16.000
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m16s

the benchmarks where you look at so
02:14:17.619
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m17s

that'll basically be it and then next
02:14:19.329
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m19s

week we'll have a deep dive and we'll
02:14:21.789
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m21s

see how to actually build this from
02:14:23.199
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m23s

scratch alright see you next week
02:14:25.300
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m25s

thank you
02:14:27.820
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m27s

[Applause]
02:14:29.040
https://www.youtube.com/watch?v=gbceqO8PpBg#t=02h14m29s

