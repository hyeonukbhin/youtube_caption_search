welcome back less than six so this is
00:00:00.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m00s

our penultimate lesson and believe it or
00:00:02.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m02s

not a couple of weeks ago in Lesson four
00:00:09.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m09s

I mentioned I was going to share that
00:00:15.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m15s

lesson with this terrific you know P
00:00:17.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m17s

researcher Sebastian Reuter which I did
00:00:19.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m19s

and he he said he loved it and he's gone
00:00:22.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m22s

on to yesterday released this new post
00:00:25.529
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m25s

he called optimization for deep learning
00:00:29.189
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m29s

highlights in 2017 in which he covered
00:00:31.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m31s

basically everything that we talked
00:00:34.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m34s

about in that lesson and with some very
00:00:36.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m36s

nice shout outs to some of the work that
00:00:40.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m40s

some of the students here have done
00:00:42.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m42s

including when he talked about this
00:00:43.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m43s

separation of the separation of weight
00:00:46.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m46s

decay from the momentum term and so he
00:00:53.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m53s

actually mentions here the opportunities
00:00:58.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h00m58s

in terms of improved kind of software
00:01:01.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m01s

decoupling this allows and actually
00:01:04.199
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m04s

links to the commits from an answer hah
00:01:06.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m06s

actually showing how to implement this
00:01:11.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m11s

in fast AI so first a eyes code is
00:01:13.799
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m13s

actually being used as a bit of a role
00:01:16.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m16s

model now he then covers some of these
00:01:18.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m18s

learning rate tuning techniques that
00:01:23.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m23s

we've talked about and this is the SGD
00:01:25.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m25s

our schedule it looks a bit different to
00:01:31.829
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m31s

what you're used to seeing this is on a
00:01:33.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m33s

log curve this is the way that they show
00:01:34.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m34s

it on the paper and for more information
00:01:36.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m36s

again links to two blog posts one from
00:01:40.439
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m40s

vitaly about this topic and and again
00:01:44.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m44s

ananza ha is blog post on this topic so
00:01:49.649
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m49s

it's great to see that some of the work
00:01:53.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m53s

from faster our students is already
00:01:55.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m55s

getting noticed and picked up and shared
00:01:58.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h01m58s

and this blog post went on to get on the
00:02:00.659
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m00s

front page of hacker news so that's
00:02:02.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m02s

pretty cool and hopefully more and more
00:02:06.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m06s

of this work or be picked up on sisters
00:02:09.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m09s

released
00:02:11.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m11s

publicly so last week we were kind of
00:02:12.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m12s

doing a deep dive into collaborative
00:02:19.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m19s

filtering and let's remind ourselves of
00:02:21.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m21s

kind of what our final model looked like
00:02:27.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m27s

so in the end we kind of ended up
00:02:34.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m34s

rebuilding the model that's actually in
00:02:36.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m36s

the first a a library where we had an
00:02:42.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m42s

embedding so we had this little get
00:02:47.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m47s

embedding function that grabbed an
00:02:49.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m49s

embedding and randomly initialize the
00:02:51.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m51s

weights for the users and for the items
00:02:54.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m54s

that's the kind of generic term in our
00:02:59.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h02m59s

case the items are movies
00:03:01.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m01s

and the bias for the users the bias for
00:03:02.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m02s

the items and we had n factors embedding
00:03:04.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m04s

size for each for each one of course the
00:03:09.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m09s

biases just had a single one and then we
00:03:11.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m11s

grabbed the users and item in weddings
00:03:14.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m14s

multiply them together summed it up each
00:03:15.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m15s

row and add it on the bias terms pop
00:03:18.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m18s

that through a sigmoid to put it into
00:03:22.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m22s

the range that we wanted so that was our
00:03:24.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m24s

model and one of you asked if we can
00:03:27.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m27s

kind of interpret this information in
00:03:33.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m33s

some way and I promised this week we
00:03:35.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m35s

would see how to do that so let's take a
00:03:37.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m37s

look so we're going to start with the
00:03:39.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m39s

model we built here where we just used
00:03:42.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m42s

that fast AI library
00:03:44.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m44s

collaborative data set from CSP and then
00:03:46.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m46s

that get learner and then we fitted it
00:03:49.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m49s

in three epochs 19 seconds we've got a
00:03:52.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m52s

pretty good result so what we can now do
00:03:58.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h03m58s

is to analyze that model so you may
00:04:02.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m02s

remember right back when we started we
00:04:09.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m09s

read in the movies CSV file but that's
00:04:11.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m11s

just a mapping from the ID of the movie
00:04:15.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m15s

to the name of the movie and so we're
00:04:17.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m17s

just going to use that for display
00:04:19.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m19s

purposes so we can see what we're doing
00:04:21.049
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m21s

because
00:04:24.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m24s

not all of us have watched every movie
00:04:25.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m25s

I'm just going to limit this to the top
00:04:27.639
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m27s

500 most populous or 3,000 most popular
00:04:30.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m30s

movies so we might have more chance of
00:04:33.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m33s

recognizing the movies we're looking at
00:04:34.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m34s

and then I'll go ahead and change it
00:04:36.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m36s

from the movie IDs from movie lens to
00:04:39.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m39s

those unique IDs that we're using the
00:04:43.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m43s

contiguous IDs because that's what a
00:04:46.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m46s

model has alright so inside the learn
00:04:47.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m47s

object that we create inside alona we
00:04:57.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h04m57s

can always grab the PI torch model
00:05:00.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m00s

itself just by saying learn model okay
00:05:03.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m03s

and like I'm going to kind of show you
00:05:07.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m07s

more and more of the code at the moment
00:05:09.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m09s

so let's take a look at the definition
00:05:12.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m12s

of model and so a model is a property so
00:05:14.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m14s

if you haven't seen a property before a
00:05:20.169
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m20s

property is just something in Python
00:05:21.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m21s

which looks like a method when you
00:05:23.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m23s

define it that you can call it without
00:05:26.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m26s

parentheses as we do here alright and so
00:05:29.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m29s

it kind of looks when you call it like
00:05:32.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m32s

it's a regular attribute but it looks
00:05:34.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m34s

like when you define it like it's a
00:05:36.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m36s

method so every time you call it it
00:05:37.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m37s

actually runs this code okay and so in
00:05:40.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m40s

this case it's just a shortcut to grab
00:05:42.669
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m42s

something called dot models model so you
00:05:44.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m44s

may be interested to know what that
00:05:48.789
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m48s

looks like
00:05:49.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m49s

learn about models and so this is
00:05:50.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m50s

there's a fast AI model type is a very
00:05:54.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m54s

thin wrapper for pite watch models so we
00:05:59.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h05m59s

could take a look at this code filter
00:06:03.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m03s

model and see what that is it's only one
00:06:06.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m06s

line of code okay and yeah we'll talk
00:06:13.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m13s

more about these in part two right but
00:06:19.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m19s

basically that there's this very thin
00:06:21.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m21s

wrapper and the main thing one of the
00:06:23.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m23s

main things that fast i out does is we
00:06:25.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m25s

have this concept of layer groups where
00:06:26.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m26s

basically when you say here though
00:06:28.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m28s

different learning rates and they're
00:06:30.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m30s

going to apply two different sets of
00:06:31.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m31s

layers and that's something that's not
00:06:33.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m33s

in paid watch so when you say I want to
00:06:35.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m35s

use this PI torch model
00:06:36.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m36s

all this with one thing we have to do
00:06:39.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m39s

which is to say like okay one hour later
00:06:41.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m41s

groups yeah so the details aren't
00:06:42.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m42s

terribly important but in general if you
00:06:44.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m44s

want to create a little wrapper for some
00:06:47.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m47s

other pipe watch model you could just
00:06:49.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m49s

write something like this so to get to
00:06:51.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m51s

get inside that to grab the actual PI
00:06:56.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m56s

torch model itself its models dot model
00:06:58.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h06m58s

that's the PI torch model and then the
00:07:02.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m02s

learn object has a shortcut to that okay
00:07:04.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m04s

so we're going to set m to be the PI
00:07:07.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m07s

torch model and so when you print out a
00:07:11.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m11s

pipe watch model it prints it out
00:07:14.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m14s

basically by listing out all of the
00:07:16.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m16s

layers that you created in the
00:07:19.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m19s

constructor it's quite it's quite nifty
00:07:22.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m22s

actually when you kind of think about
00:07:24.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m24s

the way this works thanks to kind of
00:07:26.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m26s

some very handy stuff in Python we're
00:07:28.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m28s

actually able to use standard - oh wow
00:07:32.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m32s

to kind of define these modules in these
00:07:34.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m34s

layers and they basically automatically
00:07:39.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m39s

kind of register themselves with pipe
00:07:41.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m41s

which so back in our embedding bias we
00:07:44.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m44s

just had a bunch of things where we said
00:07:48.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m48s

okay each of these things are equal to
00:07:49.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m49s

these things and then it automatically
00:07:52.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m52s

knows how to represent that so you can
00:07:54.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m54s

see there's the name is you and so the
00:07:57.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h07m57s

name is just literally whatever we
00:08:00.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m00s

called it yeah you
00:08:02.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m02s

and then the definition is it's this
00:08:05.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m05s

kind of layer okay so that's our height
00:08:07.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m07s

watch model so we can look inside that
00:08:12.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m12s

basically use that so if we say m dot I
00:08:18.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m18s

be then that's referring to the
00:08:21.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m21s

embedding layer for an item which is the
00:08:24.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m24s

bias layer so an item bias in this case
00:08:28.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m28s

is the movie bias so each move either a
00:08:31.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m31s

9000 of them has a single bias element
00:08:34.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m34s

okay now the really nice thing about
00:08:38.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m38s

high torch layers and models is that
00:08:40.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m40s

they all look the same they basically
00:08:45.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m45s

got to use them you call them as if they
00:08:48.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m48s

were
00:08:50.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m50s

action so we can go m.i.b parenthesis
00:08:50.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m50s

right and that basically says I want you
00:08:54.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m54s

to return the value of that layer and
00:08:57.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h08m57s

that layer could be a full-on model
00:09:00.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m00s

right so to actually get a prediction
00:09:03.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m03s

from a play torch model you just I would
00:09:06.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m06s

go m and pass in my variable okay and so
00:09:08.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m08s

in this case my B and pass in my top
00:09:12.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m12s

movie indexes now models remember layers
00:09:17.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m17s

they require variables not tensors
00:09:22.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m22s

because it needs to keep track of the
00:09:26.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m26s

derivatives okay and so we use this
00:09:29.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m29s

capital V to turn the tensor into a
00:09:31.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m31s

variable and was just announced this
00:09:34.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m34s

week that PI torch 0.4 which is the
00:09:37.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m37s

version after the one that's just about
00:09:42.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m42s

to be released is going to get rid of
00:09:44.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m44s

variables and will actually be able to
00:09:46.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m46s

use tensors directly to keep track of
00:09:49.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m49s

derivatives so if you're watching this
00:09:51.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m51s

on the MOOC and you're looking at point
00:09:53.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m53s

four then you'll probably notice that
00:09:55.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m55s

the code doesn't have this V unit
00:09:57.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m57s

anymore
00:09:58.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m58s

and so that would be pretty exciting
00:09:59.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h09m59s

when that happens but for now we have to
00:10:02.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m02s

remember if we're going to pass
00:10:04.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m04s

something into a model to turn it into a
00:10:05.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m05s

variable first and remember a variable
00:10:06.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m06s

has a strict superset of the API of a
00:10:09.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m09s

tensor so anything you can do to a
00:10:12.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m12s

tensor you can do to a variable and it
00:10:14.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m14s

up will take its log or whatever okay so
00:10:16.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m16s

that's going to return a variable which
00:10:20.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m20s

consists of going through each of these
00:10:23.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m23s

movie IDs putting it through this
00:10:24.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m24s

embedding layer to get its bias okay and
00:10:26.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m26s

that's going to return a variable let's
00:10:30.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m30s

take a look
00:10:36.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m36s

so before I press shift down to here you
00:10:41.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m41s

can have a think about what I'm going to
00:10:46.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m46s

have I've got a list of 3,000 movies
00:10:47.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m47s

going in turning into variable putting
00:10:50.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m50s

it through this embedding layer so just
00:10:53.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m53s

have a think about what we expect to
00:10:55.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m55s

come out okay and we have a variable of
00:10:56.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h10m56s

size 3,000 by one hopefully that doesn't
00:11:01.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m01s

surprise you
00:11:03.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m03s

we had 3000 movies that we are looking
00:11:04.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m04s

up each one hadn't had a one long
00:11:06.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m06s

embedding okay so there's our three
00:11:08.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m08s

thousand one you'll notice it's a
00:11:11.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m11s

variable just not surprising because we
00:11:12.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m12s

fed it a variable so we've got a
00:11:15.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m15s

variable back and it's a variable that's
00:11:16.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m16s

on the GPU right doc CUDA okay so we
00:11:18.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m18s

have a little shortcut in fast AI
00:11:24.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m24s

because we we very often when I take
00:11:26.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m26s

variables turn them into tensors and
00:11:28.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m28s

move them back to the CPU so we can play
00:11:31.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m31s

with them more easily
00:11:33.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m33s

so two NP is is two numpy okay and that
00:11:33.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m33s

does all of those things and it works
00:11:38.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m38s

regardless of whether it's a tensor or a
00:11:39.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m39s

variable it works regardless of whether
00:11:41.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m41s

it's on the CPU or GPU it'll end up
00:11:43.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m43s

giving you a a numpy array from that
00:11:45.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m45s

okay so if we do that that gives us
00:11:49.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m49s

exactly the same thing as we just looked
00:11:53.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m53s

at but now in numpy form okay so that's
00:11:54.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m54s

a super handy thing to use when you're
00:11:58.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h11m58s

playing around with pi torch my approach
00:12:01.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m01s

to things is I try to use numpy for
00:12:04.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m04s

everything except when I explicit and
00:12:09.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m09s

you need something to run on the GPU or
00:12:12.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m12s

I need its derivatives right in which
00:12:14.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m14s

case I use PI torch because like none
00:12:17.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m17s

part like I kind of find none PI's often
00:12:19.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m19s

easier to work with it's been around
00:12:22.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m22s

many years longer than PI torch so you
00:12:24.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m24s

know and lots of things like the Python
00:12:29.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m29s

imaging library OpenCV and lots and lots
00:12:32.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m32s

of stuff like pandas it works with numpy
00:12:35.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m35s

so my approach is kind of like do as
00:12:39.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m39s

much as I can in num pile and finally
00:12:41.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m41s

when I'm ready to do something on the
00:12:45.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m45s

GPU or take its derivative to PI torch
00:12:46.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m46s

and then as soon as I can I put it back
00:12:49.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m49s

in vampire and you'll see that the first
00:12:51.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m51s

AI library really works this way like
00:12:53.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m53s

all the transformations and stuff happen
00:12:55.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m55s

in lamb pie which is different to most
00:12:57.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h12m57s

high torch computer vision libraries
00:13:00.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m00s

which tend to do it all as much as
00:13:03.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m03s

possible in pi torch I try to do as much
00:13:05.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m05s

as possible in non pipe so let's say we
00:13:07.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m07s

wanted to transfer build a model in the
00:13:13.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m13s

GPU with the GPU and train it
00:13:15.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m15s

then we want to bring this to production
00:13:17.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m17s

so would we call to numpy on the model
00:13:21.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m21s

itself or would we have to iterate
00:13:24.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m24s

through all the different layers and
00:13:26.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m26s

then call to NP yeah good question so
00:13:28.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m28s

it's very likely that you want to do
00:13:31.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m31s

inference on a cpu rather than a GPU
00:13:33.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m33s

it's it's more scalable you don't have
00:13:36.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m36s

to worry about putting things in batches
00:13:38.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m38s

you know and so forth so you can move a
00:13:39.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m39s

model onto the cpu just by typing m dot
00:13:44.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m44s

CPU and that model is now on the cpu and
00:13:48.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m48s

so therefore you can also then put your
00:13:52.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m52s

variable on the CPU by doing exactly the
00:13:55.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m55s

same thing so you can say like so now
00:13:59.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h13m59s

having said that if you're if you'll
00:14:05.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m05s

serve it doesn't have a GPU or CUDA GPU
00:14:08.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m08s

you don't have to do this because it
00:14:10.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m10s

won't put it on the GPU at all so if for
00:14:12.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m12s

inferencing on the server if you're
00:14:17.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m17s

running it on you know some t2 instance
00:14:19.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m19s

or something it'll work fine and will
00:14:22.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m22s

run on the on the cpu automatically
00:14:24.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m24s

quick follow-up and if we train the
00:14:27.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m27s

model on the GPU and then we save those
00:14:30.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m30s

embeddings and the weights would we have
00:14:33.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m33s

to do anything special to load you know
00:14:37.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m37s

you won't we have something well it kind
00:14:40.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m40s

of depends how much of faster I you're
00:14:45.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m45s

using so I'll show you how you can do
00:14:46.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m46s

that in case you have to do it manually
00:14:49.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m49s

one of the students figure this out
00:14:51.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m51s

which is really handy when we there's a
00:14:54.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h14m54s

load model function and you'll see what
00:15:02.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m02s

it does but it does torch dot load is it
00:15:05.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m05s

basically this is like some magic
00:15:07.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m07s

incantation that like normally it has to
00:15:09.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m09s

load it onto the same GPU or saved on
00:15:12.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m12s

but this will like load it into what it
00:15:14.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m14s

was what it is available so there's a
00:15:16.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m16s

Andy discovery thanks for the great
00:15:19.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m19s

questions and
00:15:24.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m24s

to put that back on the GPU I'll need to
00:15:28.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m28s

say doc CUDA and now there we go I can
00:15:32.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m32s

run it again okay so it's really
00:15:36.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m36s

important to know about the zip function
00:15:41.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m41s

in Python which iterates through a
00:15:44.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m44s

number of lists at the same time so in
00:15:46.939
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m46s

this case I want to grab each movie
00:15:50.509
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m50s

along with its bias term so that I can
00:15:52.809
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m52s

just pop it into our list of tuples so
00:15:56.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m56s

if I just go zip like that that's going
00:15:58.279
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h15m58s

to iterate through each movie ID and
00:16:00.259
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m00s

each bias term and so then I can use
00:16:02.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m02s

that in a list comprehension to grab the
00:16:06.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m06s

name of each movie along with its place
00:16:08.629
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m08s

okay so having done that I can then sort
00:16:11.289
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m11s

and so here are I told you that John
00:16:16.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m16s

John Travolta Scientology movie at the
00:16:20.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m20s

most negative of the quiet by a lot if
00:16:24.259
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m24s

this was a cable competition Battlefield
00:16:26.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m26s

Earth would have like won by miles or
00:16:28.759
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m28s

this seven seven seven ninety six so
00:16:30.799
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m30s

here's the worst movie of all time
00:16:34.419
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m34s

according to IMDB and like it's
00:16:36.379
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m36s

interesting when you think about what
00:16:39.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m39s

this means right because this is like a
00:16:40.939
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m40s

much more authentic way to find out how
00:16:42.439
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m42s

bad this movie is because like some
00:16:44.329
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m44s

people are just more negative about
00:16:47.419
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m47s

movies right and like it more of them
00:16:49.459
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m49s

watch your movie like you know highly
00:16:51.589
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m51s

critical audience they're gonna read it
00:16:53.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m53s

badly so if you take an average it's not
00:16:55.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m55s

quite fair right and so what this is you
00:16:57.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h16m57s

know what this is doing is saying once
00:17:02.149
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m02s

we you know remove the fact that
00:17:04.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m04s

different people have different overall
00:17:06.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m06s

positive or negative experiences and
00:17:08.689
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m08s

different people watch different kinds
00:17:10.399
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m10s

of movies and we correct for all that
00:17:11.689
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m11s

this is the worst movie of all time so
00:17:13.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m13s

that's a good thing to know
00:17:17.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m17s

so this is how we can yeah look inside
00:17:21.639
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m21s

our our model and and interpret the bias
00:17:24.829
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m24s

vectors you'll see here I've sorted by
00:17:29.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m29s

the zeroth element of each tuple by
00:17:33.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m33s

using a lambda originally I used this
00:17:36.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m36s

special item ghetto this is part
00:17:39.529
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m39s

of pythons operator library and this
00:17:42.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m42s

creates a function that returns the
00:17:45.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m45s

zeroth element of something in order to
00:17:47.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m47s

save time and then I actually realize
00:17:50.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m50s

that the lambda is only one more
00:17:52.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m52s

character to write then the item get us
00:17:54.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m54s

so maybe we don't need to know this
00:17:57.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m57s

after all so yeah really useful to make
00:17:58.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h17m58s

sure you know how to write lambdas in
00:18:01.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m01s

Python so this is this is a function
00:18:03.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m03s

okay and so sort the sort is going to
00:18:06.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m06s

call this function every time it decides
00:18:09.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m09s

like is this thing higher or lower than
00:18:11.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m11s

that other thing and this fact this is
00:18:13.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m13s

going to return the zeroth element okay
00:18:15.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m15s

so here's the same thing and item get a
00:18:19.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m19s

format and here is the reverse and
00:18:21.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m21s

Shawshank Redemption right at the top
00:18:25.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m25s

I'll definitely agree with that
00:18:27.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m27s

Godfather usual suspects yeah these are
00:18:29.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m29s

all pretty great movies twelve Angry Men
00:18:31.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m31s

absolutely so there you go there's how
00:18:35.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m35s

we can look at the base so then the
00:18:39.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m39s

second piece to look at would be the the
00:18:43.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m43s

embeddings how can we look at the
00:18:45.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m45s

embeddings so we can do the same thing
00:18:47.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m47s

so remember I was the item embeddings
00:18:50.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m50s

rather than IV with the item bias we can
00:18:53.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m53s

pass in our list of movies as a variable
00:18:55.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m55s

turn it into numpy and here's our movie
00:18:58.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h18m58s

embedding so for each of the 3,000 most
00:19:01.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m01s

popular movies here are its 50
00:19:04.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m04s

embeddings so it's very hard unless
00:19:07.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m07s

you're Geoffrey Hinton to visualize a 50
00:19:12.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m12s

dimensional space so what we'll do is
00:19:14.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m14s

we'll turn it into a three dimensional
00:19:17.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m17s

space so we can compress high
00:19:19.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m19s

dimensional spaces down into lower
00:19:23.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m23s

dimensional spaces using lots of
00:19:25.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m25s

different techniques perhaps one of the
00:19:26.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m26s

most common and popular is called PCA
00:19:29.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m29s

PCA stands for principle components
00:19:31.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m31s

analysis it's a linear technique but
00:19:34.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m34s

when your techniques generally work fine
00:19:38.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m38s

for this kind of embedding I'm not going
00:19:41.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m41s

to teach you about PCA now but I will
00:19:44.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m44s

say in Rachel's computation or linear
00:19:46.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m46s

algebra class which you can get to you
00:19:48.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m48s

from first at AI we cover PCA in
00:19:50.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m50s

detail and it's a really important
00:19:55.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m55s

technique it actually it turns out to be
00:19:58.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m58s

almost identical to something called
00:19:59.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h19m59s

singular value decomposition which is a
00:20:02.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m02s

type of matrix decomposition which
00:20:04.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m04s

actually does turn up in deep learning a
00:20:06.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m06s

little bit from time to time it's kind
00:20:10.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m10s

of somewhat worth knowing if you were
00:20:13.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m13s

going to dig more into linear algebra
00:20:16.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m16s

you know SPD and PCA along with
00:20:18.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m18s

eigenvalues and eigenvectors which are
00:20:22.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m22s

all slightly different versions is this
00:20:24.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m24s

kind of the same thing or all worth
00:20:26.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m26s

knowing but for now just know that you
00:20:28.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m28s

can grab PCA from SK learn to calm
00:20:30.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m30s

position say how much you want to reduce
00:20:33.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m33s

the dimensionality too so I want to find
00:20:36.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m36s

three components and what this is going
00:20:39.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m39s

to do is it's going to find three linear
00:20:41.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m41s

combinations of the 50 dimensions which
00:20:44.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m44s

capture as much as the variation as
00:20:48.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m48s

possible Badar is different to each
00:20:50.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m50s

other as possible
00:20:52.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m52s

okay so we would call this a lower rank
00:20:53.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m53s

approximation of our matrix all right
00:20:58.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h20m58s

so then we can grab the components so
00:21:02.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m02s

that's going to be their three
00:21:04.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m04s

dimensions and so once we've done that
00:21:06.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m06s

we've now got three by three thousand
00:21:08.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m08s

and so we can now take a look at the
00:21:11.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m11s

first of them and we'll do the same
00:21:15.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m15s

thing of using zip to look at each one
00:21:16.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m16s

along with its movie and so here's the
00:21:18.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m18s

thing right we we don't know ahead of
00:21:21.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m21s

time what this PCA thing is it's just
00:21:24.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m24s

it's just a bunch of latent factors you
00:21:28.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m28s

know it's it's kind of the the main axis
00:21:33.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m33s

in this space of latent factors and so
00:21:37.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m37s

what we can do is we can look at it and
00:21:39.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m39s

see if we can figure out what it's about
00:21:41.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m41s

right so given that police academy for
00:21:45.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m45s

is high up here along with water world
00:21:49.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m49s

where else Fargo Pulp Fiction and God
00:21:51.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m51s

further a high up here I'm gonna guess
00:21:54.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m54s

that a high value is not going to
00:21:57.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h21m57s

represent like critically acclaimed
00:22:00.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m00s

movies or serious watching so I kind of
00:22:02.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m02s

like all this yeah okay I call this easy
00:22:06.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m06s

what she
00:22:08.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m08s

is serious all right but like this is
00:22:09.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m09s

kind of how you have to interpret your
00:22:11.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m11s

embeddings is like take a look at what
00:22:13.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m13s

they seem to be showing and decide what
00:22:15.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m15s

you think it means so this is the kind
00:22:18.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m18s

of the the principal axis in this set of
00:22:20.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m20s

embedding so we can look at the next one
00:22:25.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m25s

so do the same thing and look at the the
00:22:27.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m27s

first index one embedding this one's a
00:22:30.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m30s

little bit harder to kind of figure out
00:22:34.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m34s

what's going on but with things like
00:22:35.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m35s

Mulholland Drive and Purple Rose of
00:22:37.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m37s

Cairo these look more kind of dialog II
00:22:38.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m38s

kind of ones or else things like Lord of
00:22:42.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m42s

the Rings in the Latin and Star Wars
00:22:45.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m45s

these book more like kind of modern CGI
00:22:46.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m46s

II kind of ones so you could kind of
00:22:48.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m48s

imagine that on that pair of dimensions
00:22:50.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m50s

it probably represents a lot of you know
00:22:53.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m53s

differences between how people read
00:22:57.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m57s

movies you know some people like you
00:22:59.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h22m59s

know purple rise of Cairo
00:23:02.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m02s

type movies you know Woody Allen kind of
00:23:05.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m05s

classic and some people like these you
00:23:09.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m09s

know big Hollywood spectacles some
00:23:11.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m11s

people presumably like police academy
00:23:15.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m15s

for more than they like Fargo so yeah so
00:23:17.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m17s

I'm like you can kind of get the idea of
00:23:22.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m22s

what's happened it's it's done a you
00:23:24.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m24s

know through a model which was you know
00:23:26.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m26s

for a model which was literally multiply
00:23:33.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m33s

two things together and Adam hop it's
00:23:36.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m36s

learnt quite a lot you know which is
00:23:41.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m41s

kind of cool so that's what we can do
00:23:43.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m43s

with with that and then we could we
00:23:49.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m49s

could plot them if we wanted to I just
00:23:53.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m53s

grabbed a small subset to plot on those
00:23:55.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h23m55s

first two asses all right so that's that
00:24:00.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m00s

so I wanted to next kind of dig in a
00:24:04.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m04s

layer deeper into what actually happens
00:24:09.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m09s

when we say fit alright so when we said
00:24:12.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m12s

learn fit what's it doing
00:24:18.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m18s

for something like the store model is it
00:24:24.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m24s

a way to interpret the embeddings for
00:24:27.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m27s

something like this the rustman one yes
00:24:30.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m30s

yeah we'll see that in a moment well
00:24:33.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m33s

let's jump straight there what the hell
00:24:35.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m35s

okay so so for the rustman how much are
00:24:36.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m36s

we going to sell at each store on each
00:24:51.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m51s

date model we this is from the paper
00:24:52.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h24m52s

gore and burke on it so it's a great
00:25:04.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m04s

paper by the way well worth you know
00:25:06.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m06s

like pretty accessible I think any of
00:25:09.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m09s

you would at this point be able to at
00:25:12.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m12s

least get the gist of it if you know and
00:25:14.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m14s

much of the detail as well particularly
00:25:16.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m16s

as you've also done the machine learning
00:25:18.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m18s

course and they actually make this point
00:25:20.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m20s

in the paper this is in the paper that
00:25:23.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m23s

the equivalent of what they call entity
00:25:25.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m25s

embedding layers so an embedding of a
00:25:28.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m28s

categorical variable is identical to a
00:25:30.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m30s

one hot encoding followed by a matrix
00:25:33.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m33s

multiply that's why they're basically
00:25:37.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m37s

saying if you've got three embeddings
00:25:39.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m39s

that's the same as doing three one hot
00:25:41.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m41s

encodings putting each through one
00:25:44.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m44s

through a matrix multiply and then put
00:25:45.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m45s

that through a a dense layer
00:25:48.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m48s

well what pi torch would call a linear
00:25:50.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m50s

oh yeah right
00:25:53.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m53s

one of the nice things here is because
00:25:56.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m56s

this is kind of like well they thought
00:25:58.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h25m58s

it was the first paper is actually the
00:26:00.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m00s

second I think paper to show the idea of
00:26:01.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m01s

using categorical embeddings for this
00:26:03.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m03s

kind of data set they really go to clean
00:26:06.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m06s

too quite a lot of detail to you know
00:26:08.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m08s

right back to the the detailed stuff
00:26:10.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m10s

that we learnt about so it's kind of a
00:26:13.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m13s

second
00:26:15.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m15s

you know a second cat of thinking about
00:26:15.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m15s

what embeddings are doing so one of the
00:26:17.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m17s

interesting things that they did was
00:26:21.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m21s

they said okay after we've trained a
00:26:23.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m23s

neural net with these embeddings what
00:26:25.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m25s

else could we do with it so
00:26:31.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m31s

they got a winning result with a neural
00:26:34.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m34s

network where the entity meetings but
00:26:37.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m37s

then they said hey you know what
00:26:41.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m41s

we could take those empty embeddings and
00:26:42.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m42s

replace each categorical variable with
00:26:45.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m45s

the learnt entity embeddings and then
00:26:48.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m48s

feed that into a GBM right so in other
00:26:50.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m50s

words like rather than passing into the
00:26:54.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m54s

GBM a one modern coded version or an
00:26:56.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m56s

ordinal version let's actually replace
00:26:58.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h26m58s

the categorical variable with its
00:27:01.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m01s

embedding for the appropriate level for
00:27:04.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m04s

that row right so it's actually a way of
00:27:08.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m08s

create you know feature engineering and
00:27:11.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m11s

so the main average percent error
00:27:13.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m13s

without that for gbms I'm using just 100
00:27:18.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m18s

codings was 0.15 but with that it was
00:27:23.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m23s

0.11 that random forests without that
00:27:25.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m25s

was point one six with that 0.108 nearly
00:27:30.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m30s

as good as the neural net right so this
00:27:34.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m34s

is kind of an interesting technique
00:27:37.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m37s

because what it means is in your
00:27:39.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m39s

organization you can train a neural net
00:27:42.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m42s

that has an embedding of stores and an
00:27:45.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m45s

embedding of product types and an
00:27:47.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m47s

embedding of I don't know whatever kind
00:27:50.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m50s

of high cardinality or even medium
00:27:52.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m52s

cardinality categorical variables you
00:27:54.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m54s

have and then everybody else in the
00:27:56.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m56s

organization can now like chuck those
00:27:58.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h27m58s

into their you know JVM or random forest
00:28:00.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m00s

or whatever and I'm use them and what
00:28:03.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m03s

this is saying is they won't get in fact
00:28:07.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m07s

you can even use K nearest neighbors
00:28:09.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m09s

with this technique and get nearly as
00:28:11.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m11s

good a result right so this is a good
00:28:13.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m13s

way of kind of giving the power of
00:28:17.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m17s

neural nets to everybody in your
00:28:19.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m19s

organization without having them do the
00:28:21.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m21s

faster idea of learning course first you
00:28:24.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m24s

know they can just use whatever SK learn
00:28:26.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m26s

or R or whatever that they're used to
00:28:28.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m28s

and like those those embeddings could
00:28:30.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m30s

literally be in a database table because
00:28:33.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m33s

if you think about an embedding is just
00:28:35.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m35s

an index lookup right which is the same
00:28:37.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m37s

as an inner join in SQL right so if
00:28:40.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m40s

you've got a table on each product along
00:28:43.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m43s

with its embedding vector then you can
00:28:45.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m45s

literally do
00:28:48.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m48s

in a joint and now you have every row in
00:28:48.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m48s

your table along with its product
00:28:51.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m51s

embedding vector so that's a really this
00:28:53.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m53s

is this is a really useful idea and
00:28:55.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m55s

gbm's and random forests learn a lot
00:28:59.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h28m59s

quicker than neural nets do all right so
00:29:02.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m02s

that's like even if you do know how to
00:29:05.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m05s

train your on its this is still
00:29:07.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m07s

potentially quite handy so here's what
00:29:08.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m08s

happened when they took the various
00:29:12.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m12s

different states of Germany and plotted
00:29:14.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m14s

the first two principal components of
00:29:17.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m17s

their embedding vectors and they
00:29:19.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m19s

basically here is where they were in
00:29:21.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m21s

that 2d space and wacken lee enough i've
00:29:23.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m23s

circled in red three cities and i've
00:29:26.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m26s

circled here the three cities in Germany
00:29:30.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m30s

and here I've circled in purple so blue
00:29:31.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m31s

here at the blue here's the green here's
00:29:34.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m34s

the green so it's actually drawn a map
00:29:38.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m38s

of Germany even though it never was told
00:29:41.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m41s

anything about how far these states are
00:29:44.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m44s

away from each other or the very concept
00:29:47.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m47s

of geography didn't exist so that's
00:29:49.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m49s

pretty crazy so that was from there
00:29:52.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m52s

paper so I went ahead and looked well
00:29:57.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h29m57s

here's another thing I think this is
00:30:01.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m01s

also from their paper they took every
00:30:03.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m03s

pair of places and they looked at how
00:30:05.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m05s

far away they are on a map versus how
00:30:10.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m10s

far away are they in embedding space and
00:30:13.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m13s

they've got this beautiful correlation
00:30:15.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m15s

alright so again it kind of apparently
00:30:19.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m19s

you know it's doors that are near by
00:30:23.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m23s

each other physically have similar
00:30:24.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m24s

characteristics in terms of when people
00:30:30.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m30s

buy more or less stuff from them so I
00:30:32.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m32s

looked at the same thing four days of
00:30:36.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m36s

the week right so here's an embedding of
00:30:38.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m38s

the days of the week from our model and
00:30:41.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m41s

I just kind of joined up Monday Tuesday
00:30:43.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m43s

Wednesday Tuesday Thursday Friday
00:30:45.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m45s

Saturday Sunday I did the same thing for
00:30:46.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m46s

the months of the year all right again
00:30:48.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m48s

you can see you know here's here's
00:30:51.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m51s

winter here's summer so yeah I think
00:30:52.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m52s

like visualize
00:30:58.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h30m58s

embeddings can be interesting like it's
00:31:01.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m01s

good to like first of all check you can
00:31:03.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m03s

see things you would expect to see you
00:31:06.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m06s

know and then you could like try and see
00:31:08.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m08s

like maybe things you didn't expect to
00:31:10.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m10s

see so you could try all kinds of
00:31:12.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m12s

clusterings or or whatever and this is
00:31:14.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m14s

not something which has been widely
00:31:20.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m20s

studied at all right so I'm not going to
00:31:23.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m23s

tell you what the limitations are of
00:31:25.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m25s

this technique or whatever oh yes so
00:31:27.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m27s

I've heard of other ways to generate
00:31:32.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m32s

embeddings like skip grams uh-huh
00:31:34.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m34s

wondering if you could say is there one
00:31:37.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m37s

better than the other using your own
00:31:40.059
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m40s

Network sir skip grams so screwed grams
00:31:41.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m41s

is quite specific to NLP right so like
00:31:44.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m44s

I'm not sure if we'll cover it in this
00:31:49.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m49s

course but basically the the approach to
00:31:51.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m51s

original kind of word to vac approach to
00:31:56.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m56s

generating embeddings was to say you
00:31:58.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h31m58s

know what we actually don't have we
00:32:01.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m01s

don't actually have our labelled data
00:32:07.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m07s

set you know they said all we have is
00:32:10.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m10s

like google books and so they have an
00:32:12.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m12s

unsupervised learning problem
00:32:15.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m15s

unlabeled problem and so the best way in
00:32:16.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m16s

my opinion to turn an unlabeled problem
00:32:19.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m19s

into a labelled problem is to kind of
00:32:21.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m21s

invent some labels and so what they did
00:32:23.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m23s

in the word to vet case was they said
00:32:25.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m25s

okay here's a sentence with 11 words in
00:32:27.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m27s

it right and then they said okay let's
00:32:30.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m30s

delete the middle word and replace it
00:32:33.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m33s

for the random word and so you know
00:32:39.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m39s

originally it said cat and they say no
00:32:44.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m44s

let's replace that with justice all
00:32:48.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m48s

right so before it said the cute little
00:32:53.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m53s

cat sat on the fuzzy mat and now it says
00:32:55.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m55s

the cute little justice sat on the fuzzy
00:32:58.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h32m58s

man
00:33:01.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m01s

right and what they do is they do that
00:33:01.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m01s

so they have one sentence where they
00:33:03.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m03s

keep exactly as is
00:33:06.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m06s

and then they make a copy of it and they
00:33:12.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m12s

do the replacement and so then they have
00:33:14.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m14s

a label where they say it's a one if it
00:33:16.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m16s

was unchanged it was the original and
00:33:20.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m20s

zero otherwise okay and so basically
00:33:22.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m22s

then you now have something you can
00:33:27.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m27s

build a machine learning model on and so
00:33:29.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m29s

they went and build a machine learning
00:33:32.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m32s

model on this so the model was like try
00:33:33.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m33s

and find the effect sentences not
00:33:35.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m35s

because they were interested in a fake
00:33:40.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m40s

sentence binder but because as a result
00:33:42.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m42s

they now have embeddings that just like
00:33:44.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m44s

we discussed you can now use for other
00:33:46.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m46s

purposes and that became word to vet now
00:33:48.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m48s

it turns out that if you do this as just
00:33:50.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m50s

a kind of a effectively like a single
00:33:55.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m55s

matrix multiply rather than make it a
00:33:58.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m58s

deep neural net you can train this super
00:33:59.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h33m59s

quickly and so that's basically what
00:34:01.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m01s

they did with they'd met there though
00:34:05.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m05s

they kind of decided we're going to make
00:34:06.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m06s

a pretty crappy model like a shallow
00:34:08.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m08s

learning model rather than a deep model
00:34:11.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m11s

you know with the downside it's a less
00:34:13.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m13s

powerful model but a number of upsides
00:34:15.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m15s

the first thing we can train it on a
00:34:18.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m18s

really large data set and then also
00:34:20.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m20s

really importantly we're going to end up
00:34:22.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m22s

with embeddings which have really very
00:34:24.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m24s

linear characteristics so we can like
00:34:27.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m27s

add them together and subtract them and
00:34:30.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m30s

stuff like that okay so that so there's
00:34:32.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m32s

a lot of stuff we can learn about there
00:34:37.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m37s

from like for other types of embedding
00:34:39.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m39s

like categorical embeddings and
00:34:41.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m41s

specifically if we want categorical
00:34:44.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m44s

embeddings which we can kind of draw
00:34:45.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m45s

nicely and expect them to us to be able
00:34:48.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m48s

to add and subtract them and behave
00:34:51.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m51s

linearly you know probably if we want to
00:34:52.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m52s

use them in k-nearest neighbors and
00:34:56.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m56s

stuff we should probably use shallow
00:34:57.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h34m57s

learning if we want something that's
00:35:00.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m00s

going to be more predictive we probably
00:35:03.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m03s

want to use a neural net and so actually
00:35:06.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m06s

an NLP I'm really pushing the idea that
00:35:09.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m09s

we need to move past word to backhand
00:35:14.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m14s

glove these linear based methods because
00:35:17.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m17s

it turns out that those embeddings are
00:35:19.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m19s

way less predictive than embeddings
00:35:21.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m21s

learnt from
00:35:24.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m24s

models and so the language model that we
00:35:25.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m25s

learned about which ended up getting a
00:35:27.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m27s

state-of-the-art on sentiment analysis
00:35:29.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m29s

didn't used a lot more work to vet that
00:35:30.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m30s

instead we pre trained a deep recurrent
00:35:33.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m33s

neural network and we ended up with not
00:35:35.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m35s

just a pre trained word vectors but a
00:35:38.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m38s

for pre-trained model so it looks like
00:35:40.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m40s

Duke creates embeddings for entities we
00:35:46.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m46s

need like a dummy task not necessarily a
00:35:48.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m48s

dummy task like in this case we had a
00:35:51.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m51s

real task right so we created the
00:35:53.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m53s

embeddings for Rossmann by trying to
00:35:55.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m55s

predict store sales you only need this
00:35:56.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h35m56s

isn't just in this isn't just for
00:36:01.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m01s

learning embeddings for learning any
00:36:02.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m02s

kind of feature space you either need
00:36:05.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m05s

label data or you need to invent some
00:36:09.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m09s

kind of fake task
00:36:14.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m14s

so does that task matter like if I
00:36:16.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m16s

choose a task and train and lettings if
00:36:18.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m18s

I choose another task and train and
00:36:20.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m20s

lettings like which one is it's a great
00:36:22.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m22s

question and it's not something that's
00:36:26.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m26s

been studied nearly enough right I'm not
00:36:28.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m28s

sure that many people even quite
00:36:31.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m31s

understand that when they say
00:36:32.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m32s

unsupervised learning now about nowadays
00:36:34.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m34s

they almost nearly always mean fake
00:36:37.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m37s

tasks labeled learning and so the idea
00:36:40.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m40s

of like what makes a good fake task I
00:36:45.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m45s

don't know that I've seen a paper on
00:36:48.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m48s

that right that intuitively you know we
00:36:49.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m49s

need something where the kinds of
00:36:54.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m54s

relationships it's going to learn likely
00:36:56.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m56s

to be the kinds of relationships that
00:36:59.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h36m59s

you probably care about right so for
00:37:01.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m01s

example in in computer vision one kind
00:37:05.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m05s

of fake task people use is to say like
00:37:09.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m09s

let's take some images and use some kind
00:37:13.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m13s

of like unreal and unreasonable data
00:37:16.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m16s

augmentation like like recolor them too
00:37:20.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m20s

much or whatever and then we'll ask the
00:37:23.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m23s

neural net to like predict which one was
00:37:25.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m25s

the Augmented which one was not you
00:37:27.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m27s

admitted yeah so it's I think it's a
00:37:29.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m29s

fascinating area
00:37:37.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m37s

one which you know would be really
00:37:38.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m38s

interesting for people to you know maybe
00:37:41.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m41s

some of the students here they're
00:37:43.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m43s

looking to further it's like take some
00:37:44.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m44s

interesting semi-supervised tour
00:37:45.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m45s

unsupervised datasets and try and come
00:37:47.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m47s

up with some like more clever fake tasks
00:37:49.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m49s

and see like does it matter you know how
00:37:54.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m54s

much does it matter in general like if
00:37:56.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m56s

you can't come up with a fake task that
00:37:59.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h37m59s

you think seems great I would say use it
00:38:01.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m01s

use the best you can it's an often
00:38:04.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m04s

surprising how how little you need like
00:38:06.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m06s

the ultimately crappy fake task is
00:38:09.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m09s

called the auto encoder and the auto
00:38:12.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m12s

encoder is the thing which which one the
00:38:15.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m15s

claims prediction competition that just
00:38:19.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m19s

finished on cattle they had lots of
00:38:20.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m20s

examples of insurance policies where we
00:38:23.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m23s

knew this was how much was claimed and
00:38:27.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m27s

then lots of examples of insurance
00:38:28.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m28s

policies where I guess there must have
00:38:30.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m30s

been still still open we didn't yet know
00:38:32.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m32s

how much they claimed right and so what
00:38:34.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m34s

they did was they said okay so for all
00:38:36.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m36s

of the ones so let's basically start off
00:38:39.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m39s

by grabbing every policy right and we'll
00:38:41.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m41s

take a single policy and we'll put it
00:38:44.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m44s

through a neural net right and we'll try
00:38:46.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m46s

and have it reconstruct itself but in
00:38:50.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m50s

these intermediate layers and at least
00:38:55.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m55s

one of those intermediate layers will
00:38:57.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m57s

make sure there's less activations and
00:38:59.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h38m59s

there were inputs so let's say if there
00:39:01.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m01s

was a hundred variables on the insurance
00:39:03.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m03s

policy you know we'll have something in
00:39:06.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m06s

the middle that only has like twenty
00:39:08.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m08s

activations all right and so when you
00:39:09.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m09s

basically are saying hey reconstruct
00:39:13.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m13s

your own input like it's not a different
00:39:16.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m16s

kind of model doesn't require any
00:39:18.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m18s

special code it's literally just passing
00:39:20.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m20s

you can use any standard pipe torch or
00:39:23.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m23s

fast AI learner you just say my output
00:39:25.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m25s

equals my input right and that's that's
00:39:28.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m28s

like the the most uncreated you know
00:39:31.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m31s

invented task you can create and that's
00:39:35.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m35s

called an autoencoder
00:39:37.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m37s

and it works surprisingly well in fact
00:39:38.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m38s

to the point that it literally just won
00:39:41.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m41s

a cackle competition they took the
00:39:43.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m43s

features that it learnt and chucked it
00:39:45.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m45s

into another neural net and
00:39:47.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m47s

yeah and one you know maybe if we have
00:39:49.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m49s

enough students taking an interest in
00:39:54.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m54s

this then you know we'll be able to
00:39:56.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m56s

cover covered unsupervised learning in
00:39:59.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h39m59s

more detail in in part two specially
00:40:01.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m01s

given this cattle have a win I think
00:40:03.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m03s

this may be related to the previous
00:40:10.589
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m10s

question when training language models
00:40:11.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m11s

is the language model example trained on
00:40:15.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m15s

the archive data is that useful at all
00:40:18.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m18s

in the movie great question you know I
00:40:19.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m19s

was just talking to Sebastian about this
00:40:26.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m26s

question read about this this week and
00:40:29.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m29s

we thought would try and do some
00:40:31.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m31s

research on this in January it's it's
00:40:32.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m32s

again it's not well done
00:40:35.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m35s

we know that in computer vision it's
00:40:36.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m36s

shockingly effective to train on cats
00:40:39.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m39s

and dogs and use that fruit train
00:40:42.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m42s

network to do lung cancer diagnosis and
00:40:45.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m45s

CT scans in the NLP world nobody much
00:40:47.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m47s

seems to have tried this the NLP
00:40:52.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m52s

research as I've spoken to other than
00:40:54.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m54s

Sebastian about this assume that it
00:40:56.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m56s

wouldn't work and they generally haven't
00:40:58.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h40m58s

bother trying I think it would work
00:41:00.329
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m00s

great so so since we're talking about
00:41:01.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m01s

ruspin I just mentioned during the week
00:41:07.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m07s

I was interested to see like how good
00:41:12.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m12s

this solution actually actually was
00:41:14.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m14s

because I noticed that on the public
00:41:17.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m17s

leader board it didn't look like it was
00:41:20.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m20s

going to be that great and I also
00:41:21.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m21s

thought it'd be good to see like what
00:41:23.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m23s

does it actually take to use a test set
00:41:25.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m25s

properly with this kind of structured
00:41:28.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m28s

data so if you have a look at ruspin now
00:41:30.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m30s

I've pushed some changes that actually
00:41:32.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m32s

run the test set through as well and so
00:41:34.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m34s

you can get a sense of how to do this
00:41:36.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m36s

so you'll see basically every line
00:41:38.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m38s

appears twice one for tests and one-foot
00:41:40.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m40s

one for train when we get there yeah
00:41:44.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m44s

test train test trains history obviously
00:41:46.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m46s

you could do this on a lot fewer lines
00:41:48.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m48s

of code by putting all of the steps into
00:41:50.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m50s

a method and then pass either the train
00:41:53.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m53s

data set well the test data set up
00:41:55.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m55s

dataframe to it in this case i wanted to
00:41:57.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h41m57s

kind of put for teaching purposes you'd
00:42:00.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m00s

be able to see
00:42:02.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m02s

step and to experiment to see what each
00:42:03.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m03s

step looks like but you could certainly
00:42:05.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m05s

simplify this code so yeah so we do this
00:42:08.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m08s

for every data frame and then some of
00:42:12.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m12s

these you can see I kind of lived
00:42:16.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m16s

through the data frame in joined and the
00:42:17.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m17s

joint test right training just this
00:42:20.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m20s

whole thing about the durations I
00:42:24.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m24s

basically put two lines here one that
00:42:27.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m27s

said data frame equals train columns one
00:42:30.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m30s

that says data frame equals test columns
00:42:32.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m32s

and so my you know basically ideas you'd
00:42:34.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m34s

run this line first and then you would
00:42:36.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m36s

skip the next one and you'd run
00:42:39.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m39s

everything beneath it and then you'd go
00:42:40.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m40s

back and run this line and then run
00:42:42.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m42s

everything believe it
00:42:45.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m45s

so some people on the forum were asking
00:42:45.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m45s

how come this code wasn't working this
00:42:48.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m48s

week which is a good reminder that the
00:42:49.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m49s

code is not designed to be code that you
00:42:52.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m52s

always run top to bottom without
00:42:54.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m54s

thinking right you're meant to like
00:42:56.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m56s

think like what is this code here should
00:42:57.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h42m57s

I be running it right now okay and so
00:43:00.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m00s

like the early lessons I tried to make
00:43:03.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m03s

it so you can run it top to bottom but
00:43:05.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m05s

increasingly as we go along I kind of
00:43:07.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m07s

make it more and more that like you
00:43:09.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m09s

actually have to think about what's
00:43:10.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m10s

going on so Jimmy you're talking about
00:43:11.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m11s

shadow learning and deep learning could
00:43:17.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m17s

you define that a bit better by sure I'm
00:43:20.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m20s

learning I think I just mean anything
00:43:22.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m22s

that doesn't have a hidden layer so
00:43:24.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m24s

something that's like a dot product
00:43:25.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m25s

matrix multiplier basically okay so so
00:43:28.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m28s

we end up with a training and a test
00:43:40.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m40s

version and then everything else is
00:43:43.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m43s

basically the same one thing to note on
00:43:46.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m46s

a lot of these details of this we cover
00:43:50.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m50s

in the machine learning course by the
00:43:51.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m51s

way because it's not really deep
00:43:53.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m53s

learning specific so check that out if
00:43:54.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m54s

you're just in the details
00:43:55.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m55s

I should mention you know we use apply
00:43:58.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h43m58s

cats rather than train cats to make sure
00:44:00.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m00s

the test set and the training set have
00:44:02.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m02s

the same categorical codes and that they
00:44:04.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m04s

join too we also need to make sure that
00:44:09.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m09s

we keep track of the mapper this is the
00:44:14.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m14s

thing which basically says
00:44:15.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m15s

what's the mean and standard deviation
00:44:17.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m17s

of each continuous column and then apply
00:44:18.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m18s

that same method test set and so when we
00:44:22.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m22s

do all that that's basically it then the
00:44:27.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m27s

rest is easy we just have to pass you in
00:44:28.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m28s

the test data frame in the usual way
00:44:30.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m30s

when we create our model data object and
00:44:33.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m33s

there's no changes through all here we
00:44:39.099
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m39s

trained it in the same way and then once
00:44:42.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m42s

we finish training it we can then call
00:44:43.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m43s

predict as per usual passing in true to
00:44:51.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m51s

say this is the test set rather than the
00:44:55.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m55s

validation set and pass that off to
00:44:57.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h44m57s

cattle and so it was really interesting
00:45:00.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m00s

because this was my submission it got a
00:45:03.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m03s

public score of 103 which would put us
00:45:08.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m08s

in about 300 and some things place which
00:45:14.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m14s

looks awful right and our private score
00:45:21.109
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m21s

of 107 need a board private here's about
00:45:25.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m25s

fifth
00:45:37.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m37s

right so like if you're competing in a
00:45:38.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m38s

cable competition and you don't haven't
00:45:42.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m42s

thoughtfully created a validation set of
00:45:45.799
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m45s

your own and you're relying on publicly
00:45:47.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m47s

the board feedback this could totally
00:45:49.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m49s

happen to you but the other way around
00:45:52.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m52s

you'll be like oh I'm in the top ten I'm
00:45:53.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m53s

doing great
00:45:55.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m55s

and then oh for example at the moment
00:45:56.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m56s

the ice Berg's competition recognizing
00:45:59.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h45m59s

icebergs a very large percentage of the
00:46:01.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m01s

public leaderboard set is synthetically
00:46:04.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m04s

generated data augmentation data like
00:46:07.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m07s

totally meaningless and so your
00:46:10.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m10s

validation set is going to be much more
00:46:13.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m13s

helpful and the public leaderboard
00:46:15.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m15s

feedback right so yeah be very careful
00:46:17.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m17s

so our final score here is kind of
00:46:21.859
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m21s

within statistical noise of the actual
00:46:24.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m24s

third-place getters so I'm pretty
00:46:26.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m26s

confident that we've we've captured
00:46:28.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m28s

their approach and so that's that's
00:46:31.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m31s

pretty interesting something to mention
00:46:35.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m35s

there's a nice kernel about the rustman
00:46:40.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m40s

I quite a few nice kernels actually but
00:46:43.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m43s

you can go back and see like
00:46:45.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m45s

particularly if you're doing the
00:46:46.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m46s

groceries competition go and have a look
00:46:47.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m47s

at the Rossmann kernels because actually
00:46:48.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m48s

quite a few of them a higher quality
00:46:50.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m50s

than the ones for the Ecuadorian
00:46:51.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m51s

groceries competition one of them for
00:46:53.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m53s

example showed how on four particular
00:46:56.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m56s

stores like straw eighty five the sales
00:46:58.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h46m58s

for non Sundays and the sale for
00:47:02.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m02s

Sunday's looked very different where
00:47:05.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m05s

else there are some other stores where
00:47:08.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m08s

the sales on Sunday don't look any
00:47:09.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m09s

different and it can kind of like get a
00:47:11.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m11s

sense of why you need these kind of
00:47:13.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m13s

interactions the one I particularly
00:47:14.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m14s

wanted to point out is the one I think I
00:47:16.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m16s

briefly mentioned that the third-place
00:47:18.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m18s

winners whose approach we used they
00:47:20.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m20s

didn't notice is this one and here's a
00:47:22.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m22s

really cool visualization here you can
00:47:25.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m25s

see that the store this store is closed
00:47:29.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m29s

right and just after oh my god we run a
00:47:33.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m33s

we run out of eggs
00:47:37.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m37s

and just before oh my god go and get the
00:47:38.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m38s

milk before the store closes alright
00:47:41.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m41s

and here again closed bang right so this
00:47:44.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m44s

third-place winner actually deleted all
00:47:48.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m48s

of the closed store rows before they
00:47:52.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m52s

started doing any analysis right so
00:47:55.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m55s

remember how we talked about like don't
00:47:57.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m57s

touch your data unless you first of all
00:47:59.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h47m59s

analyze to see whether that thing you're
00:48:02.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m02s

doing is actually okay no assumptions
00:48:04.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m04s

right so in this case I am sure like I
00:48:08.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m08s

haven't tried it but I'm sure they would
00:48:11.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m11s

have one otherwise right because like
00:48:13.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m13s

well though there weren't actually any
00:48:15.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m15s

store closures to my knowledge in the
00:48:16.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m16s

test set period the problem is that
00:48:19.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m19s

their model was trying to fit to these
00:48:22.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m22s

like really extreme things and so and
00:48:25.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m25s

because it wasn't able to do it very
00:48:27.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m27s

well it was gonna end up getting a
00:48:28.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m28s

little bit confused it's not gonna break
00:48:30.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m30s

the model but it's definitely gonna harm
00:48:32.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m32s

it because it's kind of trying to do
00:48:34.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m34s

computations to fit something which it
00:48:36.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m36s

literally doesn't have the data for your
00:48:38.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m38s

neck can you pass that back there
00:48:40.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m40s

all right so that Russman model again
00:48:42.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m42s

like it's nice to kind of look inside to
00:48:50.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m50s

see what's actually going on right and
00:48:52.779
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m52s

so that Russman model I want to make
00:48:54.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h48m54s

sure you kind of know how to find your
00:49:02.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m02s

way around the code so you can answer
00:49:04.029
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m04s

these questions for yourself so it's
00:49:05.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m05s

inside columnar model data now um we
00:49:06.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m06s

started out by kind of saying hey if you
00:49:12.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m12s

want to look at the code for something
00:49:13.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m13s

you couldn't like a question mark
00:49:15.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m15s

question mark like this and oh okay I
00:49:17.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m17s

need to I haven't got this reading but
00:49:21.999
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m21s

you can use question mark question mark
00:49:23.829
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m23s

to get the source code for something
00:49:25.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m25s

right but obviously like that's not
00:49:27.999
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m27s

really a great way because often you
00:49:31.259
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m31s

look at that source code and it turns
00:49:33.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m33s

out you need to look at something else
00:49:35.229
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m35s

right and so for those of you that
00:49:36.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m36s

haven't done much coding you might not
00:49:38.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m38s

be aware that almost certainly the
00:49:40.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m40s

editor you're using probably has the
00:49:43.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m43s

ability to both open up stuff directly
00:49:45.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m45s

off SSH and to navigate through it so
00:49:48.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m48s

you can jump straight from place to
00:49:51.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m51s

place right so want to show you what I
00:49:53.229
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m53s

mean so if I were to find columnar model
00:49:55.029
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m55s

data and I have to be using vim here I
00:49:57.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h49m57s

can basically say tag columnar model
00:50:00.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m00s

data and it will jump straight to the
00:50:03.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m03s

definition of that plus right and so
00:50:05.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m05s

then I notice here that like oh it's
00:50:09.279
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m09s

actually building up a data loader
00:50:10.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m10s

that's interesting if I get control
00:50:12.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m12s

right square bracket it'll jump to the
00:50:15.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m15s

definition of the thing that was under
00:50:17.589
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m17s

my cursor and after I finished reading
00:50:19.569
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m19s

it for a while
00:50:21.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m21s

I can hit ctrl T to jump back up to
00:50:22.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m22s

where I came from
00:50:25.329
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m25s

right and you kind of get the idea right
00:50:26.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m26s

or if I want to find it for usage of
00:50:28.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m28s

this in this file of columnar model data
00:50:30.729
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m30s

I can hit star to jump to the next place
00:50:34.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m34s

it's new used you know and so forth
00:50:38.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m38s

alright so in this case get learner was
00:50:41.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m41s

the thing which actually got the model
00:50:46.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m46s

and we want to find out what kind of
00:50:49.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m49s

model it is and apparently it uses a
00:50:51.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m51s

I'm not using collaborative filtering
00:50:55.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m55s

are we were using columnar model data
00:50:56.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m56s

sorry columnar model data okay learner
00:50:59.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h50m59s

which users and so here you can see
00:51:08.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m08s

mixed input model is the PI torch model
00:51:10.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m10s

and then it wraps it in the structured
00:51:13.549
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m13s

learner which is the the first day I
00:51:16.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m16s

learn a type which wraps the data and
00:51:20.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m20s

the model together so if we want to see
00:51:23.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m23s

the definition of this actual PI torch
00:51:25.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m25s

model I can go to control right square
00:51:27.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m27s

bracket to see it right and so here is
00:51:30.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m30s

the model right and nearly all of this
00:51:34.519
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m34s

we can now understand right so we got
00:51:39.769
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m39s

past we got past a list of embedding
00:51:42.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m42s

sizes in the mixed model that we saw
00:51:52.009
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h51m52s

does it always expect categorical and
00:52:04.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m04s

continuous together yes it does
00:52:09.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m09s

and the the model data behind the scenes
00:52:15.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m15s

if there are no none of the other type
00:52:19.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m19s

it creates a column of ones or zeros or
00:52:21.859
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m21s

something okay so if it is null it can
00:52:26.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m26s

still work yeah yeah yeah it's kind of
00:52:30.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m30s

ugly and hacky and will you know
00:52:35.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m35s

hopefully improve it but yeah you can
00:52:36.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m36s

pass in an empty list of categorical or
00:52:39.289
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m39s

continuous variables to the model data
00:52:42.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m42s

and it will basically yeah it'll
00:52:43.759
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m43s

basically pass an unused column of zeros
00:52:46.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m46s

to avoid things breaking and I'm I'm
00:52:49.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m49s

leaving fixing some of these slightly
00:52:54.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m54s

hacky edge cases because height or 0.4
00:52:56.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m56s

as well as you're getting rid of
00:52:59.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h52m59s

variables they're going to also add rank
00:53:01.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m01s

0 tensors which is to say if you grab a
00:53:04.789
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m04s

single
00:53:08.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m08s

thing out of like a rent 110 sir rather
00:53:08.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m08s

than getting back at a number which is
00:53:11.479
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m11s

like qualitatively different you're
00:53:14.059
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m14s

actually going to get back like a tensor
00:53:16.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m16s

that just happens to have no rank now it
00:53:18.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m18s

turns out that a lot of this kind of
00:53:20.509
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m20s

codes gonna be actually easier to write
00:53:21.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m21s

then so and for now it's it's a little
00:53:23.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m23s

bit more happier than it needs to be
00:53:25.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m25s

Jeremy you talk about this a little bit
00:53:30.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m30s

before where maybe it's a good time at
00:53:33.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m33s

some points talk about how can we write
00:53:35.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m35s

something that is slightly different for
00:53:38.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m38s

worries in the library yeah I think
00:53:41.059
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m41s

we'll cover that a little bit next week
00:53:44.749
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m44s

that I'm mainly going to do that in part
00:53:47.329
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m47s

to like Pat who's going to cover quite a
00:53:49.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m49s

lot of stuff one of the main things were
00:53:53.779
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m53s

cover in part two is what it called
00:53:55.549
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m55s

generative models so things where the
00:53:57.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m57s

output is a whole sentence or a whole
00:53:59.059
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h53m59s

image but you know I also dig into like
00:54:00.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m00s

powder really either customize the first
00:54:03.469
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m03s

day I library or use it on more custom
00:54:08.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m08s

models but if we have time we'll touch
00:54:11.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m11s

on it a little bit next week okay so the
00:54:16.249
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m16s

the learner we were passing in a list of
00:54:22.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m22s

embedding sizes and as you can see that
00:54:25.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m25s

embedding sizes list was literally just
00:54:27.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m27s

the number of rows and the number of
00:54:28.999
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m28s

columns in each embedding right and the
00:54:30.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m30s

number of code rose was just coming from
00:54:32.569
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m32s

literally how many stores are there in
00:54:35.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m35s

the store category for example and the
00:54:38.809
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m38s

number of columns was just a quarter
00:54:42.049
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m42s

that divided by two and a maximum of 50
00:54:44.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m44s

so that thing that list of tuples was
00:54:47.329
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m47s

coming in and so you can see here how we
00:54:49.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m49s

use it right we go through each of those
00:54:51.469
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m51s

tuples grab the number of categories and
00:54:53.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m53s

the size of the embedding and construct
00:54:57.229
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h54m57s

an embedding all right and so that's a
00:55:00.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m00s

that's a list right one minor thing
00:55:03.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m03s

height or specific thing we haven't
00:55:05.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m05s

talked about before is for it to be able
00:55:07.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m07s

to like register remember how we kind of
00:55:11.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m11s

said like it registers your parameters
00:55:13.759
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m13s

it registers your your layers like
00:55:15.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m15s

someone we like listed the model it
00:55:18.109
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m18s

actually printed out the Novation
00:55:19.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m19s

varying an age bias it can't do that if
00:55:21.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m21s

they're hidden inside a list right they
00:55:24.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m24s

have to be like a there have to be a an
00:55:27.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m27s

actual n n dot module subclass so
00:55:29.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m29s

there's a special thing called an N n
00:55:33.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m33s

dot module list which takes a list and
00:55:35.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m35s

it basically says I want you to register
00:55:38.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m38s

everything in here has been part of this
00:55:40.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m40s

model okay so it's just a minor tweak so
00:55:42.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m42s

yeah so our mixed input model has a list
00:55:47.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m47s

of embeddings and then I do the same
00:55:49.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m49s

thing for a list of linear layers right
00:55:53.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m53s

so when I said here 1000 comma 500 this
00:55:56.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h55m56s

was saying how many activations I wanted
00:56:03.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m03s

featured my lineal is okay and so here I
00:56:06.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m06s

just go through that list and create a
00:56:09.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m09s

linear layer that goes from this size to
00:56:13.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m13s

the next size okay so you can see like
00:56:16.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m16s

how easy it is to kind of construct your
00:56:19.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m19s

own not just your own model but a kind
00:56:21.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m21s

of a model which you can pass parameters
00:56:24.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m24s

to have a constructed on the fly
00:56:26.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m26s

dynamically and that's normal talk about
00:56:28.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m28s

next week this is initialization we've
00:56:30.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m30s

mentioned climbing her initialization
00:56:34.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m34s

before and we mentioned it last week and
00:56:36.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m36s

then drop out same thing right we have
00:56:40.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m40s

here a list of how much drop out to
00:56:44.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m44s

apply to each layer right so again here
00:56:46.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m46s

it's just like go through each thing in
00:56:48.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m48s

that list and create a drop out layer
00:56:50.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m50s

for it okay so this constructor we
00:56:52.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m52s

understand everything in it except for
00:56:55.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m55s

batch norm which we don't have to worry
00:56:57.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h56m57s

about for now so that's the constructor
00:57:00.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m00s

and so then the forward also you know
00:57:03.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m03s

all stuff we're aware of go through each
00:57:08.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m08s

of those embedding layers that we just
00:57:10.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m10s

saw and remember we've just treated like
00:57:11.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m11s

as a function so call it with the ithe
00:57:14.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m14s

categorical variable and then
00:57:16.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m16s

concatenate them all together put that
00:57:18.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m18s

through drop out and then go through
00:57:22.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m22s

each one of our linear layers and call
00:57:26.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m26s

it apply relia to it
00:57:29.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m29s

apply dropout
00:57:32.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m32s

and then finally apply the final linear
00:57:33.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m33s

layer and the final linear layer has
00:57:36.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m36s

this as its size which is here right
00:57:40.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m40s

size one there's a single unit sales
00:57:47.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m47s

okay so we're kind of getting to the
00:57:49.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m49s

point where oh and then of course at the
00:57:52.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m52s

end if this I mentioned would come back
00:57:55.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m55s

to this if you passed in a Y underscore
00:57:57.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m57s

range parameter then we're going to do
00:57:59.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h57m59s

the thing we just learned about last
00:58:02.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m02s

week which is to use a sigmoid right and
00:58:03.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m03s

this is a cool little trick to make
00:58:06.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m06s

you're not just to make your
00:58:07.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m07s

collaborative filtering better but in
00:58:09.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m09s

this case my basic idea was you know
00:58:11.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m11s

sales are going to be greater than zero
00:58:14.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m14s

and probably less than the largest sale
00:58:17.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m17s

they've ever had so I just pass in that
00:58:21.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m21s

as Y range and so we do a sigmoid and
00:58:25.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m25s

multiply with the sigmoid by the range
00:58:29.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m29s

that I passed it all right and so
00:58:30.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m30s

hopefully we can find that here yeah
00:58:33.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m33s

here it is right so I actually said hey
00:58:37.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m37s

maybe the range is between zero and you
00:58:39.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m39s

know the highest x one point two you
00:58:43.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m43s

know cuz maybe maybe the next two weeks
00:58:45.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m45s

we have one bigger but this is kind of
00:58:47.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m47s

like again try to make it a little bit
00:58:49.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m49s

easier for it to give us the kind of
00:58:51.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m51s

results that it thinks is right so like
00:58:53.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m53s

increasingly you know I'd love your wall
00:58:56.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m56s

to kind of try to not treat these
00:58:59.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h58m59s

learners and models as black boxes but
00:59:04.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m04s

to feel like you now have the
00:59:07.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m07s

information you need to look inside them
00:59:09.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m09s

and remember you could then copy and
00:59:10.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m10s

paste this plus paste it into a cell in
00:59:12.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m12s

duple notebook and start fiddling with
00:59:16.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m16s

it to create your own versions okay
00:59:19.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m19s

I think what I might do is we might take
00:59:30.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m30s

a bit of a early break because we've got
00:59:33.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m33s

a lot to cover and I want to do it all
00:59:35.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m35s

in one big go so let's take a let's take
00:59:37.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m37s

a break until 7:45 and then we're going
00:59:42.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m42s

to come back and talk about recurrent
00:59:46.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m46s

neural networks all right
00:59:47.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m47s

so we're going to talk about Aaron ends
00:59:56.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m56s

before we do we've got to kind of dig a
00:59:58.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=00h59m58s

little bit deeper into SGD because I
01:00:02.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m02s

just want to make sure everybody's
01:00:05.829
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m05s

totally comfortable with with SGD and so
01:00:06.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m06s

what we're going to look at is we're
01:00:11.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m11s

going to look at lesson six SGD notebook
01:00:13.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m13s

and we're going to look at a really
01:00:17.549
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m17s

simple example of using SGD to learn y
01:00:19.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m19s

equals ax plus B and so what we're going
01:00:26.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m26s

to do here is we're going to create like
01:00:29.529
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m29s

the simplest possible model y equals ax
01:00:32.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m32s

plus B okay and then we're going to
01:00:36.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m36s

generate some random data that looks
01:00:38.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m38s

like so so here's our X and here's our Y
01:00:43.509
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m43s

we want to predict Y from X and we
01:00:46.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m46s

passed in 3 &amp; 8 as our a and B so we're
01:00:52.779
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m52s

going to kind of try and recover that
01:00:56.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m56s

right and so the idea is that if we can
01:00:57.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h00m57s

solve something like this which has two
01:01:00.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m00s

parameters we can use the same technique
01:01:03.099
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m03s

to solve we can use the same technique
01:01:05.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m05s

to solve something with a hundred
01:01:09.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m09s

million parameters right without any
01:01:10.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m10s

changes at all so in order to find a and
01:01:14.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m14s

a B that fits this we need a loss
01:01:22.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m22s

function and this is a regression
01:01:23.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m23s

problem because we have a continuous
01:01:25.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m25s

output so for continuous output
01:01:27.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m27s

regression we tend to use mean squared
01:01:30.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m30s

error all right and obviously all of
01:01:31.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m31s

this stuff there's there's
01:01:33.849
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m33s

implementations in non pious
01:01:34.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m34s

implementations in flight or we're just
01:01:36.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m36s

doing stuff by hand so you can see all
01:01:37.809
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m37s

the steps right so there's MSE okay
01:01:39.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m39s

y hat is
01:01:42.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m42s

we often call our predictions Y hat
01:01:44.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m44s

mitis y squared mean there's I meant
01:01:45.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m45s

whatever okay so for example if we had
01:01:48.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m48s

ten and five where a and B then there's
01:01:50.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m50s

our mean square R squared error three
01:01:54.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m54s

point two five okay so if we've got an A
01:01:56.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m56s

and a B and we've got an x and a y then
01:01:59.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h01m59s

our mean square error loss is just the
01:02:00.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m00s

mean squared error of our linear that's
01:02:02.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m02s

our predictions and our way okay so
01:02:05.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m05s

there's a last four ten five X Y all
01:02:07.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m07s

right so that's a loss function right
01:02:11.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m11s

and so when we talk about combining
01:02:13.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m13s

linear layers and loss functions and
01:02:18.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m18s

optionally nonlinear layers this is all
01:02:21.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m21s

we're doing right is we're putting a
01:02:24.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m24s

function inside a function yeah that's
01:02:26.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m26s

that's all like I know people draw these
01:02:29.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m29s

clever looking dots and lines all over
01:02:31.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m31s

the screen when they're saying this is
01:02:35.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m35s

what a neural network is but it's just
01:02:36.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m36s

it's just a function of a function of a
01:02:38.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m38s

function okay so here we've got a
01:02:39.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m39s

prediction function being a linear layer
01:02:41.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m41s

followed by a loss function being MSE
01:02:43.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m43s

and now we can say like oh well let's
01:02:45.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m45s

just define this as MSA Lost's and we'll
01:02:47.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m47s

use that in the future okay so there's
01:02:49.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m49s

our loss function which incorporates our
01:02:51.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m51s

prediction function okay so let's
01:02:53.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m53s

generate 10,000 items or thick data and
01:02:57.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h02m57s

let's show them in two variables so we
01:03:00.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m00s

can use them with PI torch because
01:03:02.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m02s

Jeremy doesn't like taking derivatives
01:03:03.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m03s

so we're going to use PI torch for that
01:03:05.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m05s

and let's create random wait for a and B
01:03:07.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m07s

so a single random number and we want
01:03:11.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m11s

the gradients of these to be calculated
01:03:14.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m14s

as we start computing with them because
01:03:16.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m16s

these are the actual things we need to
01:03:19.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m19s

update in our SGD okay so here's our a
01:03:20.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m20s

and B 0.029 0.111 all right so let's
01:03:24.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m24s

pick a learning rate okay and let let's
01:03:31.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m31s

do 10,000 epochs of SGD in fact this
01:03:34.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m34s

isn't really SGD it's not stochastic
01:03:40.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m40s

gradient it said this is actually full
01:03:42.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m42s

gradient descent we're going to each
01:03:43.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m43s

each loop is going to look at all of the
01:03:45.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m45s

data okay stochastic gradient descent
01:03:48.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m48s

would be looking at a subset each time
01:03:52.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m52s

so to do gradient descent we basically
01:03:56.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m56s

calculate loss right so remember we've
01:03:58.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h03m58s

started out with a random a and B okay
01:04:01.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m01s

and so this is going to compute some
01:04:03.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m03s

amount of loss and then it's nice from
01:04:05.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m05s

time to time so one way of saying from
01:04:08.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m08s

time to time is if the epoch number mod
01:04:10.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m10s

a thousand is zero right so every
01:04:13.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m13s

thousand epochs just print out the loss
01:04:15.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m15s

so you have it do it okay
01:04:17.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m17s

so now that we've computed the loss we
01:04:21.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m21s

can compute our gradients right and so
01:04:23.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m23s

you just remember this thing here is
01:04:26.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m26s

both a number a single number that is
01:04:28.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m28s

our lost something we can print but it's
01:04:32.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m32s

also a variable because we passed
01:04:34.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m34s

variables into it and therefore it also
01:04:35.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m35s

has a method type backward which means
01:04:38.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m38s

calculate the gradients of everything
01:04:41.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m41s

that we asked it to everything where we
01:04:43.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m43s

said requires radical is true okay so at
01:04:45.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m45s

this point we now have a dot grad
01:04:48.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m48s

property inside a and inside P and here
01:04:52.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m52s

they are here is that grant grad
01:04:57.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m57s

property okay so now that we've
01:04:59.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h04m59s

calculated the gradients for a and B we
01:05:02.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m02s

can update them by saying a is equal to
01:05:04.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m04s

whatever it used to be - the learning
01:05:07.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m07s

rate times the gradient okay dot data
01:05:10.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m10s

because a is a variable and a variable
01:05:14.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m14s

contains a tensor and it's dot data
01:05:18.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m18s

property and we again this is going to
01:05:21.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m21s

disappear in height which point four but
01:05:24.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m24s

for now it's actually the ten so that we
01:05:26.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m26s

need to update okay so update the tensor
01:05:28.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m28s

inside here with whatever it used to be
01:05:31.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m31s

- the learning rate times the gradient
01:05:33.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m33s

okay and that's basically it
01:05:37.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m37s

all right that's basically all gradient
01:05:40.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m40s

descent is okay so it's it's as simple
01:05:43.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m43s

as we claimed there's one extra step in
01:05:45.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m45s

pi torch which is that you might have
01:05:49.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m49s

like multiple different loss functions
01:05:51.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m51s

or like lots of lots of output layers
01:05:54.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m54s

all contributing to the gradient and you
01:05:56.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m56s

like to have to add them all together
01:05:59.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h05m59s

and so if you've got multiple loss
01:06:00.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m00s

functions you could be calling loss stop
01:06:04.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m04s

backward on each of them and what it
01:06:05.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m05s

does is an ad
01:06:07.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m07s

sit to the gradients right and so you
01:06:08.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m08s

have to tell it when to set the
01:06:10.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m10s

gradients back to zero okay so that's
01:06:12.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m12s

where you just go okay set a to zero and
01:06:15.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m15s

gradients in set B gradients to zero
01:06:18.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m18s

okay and so this is wrapped up inside
01:06:21.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m21s

the you know op TMS JD class right so
01:06:25.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m25s

when we say up Tim dot SGD and we just
01:06:31.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m31s

say you know dot step it's just doing
01:06:34.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m34s

these for us so when we say dot zero
01:06:37.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m37s

gradients is just doing this force and
01:06:38.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m38s

this underscore here every pretty much
01:06:41.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m41s

every function that applies to a tensor
01:06:46.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m46s

in pi torch if you stick an underscore
01:06:48.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m48s

on the end it means do it in place okay
01:06:50.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m50s

so this is actually going to not return
01:06:53.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m53s

a bunch of zeros but it's going to
01:06:54.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m54s

change this in place to be a bunch of
01:06:56.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m56s

zeros so that's basically it we can look
01:06:58.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h06m58s

at the same thing without PI torch which
01:07:04.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m04s

means we actually do have to do some
01:07:09.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m09s

calculus so if we generate some fake
01:07:10.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m10s

data again we're just going to create 50
01:07:12.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m12s

data points this time just to make this
01:07:16.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m16s

fast and easy to look at and so let's
01:07:18.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m18s

create a function called update right
01:07:21.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m21s

we're just going to use numpy no pi
01:07:23.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m23s

torch okay so our predictions is equal
01:07:25.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m25s

to again linear and in this case we
01:07:28.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m28s

actually gonna calculate the derivatives
01:07:31.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m31s

so the derivative of the square of the
01:07:32.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m32s

loss is just two times and then the
01:07:34.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m34s

derivative is the vector a is just that
01:07:37.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m37s

you can confirm that yourself if you
01:07:39.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m39s

want to and so here our we're going to
01:07:41.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m41s

update a minus equals learning rate
01:07:44.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m44s

times the derivative of loss with
01:07:46.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m46s

respect to a and for B it's learning
01:07:49.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m49s

rate times derivative with respect to B
01:07:52.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m52s

okay and so what we can do let's just
01:07:54.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m54s

run all this so just for fun
01:07:59.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h07m59s

rather than looping through manually we
01:08:02.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m02s

can use the map flop matplotlib func
01:08:04.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m04s

animation command to run the animate
01:08:07.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m07s

function a bunch of times and the
01:08:12.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m12s

animate function is going to run 30
01:08:14.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m14s

epochs and at the end of each epoch it's
01:08:16.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m16s

going to print out
01:08:20.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m20s

on the plot where the line currently is
01:08:22.049
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m22s

and that creates this at all movie okay
01:08:24.029
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m24s

so you can actually see that the line
01:08:27.509
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m27s

moving at a place right so if you want
01:08:30.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m30s

to play around with like understanding
01:08:33.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m33s

how high torque gradients actually work
01:08:35.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m35s

step-by-step here's like the world's
01:08:40.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m40s

simplest at all example okay and you
01:08:42.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m42s

know it's kind of like it's kind of
01:08:46.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m46s

weird to say like that's that's it like
01:08:49.799
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m49s

when you're optimizing a hundred million
01:08:52.199
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m52s

parameters in a neural net it's doing
01:08:53.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m53s

the same thing but it it actually is
01:08:55.409
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m55s

alright you can actually look at the PI
01:08:57.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m57s

torch code and see it's this is it right
01:08:59.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h08m59s

there's no trick
01:09:01.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m01s

well we load a couple of minor tricks
01:09:04.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m04s

last time which was like momentum and
01:09:07.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m07s

atom right that if you could do it in
01:09:09.779
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m09s

Excel you can do it invite them so okay
01:09:13.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m13s

so let's do talk about our lens so we're
01:09:15.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m15s

now in less than six hour and in
01:09:19.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m19s

notebook and we're going to study
01:09:20.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m20s

Nietzsche as you should
01:09:29.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m29s

so Nietzsche says supposing that truth
01:09:34.549
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m34s

is a woman what then I love this
01:09:38.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m38s

apparently all philosophers have failed
01:09:41.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m41s

to understand women
01:09:46.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m46s

so apparently at the point that
01:09:47.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m47s

Nietzsche was alive there was no female
01:09:48.449
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m48s

philosophers or at least those that were
01:09:49.799
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m49s

around didn't understand women either so
01:09:52.049
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m52s

anyway so this is the philosopher
01:09:54.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m54s

apparently we've chosen to study it
01:09:56.159
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m56s

leech is actually much less worse than
01:09:59.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h09m59s

people think he is but it's a different
01:10:02.159
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m02s

era I guess alright so we're going to
01:10:05.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m05s

learn to write philosophy like Nietzsche
01:10:07.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m07s

and so we're going to do it one
01:10:13.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m13s

character at a time so this is like the
01:10:16.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m16s

language model that we did in Lesson
01:10:18.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m18s

four where we did it a word at the time
01:10:20.099
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m20s

but this time we're going to do a
01:10:21.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m21s

character at a time and so the main
01:10:22.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m22s

thing I'm going to try and convince you
01:10:26.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m26s

is an RNN is no different to anything
01:10:28.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m28s

you've already learned okay and so to
01:10:31.469
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m31s

show you that
01:10:34.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m34s

going to build it from plain PI torch
01:10:35.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m35s

layers all of which are extremely
01:10:39.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m39s

familiar already okay and eventually
01:10:41.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m41s

we're going to use something really
01:10:43.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m43s

complex which is a for loop okay so
01:10:44.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m44s

that's when we're going to make a really
01:10:47.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m47s

sophisticated so the basic idea of our n
01:10:48.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m48s

ends is that you want to keep track of
01:10:52.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m52s

the main thing is you want to keep track
01:10:55.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m55s

of kind of state over long term
01:10:57.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m57s

dependencies so for example if you're
01:10:59.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h10m59s

trying to model something like this kind
01:11:01.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m01s

of template language right then at the
01:11:04.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m04s

end of your percent comment blue percent
01:11:08.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m08s

you need a percent common end percent
01:11:10.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m10s

right and so somehow your model needs to
01:11:13.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m13s

keep track of the fact that it's like
01:11:15.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m15s

inside a comment over all of these
01:11:16.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m16s

different characters right and so this
01:11:19.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m19s

is this idea of state it's kind of
01:11:21.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m21s

memory right and this is quite a
01:11:23.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m23s

difficult thing to do with like just a
01:11:25.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m25s

calm confident it turns out actually to
01:11:29.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m29s

be possible but it's it's you know a
01:11:31.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m31s

little bit tricky
01:11:34.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m34s

where elsewhere as an iron in it turns
01:11:36.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m36s

out to be pretty straightforward all
01:11:38.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m38s

right so these are the basic ideas if
01:11:40.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m40s

you want the stateful representation
01:11:42.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m42s

where you kind of keeping track of like
01:11:43.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m43s

where are we now have memory have long
01:11:44.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m44s

term dependencies and potentially even
01:11:47.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m47s

have variable length sequences these are
01:11:49.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m49s

all difficult things to do with
01:11:53.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m53s

confidence they're very straightforward
01:11:54.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m54s

with arid ends so for example SwiftKey a
01:11:57.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h11m57s

year or so ago did a blog post about how
01:12:02.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m02s

they had a new language model where they
01:12:04.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m04s

basically this is from their blog post
01:12:06.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m06s

we basically said like of course this is
01:12:08.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m08s

what their neural net looks like somehow
01:12:10.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m10s

they always look like this on the
01:12:14.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m14s

internet you know you've got a bunch of
01:12:15.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m15s

words and it's basically going to take
01:12:17.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m17s

your particular words in their
01:12:19.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m19s

particular orders and try and figure out
01:12:21.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m21s

what the next words going to be which is
01:12:23.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m23s

to say they built a language model they
01:12:25.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m25s

actually have a pretty good language
01:12:27.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m27s

model if you've used SwiftKey they seem
01:12:28.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m28s

to do better predictions than anybody
01:12:30.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m30s

else still another cool example was
01:12:31.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m31s

andre capaci a couple of years ago
01:12:35.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m35s

showed that he could use character level
01:12:36.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m36s

are a 10 to actually create an entire
01:12:39.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m39s

latex document so he didn't actually
01:12:42.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m42s

tell it in any way what life looks like
01:12:45.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m45s

he just passed the
01:12:48.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m48s

some may tech text like this and said
01:12:49.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m49s

generate more low text text and it
01:12:52.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m52s

literally started writing something
01:12:54.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m54s

which means about as much to me as most
01:12:56.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m56s

math papers do this okay so we're gonna
01:12:58.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h12m58s

start with something that's not an RN
01:13:05.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m05s

and I'm going to introduce Jeremy's
01:13:07.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m07s

patented neural network notation
01:13:11.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m11s

involving boxes circles and triangles so
01:13:15.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m15s

let me explain what's going on as a
01:13:20.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m20s

rectangle is an input an arrow is a
01:13:23.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m23s

layer as a circle in fact every square
01:13:29.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m29s

is a bunch of activate so every shape is
01:13:35.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m35s

a bunch of activations right the
01:13:38.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m38s

rectangle is the input activations the
01:13:41.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m41s

circle is a hidden activations and a
01:13:43.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m43s

triangle is an output activations and
01:13:47.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m47s

arrow is a layer operation right or
01:13:51.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m51s

possibly more than one all right so here
01:13:56.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m56s

my rectangle is an input of number of
01:13:58.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h13m58s

rows equal a batch size and number of
01:14:02.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m02s

columns equal to the number of number of
01:14:04.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m04s

inputs number of variables all right and
01:14:06.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m06s

so my first arrow my first operation is
01:14:08.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m08s

going to represent a matrix product
01:14:11.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m11s

followed by our Lu and that's going to
01:14:13.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m13s

generate a set of activation remember
01:14:17.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m17s

activations like an activation is a
01:14:20.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m20s

number that an activation is a number a
01:14:23.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m23s

number that's being calculated by a
01:14:27.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m27s

value or a matrix product or whatever
01:14:29.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m29s

it's a number right so this circle here
01:14:32.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m32s

represents a matrix of activations all
01:14:35.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m35s

of the numbers that come out when we
01:14:39.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m39s

take the inputs we do a matrix product
01:14:41.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m41s

followed by a value so we started with
01:14:43.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m43s

batch size byte number of inputs and so
01:14:45.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m45s

after we do this matrix operation we now
01:14:47.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m47s

have batch size by you know whatever the
01:14:50.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m50s

number of columns in our matrix product
01:14:54.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m54s

was by number of hidden units okay and
01:14:56.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h14m56s

so if we now take these activations
01:15:00.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m00s

but it's the matrix and we put it
01:15:02.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m02s

through another operation in this case
01:15:04.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m04s

another matrix product and the softmax
01:15:06.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m06s

we get a triangle that's our output
01:15:08.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m08s

activations another matrix of
01:15:10.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m10s

activations and again number of roses
01:15:12.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m12s

batch size number of columns number is
01:15:14.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m14s

equal to the number of classes again
01:15:17.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m17s

however many columns our matrix in this
01:15:18.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m18s

matrix product head so that's a that's a
01:15:21.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m21s

neuro net right that's our basic kind of
01:15:27.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m27s

one hidden layer neural net and if you
01:15:29.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m29s

haven't written one of these from
01:15:34.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m34s

scratch try it you know and in fact in
01:15:35.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m35s

lessons nine ten and eleven of the
01:15:39.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m39s

machine learning course we do this right
01:15:41.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m41s

we create one of these from scratch so
01:15:43.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m43s

if you're not quite sure how to do it
01:15:46.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m46s

you can check out the machine learning
01:15:47.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m47s

costs yeah in general the machine
01:15:49.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m49s

learning cost is much more like building
01:15:51.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m51s

stuff up from the foundations where else
01:15:54.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m54s

this course is much more like best
01:15:56.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m56s

practices kind of top-down all right so
01:15:58.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h15m58s

if we were doing like a cognate with a
01:16:02.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m02s

single dense hidden layer our input
01:16:05.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m05s

would be equal to actually number yeah
01:16:08.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m08s

that's very implied watch number of
01:16:11.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m11s

channels by height by width right and
01:16:13.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m13s

notice that here batch size appeared
01:16:16.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m16s

every time so I'm not gonna I'm not
01:16:18.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m18s

gonna write it anymore
01:16:20.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m20s

okay so I've removed the batch size also
01:16:21.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m21s

the activation function it's always
01:16:26.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m26s

basically value or something similar for
01:16:28.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m28s

all the hidden layers and softmax at the
01:16:30.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m30s

end for classification so I'm not going
01:16:33.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m33s

to write that either okay so I'm kind of
01:16:34.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m34s

edge picture I'm going to simplify it a
01:16:36.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m36s

little bit alright so I'm not gonna
01:16:38.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m38s

mention batch size it's still there
01:16:41.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m41s

we're not going to mention real you or
01:16:42.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m42s

softmax but it's still there so here's
01:16:43.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m43s

our input and so in this case rather
01:16:45.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m45s

than a matrix product will do a
01:16:47.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m47s

convolution let's drive to convolution
01:16:50.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m50s

so we'll skip over every second one or
01:16:53.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m53s

could be a convolution followed by a mac
01:16:56.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m56s

spool in either case we end up with
01:16:58.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h16m58s

something which is replaced number of
01:17:01.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m01s

channels with number of filters right
01:17:03.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m03s

and we have now height divided by two
01:17:05.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m05s

and width divided by 2
01:17:08.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m08s

okay and then we can flatten that out
01:17:09.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m09s

somehow we'll talk next week about the
01:17:12.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m12s

main way
01:17:15.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m15s

we do that nowadays which is basically
01:17:15.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m15s

to do something called an adaptive max
01:17:17.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m17s

pooling where we basically get an
01:17:19.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m19s

average across the height and the width
01:17:21.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m21s

and turn that into a vector anyway
01:17:24.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m24s

somehow we flatten it out into a vector
01:17:28.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m28s

we can do a matrix product or a couple
01:17:29.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m29s

of matrix products we actually tend to
01:17:33.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m33s

do in fast AI so that'll be our fully
01:17:34.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m34s

connected layer with some number of
01:17:38.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m38s

activations final matrix product give us
01:17:40.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m40s

some number of classes okay so this is
01:17:43.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m43s

our basic component remembering
01:17:46.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m46s

rectangles input circle is hidden
01:17:48.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m48s

triangle is output all other shapes
01:17:51.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m51s

represent a tensor of activations all of
01:17:54.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m54s

the arrows represent a operation or lay
01:17:59.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h17m59s

operation all right
01:18:02.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m02s

so now that's going to jump to the one
01:18:04.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m04s

the first one that we're going to
01:18:06.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m06s

actually try to try to create for NLP
01:18:07.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m07s

and we're going to basically do exactly
01:18:12.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m12s

the same thing as here right and we're
01:18:14.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m14s

going to try and predict the third
01:18:17.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m17s

character in a three character sequence
01:18:18.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m18s

based on the previous two characters so
01:18:21.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m21s

our input and again remember we've
01:18:25.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m25s

removed the batch size dimension we're
01:18:29.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m29s

not saying that we're still here okay
01:18:33.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m33s

and also here I've removed the names of
01:18:35.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m35s

the layer operations entirely
01:18:39.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m39s

okay just keeping simplifying things so
01:18:41.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m41s

for example our first import would be
01:18:43.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m43s

the first character of each string in
01:18:46.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m46s

our mini batch okay and assuming this is
01:18:50.700
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m50s

one hot encoded then the width is just
01:18:54.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m54s

however many items there are in the
01:18:57.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m57s

vocabulary how many unique characters
01:18:59.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h18m59s

could we have okay we probably won't
01:19:01.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m01s

really one hot encoder will feed it in
01:19:04.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m04s

as an integer and pretend it's one hot
01:19:06.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m06s

encoded by using an embedding layer
01:19:08.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m08s

which is mathematically identical okay
01:19:09.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m09s

and then we that's going to give us some
01:19:12.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m12s

activations which we can stick through a
01:19:15.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m15s

fully connected layer okay so we we put
01:19:16.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m16s

that through if we click through a fully
01:19:23.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m23s

connected layer to get some activations
01:19:25.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m25s

we can then put that
01:19:27.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m27s

another fully connected layer and now
01:19:29.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m29s

we're going to bring in the input of
01:19:31.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m31s

character to alright so the character to
01:19:34.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m34s

input will be exactly the same
01:19:36.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m36s

dimensionality as the character one
01:19:37.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m37s

input and we now need to somehow combine
01:19:39.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m39s

these two arrows together so we could
01:19:42.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m42s

just add them up for instance right
01:19:45.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m45s

because remember this arrow here
01:19:47.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m47s

represents a matrix product so this
01:19:50.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m50s

matrix product is going to spit out the
01:19:53.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m53s

same dimensionality as this matrix
01:19:55.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m55s

product so we could just add them up to
01:19:56.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m56s

create these activations and so now we
01:19:59.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h19m59s

can put that through another matrix
01:20:02.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m02s

product and of course remember all these
01:20:04.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m04s

metrics products have a RAL you as well
01:20:05.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m05s

and this final one will have a softmax
01:20:08.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m08s

instead to create our predicted set of
01:20:10.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m10s

characters right so it's a standard you
01:20:13.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m13s

know two hidden layer
01:20:18.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m18s

I guess it's actually three matrix
01:20:20.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m20s

products neural net this first one is
01:20:23.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m23s

coming through an embedding layer the
01:20:27.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m27s

only difference is that we're also got a
01:20:29.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m29s

second input coming in here that we're
01:20:32.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m32s

just adding in right but it's kind of
01:20:34.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m34s

conceptually identical so let's let's
01:20:36.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m36s

implement that for Nietzsche all right
01:20:39.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m39s

so I'm not going to use torch text I'm
01:20:46.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m46s

gonna try not to use almost any fast AI
01:20:48.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m48s

so we can see it all kind of again from
01:20:51.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m51s

raw right so here's the first 400
01:20:53.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m53s

characters of the collected works let's
01:20:56.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m56s

grab a set of all of the letters that we
01:20:59.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h20m59s

see there and sort them okay and so a
01:21:02.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m02s

set creates all the unique letters so
01:21:06.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m06s

we've got 85 unique letters in our vocab
01:21:08.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m08s

let's pop up it's nice to put an empty
01:21:12.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m12s

kind of a null or some some kind of
01:21:15.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m15s

padding character in there for padding
01:21:17.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m17s

so we're gonna put a parenting character
01:21:18.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m18s

at the start right and so here is what
01:21:20.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m20s

our vocab looks like okay so so Kars is
01:21:23.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m23s

our bouquet so as per usual we want some
01:21:29.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m29s

way to map every character to a unique
01:21:33.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m33s

ID and every unique ID to a character
01:21:37.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m37s

and
01:21:41.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m41s

so now we can just go through our
01:21:42.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m42s

collected works of niche and grab the
01:21:44.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m44s

index of each one of those characters so
01:21:48.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m48s

now we've just turned it into this right
01:21:51.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m51s

so rather than quote PR e we now have 40
01:21:54.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h21m54s

42 29 okay so so that's basically the
01:22:01.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m01s

first step and just to confirm we can
01:22:08.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m08s

now take each of those indexes and turn
01:22:10.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m10s

them back into characters and join them
01:22:13.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m13s

together and yeah there it is okay so
01:22:15.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m15s

from now on we're just going to work
01:22:20.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m20s

with this IDX
01:22:21.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m21s

list the list of character members in
01:22:23.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m23s

the connected works of Nietzsche yes so
01:22:26.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m26s

Jeremy why are we doing like a model of
01:22:30.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m30s

characters and not a model of words I
01:22:33.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m33s

just thought it seemed simpler you know
01:22:36.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m36s

with a vocab of 80-ish items we can kind
01:22:38.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m38s

of see it better character level models
01:22:42.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m42s

turn out to be potentially quite useful
01:22:47.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m47s

in a number of situations but we'll
01:22:50.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m50s

cover that in part two the short answer
01:22:51.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m51s

is like you generally want to combine
01:22:54.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m54s

both the word level model and a connect
01:22:57.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m57s

character level model like if you're
01:22:58.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m58s

doing say translation it's a great way
01:22:59.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h22m59s

to deal with unknown like unusual words
01:23:02.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m02s

rather than treating it as unknown
01:23:04.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m04s

anytime you see a word you haven't seen
01:23:05.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m05s

before you could use a character level
01:23:07.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m07s

model for that and there's actually
01:23:09.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m09s

something in between the two quarter
01:23:11.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m11s

byte pair and coding vpe which basically
01:23:13.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m13s

looks at at all engrams of characters
01:23:15.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m15s

but we'll cover all that in part two if
01:23:18.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m18s

you want to look at it right now
01:23:22.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m22s

then part two of the existing course
01:23:24.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m24s

already has this stuff taught and part
01:23:27.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m27s

two of the version 1 of this course
01:23:30.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m30s

although the NLP stuff is in flight
01:23:33.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m33s

which by the way so you'll understand it
01:23:35.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m35s

straight away it was actually the thing
01:23:38.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m38s

that inspired us to move to piped watch
01:23:41.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m41s

because trying to do it in chaos turned
01:23:43.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m43s

out to be a nightmare all right so let's
01:23:44.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m44s

create the inputs to this we're actually
01:23:48.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m48s

going to do something slightly different
01:23:52.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m52s

what I said we're actually going to
01:23:53.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m53s

I predict the fourth character that
01:23:55.679
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m55s

actually this the fifth character using
01:23:58.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h23m58s

the first four so the index four
01:24:00.659
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m00s

character using the index zero one two
01:24:02.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m02s

and three okay so it was exactly the
01:24:04.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m04s

same thing but with just a couple more
01:24:06.539
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m06s

layers so that means that we need a list
01:24:08.459
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m08s

of the zeroth first second and third
01:24:11.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m11s

characters that's why I'm just cutting
01:24:17.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m17s

every character from the start from the
01:24:19.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m19s

one from two from three skipping over
01:24:21.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m21s

three at a time okay
01:24:24.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m24s

so hmm
01:24:28.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m28s

this is I I said this wrong so we're
01:24:32.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m32s

going to predict the third character the
01:24:36.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m36s

fourth character from the third for the
01:24:39.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m39s

first story okay
01:24:41.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m41s

the fourth character is history
01:24:42.479
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m42s

all right so our inputs will be these
01:24:46.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m46s

three lists right so we can just use n P
01:24:50.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m50s

dot stack to pop them together all right
01:24:53.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m53s

so here's the zero one and two
01:24:57.539
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h24m57s

characters that are going to feed into a
01:25:01.639
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m01s

model and then here is the next
01:25:04.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m04s

character in the list so for example X 1
01:25:05.519
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m05s

X 2 X 3 and Y all right so you can see
01:25:13.729
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m13s

for example we start off the first the
01:25:23.249
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m23s

very first item would be 40 42 and 29
01:25:25.829
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m25s

right so that's characters naught 1 and
01:25:33.749
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m33s

2 and then we'd be predicting 30 that's
01:25:36.539
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m36s

the fourth character which is the start
01:25:40.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m40s

of the next row
01:25:44.789
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m44s

all right so then 30 25 27 we need to
01:25:46.289
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m46s

predict 29 which is the start of next
01:25:49.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m49s

row and so forth so we're always using
01:25:52.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m52s

three characters to predict the fourth
01:25:54.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m54s

so there are 200,000 of these that we're
01:25:59.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h25m59s

going to try and model right so we're
01:26:05.189
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m05s

going to build this
01:26:08.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m08s

which means we need to decide how many
01:26:09.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m09s

activations so I'm going to use 256 okay
01:26:11.159
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m11s

and we need to decide how big our
01:26:18.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m18s

embeddings are going to be and so I
01:26:19.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m19s

decided to use 42 so about half the
01:26:21.899
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m21s

number of characters I have and you can
01:26:24.029
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m24s

play around these so you can come up
01:26:27.449
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m27s

with better numbers it's just a kind of
01:26:28.709
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m28s

experimental and now we're going to
01:26:30.149
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m30s

build our model now I'm gonna change my
01:26:32.729
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m32s

model slightly and so here is the the
01:26:35.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m35s

full version so predicting character for
01:26:38.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m38s

using characters 1 2 &amp; 3 as you can see
01:26:41.249
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m41s

it's the same picture as a previous page
01:26:44.399
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m44s

but I put some very important coloured
01:26:45.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m45s

arrows here all the arrows of the same
01:26:48.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m48s

color are going to use the same matrix
01:26:51.299
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m51s

the same weight matrix right so all of
01:26:54.629
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m54s

our input embeddings are going to use
01:26:58.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h26m58s

the same matrix all of our layers that
01:27:00.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m00s

go from one layer to the next they're
01:27:05.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m05s

going to use the same orange arrow
01:27:07.529
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m07s

weight matrix and then our output will
01:27:09.689
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m09s

have its own matrix so we're going to
01:27:13.199
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m13s

have one two three weight matrices right
01:27:15.359
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m15s

and the idea here is the reason I'm not
01:27:19.859
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m19s

gonna have a separate one but every
01:27:22.499
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m22s

everything here is that like why would
01:27:24.089
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m24s

kind of semantically a carrot to have a
01:27:27.359
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m27s

different meaning depending if it's the
01:27:29.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m29s

first or the second or the third item in
01:27:31.049
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m31s

a sequence like it's not like we're even
01:27:33.029
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m33s

starting every sequence at the start of
01:27:34.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m34s

a sentence we're just arbitrarily
01:27:36.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m36s

chopped it into groups of three right so
01:27:37.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m37s

you would expect these to all have the
01:27:39.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m39s

same kind of conceptual mapping and
01:27:41.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m41s

ditto like when we're moving from
01:27:44.189
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m44s

claritin or character one you know to
01:27:45.809
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m45s

kind of say build up some state here why
01:27:48.659
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m48s

would that be any different kind of
01:27:51.149
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m51s

operation to moving from character
01:27:52.499
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m52s

wonder character to so that's the basic
01:27:53.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m53s

idea so let's create a three character
01:27:56.939
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h27m56s

model and so we're going to create one
01:28:00.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m00s

linear layer for our Green Arrow one
01:28:04.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m04s

linear layer fat orange arrow and one
01:28:06.899
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m06s

linear layer for our blue arrow and then
01:28:09.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m09s

also one embedding okay so the embedding
01:28:11.819
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m11s

is going to bring in something with size
01:28:16.529
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m16s

whatever it was 84
01:28:18.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m18s

I think vocab size and spit out
01:28:20.609
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m20s

something with an
01:28:22.139
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m22s

factors in the embedding well then put
01:28:23.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m23s

that through a linear layer and then
01:28:26.429
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m26s

we've got our hidden layers before the
01:28:29.519
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m29s

output layer so when we call forward
01:28:30.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m30s

they're going to be passing in one two
01:28:34.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m34s

three characters so if each one will
01:28:37.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m37s

stick it through an embedding we'll
01:28:40.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m40s

stick it through a linear layer and
01:28:42.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m42s

we'll stick it through a value just to
01:28:44.639
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m44s

do it the character one character - and
01:28:46.769
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m46s

character three okay
01:28:48.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m48s

then I'm going to create this circle of
01:28:51.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h28m51s

activations here okay and that matrix
01:29:05.099
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m05s

I'm going to call H right and so it's
01:29:07.769
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m07s

going to be equal to my input
01:29:10.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m10s

activations okay after going through the
01:29:12.539
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m12s

value and the linear layer and the
01:29:17.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m17s

embedding right and then I'm going to
01:29:19.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m19s

apply this l hidden so the orange arrow
01:29:21.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m21s

and that's going to get me to here okay
01:29:26.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m26s

so that's what this layer here does and
01:29:30.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m30s

then to get to the next one I need to
01:29:32.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m32s

reply the same thing and it apply the
01:29:34.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m34s

orange arrow to that okay but I also
01:29:36.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m36s

have to add in this second input right
01:29:40.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m40s

so take my second input and add in okay
01:29:43.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m43s

my previous layer your neck could you
01:29:48.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m48s

pass it back three rows I don't really
01:29:52.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m52s

see how these dimensions are the same
01:29:58.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h29m58s

from eight and in2 from literature which
01:30:01.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m01s

from yeah okay let's go through so let's
01:30:05.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m05s

figure out the dimensions together so
01:30:07.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m07s

self dot E is gonna be of length 42 okay
01:30:10.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m10s

and then it's gonna go through L in I'm
01:30:16.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m16s

just gonna make it of size n hidden okay
01:30:18.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m18s

and so then we're going to pass that
01:30:24.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m24s

which is now size n hidden through this
01:30:26.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m26s

which is also going to return something
01:30:30.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m30s

of size n hidden
01:30:34.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m34s

okay so it's a really important to
01:30:35.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m35s

notice that this is square this is a
01:30:37.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m37s

square weight matrix okay so we now know
01:30:39.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m39s

that this is of size n hidden into it's
01:30:43.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m43s

going to be exactly the same size as in
01:30:46.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m46s

one was which is n hidden so we can now
01:30:47.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m47s

sum together two sets of activations
01:30:50.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m50s

both the size n hidden passing it into
01:30:53.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m53s

here and again it returns something of
01:30:56.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m56s

size n hidden so basically the trick was
01:30:59.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h30m59s

to make this a square matrix and to make
01:31:01.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m01s

sure that it's square matrix was the
01:31:03.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m03s

same size as the output of this hidden
01:31:05.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m05s

well thanks for the great question can
01:31:06.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m06s

you pass that out to you now Jeremy is
01:31:09.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m09s

summing the only thing people can do in
01:31:16.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m16s

these cases I'll come back to that in a
01:31:19.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m19s

moment that's great point okay um I
01:31:21.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m21s

don't like it when I have like three
01:31:25.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m25s

bits of code that look identical and
01:31:28.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m28s

then three bits of codes that look
01:31:29.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m29s

nearly identical but aren't quiet
01:31:31.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m31s

because it's harder to refactor so I'm
01:31:32.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m32s

going to put a make H into a bunch of
01:31:35.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m35s

zeros so that I can then put H here and
01:31:40.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m40s

these are now identical okay so that the
01:31:45.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m45s

hugely complex trick that we're going to
01:31:49.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m49s

do very shortly is to replace these
01:31:51.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m51s

three things with a for loop okay and
01:31:54.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m54s

it's going to loop through one two and
01:31:57.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h31m57s

three that's that's going to be the for
01:32:00.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m00s

loop or actually zero one two okay at
01:32:02.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m02s

that point we'll be able to call it a
01:32:05.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m05s

recurrent neural network okay so just to
01:32:06.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m06s

skip ahead a little bit alright so we
01:32:09.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m09s

create that that model make sure I've
01:32:12.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m12s

run all these so we can actually run
01:32:16.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m16s

this thing okay so we can now just use
01:32:17.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m17s

the same columnar model data class that
01:32:24.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m24s

we've used before and if we use from
01:32:26.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m26s

arrays then it's basically it's going to
01:32:28.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m28s

spit back the exact arrays we gave it
01:32:31.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m31s

right so if we pass if we stack together
01:32:33.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m33s

those three arrays then it's going to
01:32:36.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m36s

feed us those three things back to our
01:32:38.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m38s

forward method so if you want to like
01:32:40.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m40s

play around with training models using
01:32:43.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m43s

like you know as roar
01:32:47.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m47s

approach as possible but without writing
01:32:49.889
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m49s

lots of boilerplate this is kind of how
01:32:51.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m51s

to do it here's column Namit model data
01:32:53.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m53s

from arrays and then if you pass in
01:32:55.649
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m55s

whatever you pass in here right you're
01:32:58.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h32m58s

going to get back here okay so I've
01:33:01.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m01s

passed in three things which means I'm
01:33:06.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m06s

going to get sent three things okay so
01:33:09.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m09s

that's how that works
01:33:11.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m11s

batch size 512 because this is you know
01:33:14.189
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m14s

this data is tiny so I can use a bigger
01:33:16.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m16s

batch size so I'm not using really much
01:33:18.209
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m18s

faster i stuff at all I'm using fast AI
01:33:23.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m23s

stuff just to save me fiddling around
01:33:25.229
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m25s

with data loaders and data sets and
01:33:27.059
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m27s

stuff but I'm actually going to create a
01:33:28.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m28s

standard ply torch model I'm not going
01:33:30.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m30s

to create a loner okay so this is a
01:33:33.209
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m33s

standard paper model and because I'm
01:33:35.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m35s

using ply towards that means I have to
01:33:36.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m36s

remember to write CUDA okay let's tick
01:33:38.249
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m38s

it on the GPU so here is how we can look
01:33:40.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m40s

inside at what's going on right so we
01:33:49.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m49s

can say it er MD train data loader to
01:33:50.939
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m50s

grab the iterator to iterate through the
01:33:54.269
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m54s

training set we can then call next on
01:33:56.429
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m56s

that to grab a mini batch and that's
01:33:59.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h33m59s

going to return all of our X's and why
01:34:01.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m01s

tensor and so we can then take a look at
01:34:05.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m05s

you know here's our X's for example all
01:34:08.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m08s

right and so you would expect have a
01:34:13.619
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m13s

think about what you would expect for
01:34:16.169
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m16s

this length three not surprisingly
01:34:17.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m17s

because these are the three things okay
01:34:22.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m22s

and so then XS 0 not surprisingly okay
01:34:24.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m24s

is of length 512 and it's not actually
01:34:32.459
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m32s

one hot encoded because we use an
01:34:37.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m37s

embedding to pretend it is okay and so
01:34:38.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m38s

then we can use a model as if it's a
01:34:41.399
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m41s

function okay by passing to it
01:34:42.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m42s

the variable eyes version of our tensors
01:34:46.099
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m46s

and so have a think about what you would
01:34:49.079
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m49s

expect to be returned here okay so not
01:34:51.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m51s

surprisingly we had a mini batch of 512
01:34:56.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m56s

so we still have 5 12 and then 85 is the
01:34:58.349
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h34m58s

probability of each of the possible
01:35:01.439
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m01s

vocab items and of course we've got the
01:35:03.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m03s

log of them because that's kind of what
01:35:05.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m05s

we do in pi torch okay you can see here
01:35:07.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m07s

the softmax alright so that's how you
01:35:09.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m09s

can look inside alright so you can see
01:35:12.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m12s

here how to do everything really very
01:35:14.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m14s

much by hand so we can create an
01:35:15.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m15s

optimizer again using standard pipe
01:35:19.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m19s

torch so with PI torch when you use a
01:35:22.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m22s

plate or optimizer you have to pass in a
01:35:24.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m24s

list of the things to optimize and so if
01:35:27.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m27s

you call m dot parameters that will
01:35:29.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m29s

return that list for you and then we can
01:35:31.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m31s

fit and there it goes
01:35:34.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m34s

okay and so we don't have learning rate
01:35:37.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m37s

finders and sttr and all that stuff
01:35:43.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m43s

because we're not using a learner so
01:35:46.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m46s

we'll have to manually do learning rate
01:35:47.469
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m47s

annealing so set the learning rate a
01:35:48.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m48s

little bit lower and fit again okay and
01:35:50.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m50s

so now we can write a little function to
01:35:57.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h35m57s

to test this thing out okay
01:36:01.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m01s

so here's something called getnext where
01:36:03.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m03s

we can pass in three characters like why
01:36:10.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m10s

full top space right and so I can then
01:36:14.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m14s

go through and turn that into a tensor
01:36:17.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m17s

with capital T of an array of the
01:36:19.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m19s

character index for each character in
01:36:24.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m24s

that list
01:36:26.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m26s

so basically turn those into the
01:36:27.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m27s

integers turn those into variables pass
01:36:28.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m28s

that to our model right and then we can
01:36:31.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m31s

do an Arg max on that to grab which
01:36:35.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m35s

character number is it and in order to
01:36:38.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m38s

do stuff in none pile and I use two NP
01:36:40.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m40s

to turn that variable into a lumpy array
01:36:43.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m43s

right and then I can return that
01:36:45.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m45s

character and so for example a capital T
01:36:47.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m47s

because what it thinks would be
01:36:49.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m49s

reasonable after seeing why . space that
01:36:51.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m51s

seems like a very reasonable way to
01:36:55.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m55s

start a sentence if it was ppl a that
01:36:56.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h36m56s

sounds reasonable space th a that's
01:37:00.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m00s

bouncer e small a and D space that
01:37:02.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m02s

sounds reasonable
01:37:05.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m05s

so it seems to reflect created something
01:37:05.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m05s

sensible alright so you know the
01:37:08.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m08s

important thing to note here is our
01:37:11.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m11s

character model
01:37:15.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m15s

is a totally standard fully connected
01:37:17.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m17s

model right the only slightly
01:37:21.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m21s

interesting thing we did was to kind of
01:37:23.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m23s

do this addition of each of the inputs
01:37:27.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m27s

one at a time okay but there's nothing
01:37:31.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m31s

new conceptually here we're training it
01:37:36.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m36s

in the usual way
01:37:39.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m39s

all right let's now create an errand in
01:37:42.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m42s

so an iron in is when we do exactly the
01:37:49.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m49s

same thing that we did here all right
01:37:59.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h37m59s

but I could draw this more simply by
01:38:03.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m03s

saying you know what if we've got a
01:38:05.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m05s

green arrow going to a circle let's not
01:38:07.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m07s

draw a green arrow go into a circle
01:38:10.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m10s

again and again and again so let's just
01:38:12.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m12s

draw it like this green arrow going to a
01:38:14.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m14s

circle right and rather than drawing an
01:38:16.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m16s

orange arrow going to a circle let's
01:38:18.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m18s

just draw it like this okay so this is
01:38:20.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m20s

the same picture exactly the same
01:38:24.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m24s

picture as this one right and so you
01:38:27.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m27s

just have to say how many times to go
01:38:32.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m32s

around this circle right so in this case
01:38:33.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m33s

if we were to predict character number n
01:38:35.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m35s

from characters one through n minus one
01:38:37.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m37s

then we can take the character one input
01:38:39.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m39s

get some activations feed that to some
01:38:41.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m41s

new activations that go through remember
01:38:44.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m44s

orange is the hidden to hidden weight
01:38:46.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m46s

matrix right and each time we'll also
01:38:49.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m49s

bring in the next character of input
01:38:51.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m51s

through its embeddings okay so that
01:38:53.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m53s

picture and that picture I have two ways
01:38:57.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h38m57s

of writing the same thing but this one
01:39:01.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m01s

is more flexible because rather than me
01:39:04.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m04s

having to say hey let's do it for H I
01:39:06.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m06s

don't have to draw eight circles right I
01:39:07.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m07s

can just say I'll just repeat this so I
01:39:10.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m10s

could simplify this a little bit further
01:39:16.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m16s

by saying you know what rather than
01:39:17.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m17s

having this thing as a special case
01:39:21.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m21s

let's actually start out with a bunch of
01:39:23.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m23s

zeros right and then let's have all of
01:39:26.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m26s

our characters
01:39:28.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m28s

inside here yes yeah so I was wondering
01:39:30.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m30s

if you can explain it be better why are
01:39:39.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m39s

you reusing those why you think oh
01:39:41.889
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m41s

they're the same yeah where are you you
01:39:45.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m45s

kind of seem to be reusing the same same
01:39:47.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m47s

weight matrices weight matrices yeah
01:39:50.499
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m50s

maybe this is kind of similar to what we
01:39:52.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m52s

did in convolution your Nets like if
01:39:55.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m55s

somehow no I don't think so
01:39:57.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h39m57s

at least not that I can see so the idea
01:40:00.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m00s

is just kind of semantically speaking
01:40:02.679
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m02s

like this arrow here this this arrow
01:40:05.679
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m05s

here is saying take a character of
01:40:12.579
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m12s

import and represented as some says some
01:40:17.499
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m17s

set of features right and this arrow is
01:40:21.999
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m21s

saying the same thing take some
01:40:24.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m24s

character and represent as a set of
01:40:26.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m26s

features and so is this one okay so like
01:40:27.249
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m27s

why would the three be represented with
01:40:30.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m30s

different weight matrices because it's
01:40:32.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m32s

all doing the same thing right and this
01:40:34.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m34s

orange arrow is saying kind of
01:40:36.519
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m36s

transition from character 0 state to
01:40:40.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m40s

character 1 state 2 characters to state
01:40:44.019
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m44s

again it's it's the same thing it's like
01:40:46.769
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m46s

why would the transition from character
01:40:49.539
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m49s

0 to 1 be different to character from
01:40:51.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m51s

transition from one or two so the idea
01:40:53.409
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m53s

is like but is to like say hey if if
01:40:55.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m55s

it's doing the same conceptual thing
01:40:59.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h40m59s

let's use the exact same white matrix my
01:41:02.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m02s

comment on convolution neural networks
01:41:07.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m07s

is that a filter or so this apply to
01:41:09.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m09s

multiple places I think something like a
01:41:12.159
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m12s

convolution is almost like a kind of a
01:41:16.599
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m16s

special dot product with shared weights
01:41:18.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m18s

yeah no that's okay
01:41:21.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m21s

that's very good point and in fact one
01:41:22.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m22s

of our students actually wrote a good
01:41:25.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m25s

blog post about that last year we should
01:41:27.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m27s

dig that up okay I totally see where
01:41:29.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m29s

you're coming from and I totally agree
01:41:31.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m31s

with you all right so let's let's
01:41:32.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m32s

implement this version so this time
01:41:37.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m37s

we're going to do eight
01:41:41.499
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m41s

as eight sees okay and so let's create a
01:41:43.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m43s

list of every eighth character from zero
01:41:48.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m48s

through seven and then our outputs will
01:41:52.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m52s

be the next character and so we can
01:41:55.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m55s

stack them together and so now we've got
01:41:57.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h41m57s

six hundred thousand by eight so here's
01:42:00.159
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m00s

an example so for example after this
01:42:05.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m05s

series of eight characters right so this
01:42:11.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m11s

is characters north through eight
01:42:15.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m15s

this is characters one through nine this
01:42:17.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m17s

is two through ten these are all
01:42:20.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m20s

overlapping okay so after characters one
01:42:21.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m21s

north through eight this is going to be
01:42:25.119
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m25s

the next one okay and then after these
01:42:27.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m27s

characters this will be the next one all
01:42:30.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m30s

right so you can see that this one here
01:42:33.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m33s

has 43 is its Y value right because
01:42:35.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m35s

after those the next one will be 43 okay
01:42:39.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m39s

so so this is the first eight characters
01:42:42.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m42s

this is two through nine three through
01:42:46.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m46s

ten and so forth right so these are
01:42:49.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m49s

overlapping groups of eight characters
01:42:51.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m51s

and then this is the the next one okay
01:42:53.139
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m53s

so let's create that model okay so again
01:42:57.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h42m57s

we use from arrays to create a model
01:43:06.639
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m06s

data class and so you'll see here we
01:43:09.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m09s

have exactly the same code as we had
01:43:12.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m12s

before
01:43:14.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m14s

there's our embedding Linea hidden
01:43:14.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m14s

output these are literally identical
01:43:18.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m18s

okay and then we've replaced our value
01:43:20.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m20s

of the linear input of the embedding
01:43:25.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m25s

with something that's inside a loop okay
01:43:27.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m27s

and then we've replaced the cell hidden
01:43:30.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m30s

thing okay
01:43:33.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m33s

also inside the loop
01:43:35.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m35s

I just realize didn't mentioned last
01:43:43.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m43s

time the use of the hyperbolic tan
01:43:45.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m45s

hyperbolic tan looks like this okay so
01:43:48.699
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m48s

it's just a sigmoid that's offset right
01:43:57.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m57s

and it's very common to use a hyperbolic
01:43:59.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h43m59s

tan inside this trend this state to
01:44:02.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m02s

state transition because it kind of
01:44:05.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m05s

stops it from flying off too high or too
01:44:07.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m07s

low you know it's nicely controlled back
01:44:09.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m09s

in the old days we used to use
01:44:14.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m14s

hyperbolic tanh or the equivalent
01:44:15.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m15s

sigmoid a lot as most of our activation
01:44:19.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m19s

functions nowadays we tend to use value
01:44:22.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m22s

but in these hidden state to here in the
01:44:24.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m24s

hidden state transition weight matrices
01:44:28.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m28s

we still tend to use hyperbolic tanh
01:44:31.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m31s

quite a lot so you'll see I've done that
01:44:33.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m33s

also yeah hyperbolic tanh okay so this
01:44:36.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m36s

is exactly the same as before but I've
01:44:42.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m42s

just replaced it with a Pollard and then
01:44:43.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m43s

here's my output yes you know so a does
01:44:45.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m45s

he have to do anything with convergence
01:44:50.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m50s

these networks yeah we'll talk about
01:44:52.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m52s

that a little bit over time let's let's
01:44:57.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h44m57s

let's come back to that though for now
01:45:00.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m00s

we're not really going to do anything
01:45:03.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m03s

special at all you know recognizing this
01:45:04.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m04s

is just a standard fully connected
01:45:06.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m06s

Network you know interestingly it's
01:45:09.050
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m09s

quite a deep one right like because this
01:45:11.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m11s

is actually this that we've got eight of
01:45:16.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m16s

these things now we've now got a deep
01:45:19.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m19s

eight layer Network which is why units
01:45:22.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m22s

starting suggest we should be concerned
01:45:24.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m24s

as you know as we get deeper and deeper
01:45:26.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m26s

networks they can be harder and harder
01:45:28.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m28s

to train but let's try training this
01:45:29.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m29s

all right so when it goes as before
01:45:37.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m37s

we've got a batch size of 512 we're
01:45:41.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m41s

using Adam and where it goes so we will
01:45:45.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m45s

sit there watching it so we can then set
01:45:49.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m49s

the learning rate down back to 20 neg 3
01:45:51.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m51s

we can fit it again and yeah it's
01:45:53.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m53s

actually it seems to be training fun
01:45:58.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h45m58s

okay but we're gonna try something else
01:46:01.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m01s

which is we're going to use this a trick
01:46:05.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m05s

that your net rather hinted at before
01:46:07.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m07s

which is maybe we shouldn't be adding
01:46:09.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m09s

these things together and so the reason
01:46:11.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m11s

you might want to be feeling a little
01:46:14.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m14s

uncomfortable about adding these things
01:46:15.990
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m15s

together is that the input state and the
01:46:18.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m18s

hidden state are kind of qualitatively
01:46:23.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m23s

different kinds of things right the
01:46:26.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m26s

input state is the is the encoding of
01:46:28.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m28s

this character for us H represents the
01:46:31.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m31s

encoding of the series of characters so
01:46:34.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m34s

far and so adding them together is kind
01:46:36.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m36s

of potentially going to lose information
01:46:39.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m39s

so I think what your net was going to
01:46:42.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m42s

prefer that we might do is maybe to
01:46:44.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m44s

concatenate these instead of adding them
01:46:46.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m46s

so it sound good to you you know she's
01:46:47.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m47s

not it okay so let's now make a copy of
01:46:49.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m49s

the previous cell all the same right
01:46:53.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m53s

rather than using plus let's use cat
01:46:56.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m56s

okay now if we can cat then we need to
01:46:59.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h46m59s

make sure now that our input layer is
01:47:03.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m03s

not from n fac-2 hidden which is what we
01:47:06.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m06s

had before but because we're
01:47:11.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m11s

concatenated it needs to be in fact plus
01:47:12.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m12s

and hidden to end hidden okay and so now
01:47:15.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m15s

that's going to make all the dimensions
01:47:19.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m19s

work nicely so this now is of size n
01:47:20.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m20s

fact plus and hidden this now makes it
01:47:26.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m26s

back to size n hidden again okay and
01:47:30.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m30s

then this is putting it through the same
01:47:33.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m33s

square matrix as before so it's still a
01:47:35.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m35s

size n here okay so this is like a good
01:47:37.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m37s

design heuristic if you're designing an
01:47:42.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m42s

architecture is if you've got different
01:47:45.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m45s

types of information that you want to
01:47:47.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m47s

combine you generally want
01:47:49.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m49s

concatenate it okay you know adding
01:47:51.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m51s

things together even if they're the same
01:47:54.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m54s

shape is losing information okay and so
01:47:56.320
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h47m56s

once you've concatenated things together
01:48:00.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m00s

you can always convert it back down to a
01:48:02.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m02s

fixed size by just tracking it through a
01:48:05.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m05s

matrix product okay so that's what we've
01:48:08.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m08s

done here again it's the same thing but
01:48:11.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m11s

now we're concatenating instead and so
01:48:12.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m12s

we can fit that and so last time we got
01:48:17.469
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m17s

one point seven two this time you go at
01:48:19.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m19s

one point six six so it's not setting
01:48:23.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m23s

the world on fire but it's an
01:48:25.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m25s

improvement and the improvements of it
01:48:26.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m26s

okay
01:48:28.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m28s

so we can now test that with get next
01:48:29.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m29s

and so now we can pass in eight things
01:48:32.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m32s

right so it's no before those let's go
01:48:34.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m34s

to a part of that sounds good as well so
01:48:38.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m38s

Queens and that sounds good too all
01:48:41.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m41s

right so great so that's enough
01:48:45.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m45s

manual hackery let's see if pi torch
01:48:49.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m49s

couldn't do some of this for us and so
01:48:53.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m53s

basically what pi torch will do for us
01:48:55.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m55s

is it will write this loop automatically
01:48:58.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h48m58s

okay and it will create these linear
01:49:02.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m02s

input layers automatically okay and so
01:49:05.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m05s

to ask it to do that we can use the n n
01:49:08.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m08s

dot R and n plus so here's the exact
01:49:11.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m11s

same thing in less code by taking
01:49:15.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m15s

advantage of height choice and again I'm
01:49:19.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m19s

not using a conceptual analogy to say
01:49:21.219
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m21s

player torches doing something like it
01:49:23.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m23s

I'm saying play torch is doing it now
01:49:25.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m25s

this is just the code you just saw
01:49:28.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m28s

wrapped up a little bit
01:49:30.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m30s

reflect it a little bit for your
01:49:32.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m32s

convenience right so where we say we now
01:49:33.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m33s

want to create an era ten call our it n
01:49:36.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m36s

then what this does is it does that for
01:49:39.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m39s

live now notice that our for loop needed
01:49:43.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m43s

a starting point you remember why right
01:49:47.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m47s

because otherwise our for loop didn't
01:49:51.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m51s

quite work we couldn't quite refactor it
01:49:53.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m53s

out and because this is exactly the same
01:49:54.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m54s

this needs our starting point to and so
01:49:56.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m56s

let's give it a starting point and so
01:49:59.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h49m59s

you have to pass in your initial hidden
01:50:01.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m01s

State
01:50:03.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m03s

for reasons that will become apparent
01:50:05.139
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m05s

later on it turns out to be quite useful
01:50:07.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m07s

to be able to get back that here in the
01:50:14.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m14s

state at the end and just like we could
01:50:17.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m17s

here we could actually keep track of the
01:50:20.409
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m20s

hidden state we get back to things we
01:50:21.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m21s

get back both the output and the hidden
01:50:25.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m25s

state right so we pass in the input in
01:50:28.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m28s

the hidden State when we get back the
01:50:30.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m30s

output and the hidden state yes could
01:50:32.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m32s

you remind us what the hint state
01:50:36.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m36s

represents the hidden state is H so it's
01:50:38.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m38s

the it's the orange circle ellipse of
01:50:42.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m42s

activations okay and so it is of size
01:50:49.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m49s

256 okay all right so we can okay
01:50:54.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h50m54s

there's one other thing too to know
01:51:06.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m06s

which is in our case we were replacing H
01:51:07.659
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m07s

with a new hidden state the one minor
01:51:11.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m11s

difference in pi torch is they append
01:51:16.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m16s

the new hidden state to a list or to a
01:51:19.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m19s

tensor which gets bigger and bigger so
01:51:22.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m22s

they actually give you back all of the
01:51:24.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m24s

hidden states so in other words rather
01:51:25.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m25s

than just giving you back the final
01:51:27.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m27s

ellipse they give you back all the
01:51:29.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m29s

ellipses stacked on top of each other
01:51:32.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m32s

and so because we just want the final
01:51:33.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m33s

one I was got indexed into it with minus
01:51:35.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m35s

one here okay other than that this is
01:51:38.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m38s

the same code as before put that through
01:51:40.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m40s

our output layer to get the correct
01:51:44.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m44s

vocab size and then we can train that
01:51:46.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m46s

alright so you can see here I can do it
01:51:57.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m57s

manually I can create some hidden state
01:51:59.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h51m59s

I can pass it to that area and I can see
01:52:01.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m01s

the stuff I get back you'll see that the
01:52:03.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m03s

dimensionality of H it's actually a rank
01:52:08.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m08s

3 tensor where else in my version it was
01:52:12.429
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m12s

a
01:52:16.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m16s

let's see it was a rank two tensor okay
01:52:19.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m19s

and the difference is here we've got
01:52:23.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m23s

just a unit axis at the front we'll
01:52:25.180
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m25s

learn more about why that is later but
01:52:28.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m28s

basically it turns out you can have a
01:52:30.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m30s

second R and n that goes backwards
01:52:32.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m32s

alright one that goes forwards one that
01:52:34.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m34s

goes backwards from the idea is neck and
01:52:36.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m36s

then it's going to be better at finding
01:52:38.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m38s

relationships that kind of go backwards
01:52:40.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m40s

that's quite a bi-directional eridan
01:52:43.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m43s

also it turns out you can have an error
01:52:44.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m44s

in feed to an iron in that's got a
01:52:47.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m47s

multi-layer eridan so basically if you
01:52:48.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m48s

have those things you need an additional
01:52:51.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m51s

access on your tensor to keep track of
01:52:53.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m53s

those additional layers of hidden state
01:52:56.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m56s

but for now we'll always have a one yeah
01:52:58.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h52m58s

and we'll always also get back a one at
01:53:01.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m01s

the end okay so if we go ahead and fit
01:53:05.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m05s

this now let's actually trade it for a
01:53:10.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m10s

bit longer
01:53:13.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m13s

okay so last time we only kind of did a
01:53:14.490
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m14s

couple of epochs this time we're due for
01:53:17.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m17s

a pox
01:53:20.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m20s

what have we sit at one in egg three and
01:53:21.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m21s

then we'll do another to epochs at one
01:53:24.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m24s

in egg four and so we've now got our
01:53:28.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m28s

lost down to one point five so getting
01:53:31.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m31s

better and better so here's our get next
01:53:34.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m34s

again okay and you know let's just it
01:53:39.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m39s

was the same thing so what we can now do
01:53:43.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m43s

is we can look through like forty times
01:53:45.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m45s

calling get next each time and then each
01:53:49.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m49s

time will replace our input by removing
01:53:52.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m52s

the first character and adding the thing
01:53:54.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m54s

that we just predicted and so that way
01:53:56.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m56s

we can like feed in a new set of eight
01:53:58.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h53m58s

characters that get them again and again
01:54:00.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m00s

and so that way we'll call that get next
01:54:02.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m02s

in so here are 40 characters that we've
01:54:05.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m05s

generated so we started out with four th
01:54:09.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m09s

OS so we got four those of the same -
01:54:11.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m11s

the same - the same you can probably
01:54:14.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m14s

guess what happens if you can't
01:54:17.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m17s

predicting the same - the same all right
01:54:18.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m18s

so it's you know it's doing okay we we
01:54:20.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m20s

now have something which you know
01:54:25.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m25s

we've basically built from scratch and
01:54:31.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m31s

then we've said here's how high torture
01:54:33.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m33s

effected it for us so if you want to
01:54:37.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m37s

like have an interesting little homework
01:54:39.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m39s

assignment this week try to write your
01:54:41.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m41s

own version of an RNN plus all right
01:54:44.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m44s

like try to like literally like create
01:54:48.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m48s

your like you know Jeremy's aren't in
01:54:51.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m51s

and then like type in here
01:54:53.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m53s

Jeremy's aren't in or in your case maybe
01:54:55.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m55s

your name's not Jeremy which is okay too
01:54:58.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h54m58s

and then get it to run writing your
01:55:00.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m00s

implementation that's fast from scratch
01:55:04.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m04s

without looking at the piped water
01:55:06.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m06s

source code you know like basically it's
01:55:07.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m07s

just a case of like going up and seeing
01:55:10.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m10s

what we did back here right and like
01:55:12.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m12s

make sure you get the same answers and
01:55:14.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m14s

confirm that you do so that's kind of a
01:55:17.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m17s

good little test simply simple at all
01:55:19.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m19s

assignment but I think you'll feel
01:55:21.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m21s

really good when you seem like oh I've
01:55:24.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m24s

just reimplemented an end alone in
01:55:25.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m25s

alright so I'm going to do one other
01:55:30.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m30s

thing when I switched from this one when
01:55:36.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m36s

I've moved the car one input inside the
01:55:37.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m37s

dotted line right this dotted rectangle
01:55:40.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m40s

represents the thing I'm repeating I
01:55:41.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m41s

also watch the triangle the output I
01:55:44.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m44s

moved that inside as well now that's a
01:55:47.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m47s

big difference
01:55:51.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m51s

because now what I've actually done is
01:55:51.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m51s

I'm actually saying spit out an output
01:55:55.800
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m55s

after every one of these circles so spit
01:55:59.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h55m59s

out an output here and here and here
01:56:03.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m03s

alright so in other words if I have a
01:56:07.200
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m07s

three character input I'm going to spit
01:56:09.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m09s

out a three character output I'm saying
01:56:12.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m12s

half the character 1 this will be next
01:56:13.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m13s

after character to this be next after
01:56:15.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m15s

character 3 this will be next
01:56:17.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m17s

so again nothing different
01:56:20.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m20s

and again this you know if you want to
01:56:24.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m24s

go a bit further with the assignment you
01:56:26.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m26s

could write this by hand as well but
01:56:28.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m28s

basically what we're saying is in the
01:56:31.450
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m31s

for loop would be saying like you know
01:56:33.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m33s

results equals some empty list right and
01:56:37.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m37s

then would be going through and rather
01:56:41.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m41s

than returning that
01:56:42.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m42s

we're instead be saying you know results
01:56:44.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m44s

dot append that right and then like
01:56:48.950
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m48s

return whatever torch dot stat something
01:56:55.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h56m55s

like that right that it made me right in
01:57:00.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m00s

my question so now you know we now have
01:57:02.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m02s

like every step we've created an output
01:57:05.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m05s

okay so which is basically this picture
01:57:09.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m09s

and so the reason was lots of reasons
01:57:13.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m13s

that's interesting but I think the main
01:57:16.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m16s

reason right now that's interesting is
01:57:19.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m19s

that you probably noticed this this
01:57:21.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m21s

approach to dealing with our data seems
01:57:29.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m29s

terribly inefficient like we're grabbing
01:57:32.060
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m32s

the first eight right but then this next
01:57:34.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m34s

set all but one of them overlap the
01:57:38.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m38s

previous one right so we're kind of like
01:57:41.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m41s

recalculating the exact set of
01:57:45.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m45s

embeddings seven out of eight of them
01:57:48.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m48s

are going to be exact same embeddings
01:57:50.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m50s

right exact same transitions it kind of
01:57:51.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m51s

seems weird to like do all this
01:57:55.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m55s

calculation to just predict one thing
01:57:58.160
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h57m58s

and then go back and recalculate seven
01:58:00.740
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m00s

out of eight of them and add one more to
01:58:02.840
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m02s

the end to calculate the next thing all
01:58:04.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m04s

right
01:58:06.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m06s

so the basic idea then is to say well
01:58:06.980
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m06s

let's not do it that way instead let's
01:58:09.590
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m09s

taking non overlapping sets of
01:58:16.430
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m16s

characters all right so like so here is
01:58:18.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m18s

our first eight characters here is the
01:58:22.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m22s

next day characters here are the next
01:58:25.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m25s

day characters so like if you read this
01:58:27.470
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m27s

top left to bottom right that would be
01:58:29.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m29s

the whole nature right and so then if
01:58:32.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m32s

these are the first eight characters
01:58:38.240
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m38s

then offset this by one starting here
01:58:39.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m39s

that's a list of outputs right so after
01:58:43.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m43s

we see characters zero through seven
01:58:48.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m48s

we should predict characters 1 through 8
01:58:51.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m51s

the XS so after 40 should come 42
01:58:54.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m54s

as it did after 42 should come 29 as it
01:58:58.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h58m58s

did okay and so now that can be our
01:59:02.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m02s

inputs and labels for that model and so
01:59:05.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m05s

it shouldn't be any more or less
01:59:11.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m11s

accurate it should just be the same
01:59:14.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m14s

right pretty much but it should allow us
01:59:17.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m17s

to do it more efficiently so let's try
01:59:20.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m20s

that all right
01:59:27.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m27s

so I mentioned last time that we had a
01:59:34.580
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m34s

minus 1 index here because we just
01:59:40.489
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m40s

wanted to grab the last triangle okay so
01:59:43.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m43s

in this case we're going to grab all the
01:59:48.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m48s

triangles so this this is actually the
01:59:50.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m50s

way it end on RNN creates things we we
01:59:52.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m52s

only kept the last one but this time
01:59:55.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m55s

we're going to keep all of them so we've
01:59:58.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=01h59m58s

made one change which is to remove that
02:00:06.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m06s

minus one other than that this is the
02:00:07.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m07s

exact same code as before okay so but
02:00:12.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m12s

there's nothing much to show you here I
02:00:22.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m22s

mean except of course at this time if we
02:00:24.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m24s

look at the labels it's now 512 by eight
02:00:26.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m26s

factors we're trying to predict eight
02:00:31.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m31s

things every time through so there is
02:00:33.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m33s

one complexity here which is that we
02:00:38.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m38s

want to use the negative log likelihood
02:00:42.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m42s

loss function as before right but the
02:00:46.670
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m46s

ligand if lost likelihood loss function
02:00:50.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m50s

just like our MSE expects to receive to
02:00:53.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m53s

rank one tensors actually with the
02:00:56.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m56s

mini-batch access to rank two tensors
02:00:59.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h00m59s

all right so two to mini-batches of
02:01:02.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m02s

vectors problem is that we've got
02:01:05.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m05s

eight-time steps you know it characters
02:01:12.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m12s

in an RNN we call it a time step right
02:01:15.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m15s

we have eight time steps and then for
02:01:18.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m18s

each one we have 84 probabilities we
02:01:20.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m20s

have the probability for every single
02:01:24.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m24s

one of those eight times deaths and then
02:01:27.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m27s

we have that for each of our 512 items
02:01:30.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m30s

in the mini batch so we have a rank 3
02:01:34.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m34s

tensor not a rank two tensor um so that
02:01:37.389
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m37s

means that the negative log likelihood
02:01:42.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m42s

loss function is going to spit out an
02:01:44.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m44s

error now frankly I think this is kind
02:01:46.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m46s

of dumb you know I think it would be
02:01:48.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m48s

better if PI torch had written the loss
02:01:50.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m50s

functions in such a way that they didn't
02:01:54.429
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m54s

care at all about rank and they just
02:01:56.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m56s

applied it to whatever rank you gave it
02:01:59.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h01m59s

but for now at least it does care about
02:02:01.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m01s

rick but the nice thing is I get to show
02:02:05.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m05s

you how to write a custom loss function
02:02:07.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m07s

okay so we're going to create a special
02:02:09.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m09s

negative log likelihood loss function
02:02:11.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m11s

for sequences okay and so it's going to
02:02:14.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m14s

take an input in the target and it's got
02:02:17.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m17s

a call f dot negative log likelihood
02:02:19.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m19s

lost so the pipe launched one all right
02:02:21.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m21s

but what we're going to do is we're
02:02:25.199
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m25s

going to flatten our input and we're
02:02:28.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m28s

going to flatten our targets right and
02:02:33.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m33s

so and it turns out these are going to
02:02:37.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m37s

be the first two axes that I have to be
02:02:40.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m40s

transposed so the way PI torch handles
02:02:45.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m45s

are and end data by default is the first
02:02:50.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m50s

axis is the sequence length in this case
02:02:54.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m54s

eight right so the sequence length of an
02:02:56.860
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m56s

R and n is how many times deaths so we
02:02:59.199
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h02m59s

have eight characters so a sequence
02:03:02.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m02s

length of eight the second axis is the
02:03:04.449
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m04s

batch size and then as would expect the
02:03:06.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m06s

third axis is the actual hidden state
02:03:10.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m10s

itself okay so this is going to be eight
02:03:12.520
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m12s

by 512 by n hidden which I think was 256
02:03:15.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m15s

yeah
02:03:22.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m22s

okay so we can grab the size and unpack
02:03:24.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m24s

it into each of these sequence length
02:03:28.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m28s

batch size and I'm hidden now target
02:03:31.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m31s

mighty dot size is 512 by 8 where else
02:03:39.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m39s

this one here was 8 by 512 so to make
02:03:49.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m49s

them match we're going to have to
02:03:53.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m53s

transpose the first two axis okay
02:03:55.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h03m55s

[Music]
02:04:00.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m00s

hi torch when you do something like
02:04:01.540
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m01s

transpose doesn't generally actually
02:04:04.100
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m04s

shuffle the memory order but instead it
02:04:06.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m06s

just kind of keeps some internal
02:04:09.380
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m09s

metadata to say like hey you should
02:04:11.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m11s

treat this as if it's transposed and
02:04:13.940
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m13s

some things in pi torch will give you an
02:04:17.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m17s

error if you try and use it when it has
02:04:20.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m20s

these like this internal state and I
02:04:23.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m23s

basically say error this tensor is not
02:04:26.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m26s

contiguous if you ever see that error at
02:04:30.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m30s

the word contiguous after it and it goes
02:04:33.260
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m33s

away so I don't know they can't do that
02:04:35.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m35s

for you apparently so in this particular
02:04:38.150
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m38s

case I got that error so I wrote the
02:04:39.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m39s

code contiguous after it okay and so
02:04:41.510
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m41s

then finally we need to flatten it out
02:04:44.239
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m44s

into a single vector and so we can just
02:04:46.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m46s

go a dot view which is the same as non
02:04:49.130
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m49s

PI dot reshape and minus one means as
02:04:50.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m50s

long as it needs to be okay and then the
02:04:53.719
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m53s

input again we also reshape that right
02:04:58.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h04m58s

but remember the input sorry the the the
02:05:02.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m02s

predictions also have this axis of
02:05:05.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m05s

length 84 all of the predicted
02:05:09.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m09s

probabilities okay so so here's a custom
02:05:11.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m11s

these are custom lost function that's it
02:05:15.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m15s

right so if you ever want to play around
02:05:18.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m18s

with your own loss functions you can
02:05:20.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m20s

just do that like so and then pass that
02:05:22.850
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m22s

to fit okay so it's important to
02:05:27.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m27s

remember that Fitch is this like lowest
02:05:30.710
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m30s

level fast AI abstraction
02:05:34.400
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m34s

that's--it's that this is the thing that
02:05:37.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m37s

implements the training look okay and so
02:05:39.790
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m39s

like you're the stuff you pass it in is
02:05:42.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m42s

all standard pi torch stuff except for
02:05:45.970
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m45s

this this is our model data object this
02:05:50.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m50s

is the thing that wraps up the test set
02:05:53.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m53s

the training set and the validation set
02:05:56.010
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m56s

to get that okay your neck could you
02:05:58.600
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h05m58s

pass that back so when we pull the
02:06:01.420
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m01s

triangle into the replicator structure
02:06:06.460
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m06s

right so the the first n minus one
02:06:09.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m09s

iterations of the sequence length we
02:06:13.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m13s

don't see the whole sequence length yeah
02:06:15.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m15s

so does that mean that the batch size
02:06:18.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m18s

should be much bigger so that be careful
02:06:20.500
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m20s

you don't mean that size you main
02:06:24.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m24s

sequence length right because the batch
02:06:26.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m26s

size is like some firing yeah okay so
02:06:28.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m28s

yes yes if you have a short sequence
02:06:31.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m31s

length like eight yeah
02:06:34.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m34s

the first character has nothing to go on
02:06:37.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m37s

it starts with an empty hidden state of
02:06:41.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m41s

zeros okay so what we're going to start
02:06:46.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m46s

with next week
02:06:49.720
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m49s

is we're going to learn how to avoid
02:06:51.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m51s

that problem right and so it's a really
02:06:52.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m52s

insightful question or concern right and
02:06:55.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m55s

but if you think about it the basic idea
02:06:59.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h06m59s

is why should we reset this to zero
02:07:01.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m01s

every time you know like if we can kind
02:07:05.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m05s

of line up these mini batches somehow so
02:07:09.910
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m09s

that the next mini batch joins up
02:07:13.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m13s

correctly it represents like the next
02:07:16.780
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m16s

letter in leaches works then we'd want
02:07:18.640
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m18s

to move this up into the constructor
02:07:22.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m22s

right and then like pass that here and
02:07:26.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m26s

then store it here right and now we're
02:07:32.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m32s

not resetting the hidden state each time
02:07:38.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m38s

we're actually we're actually keeping
02:07:40.210
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m40s

the hidden state from call to call and
02:07:43.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m43s

so the only time that it would be
02:07:45.220
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m45s

failing to benefit from
02:07:48.340
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m48s

learning state would be like literally
02:07:51.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m51s

at the very start of the document so
02:07:53.109
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m53s

that's where but that's where we're
02:07:55.569
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m55s

going to try and ahead next week
02:07:56.559
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m56s

I feel like this lesson every time I've
02:07:58.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h07m58s

got a punch line coming somebody asks me
02:08:09.069
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m09s

a question where I have to like do the
02:08:11.169
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m11s

punch line ahead of time okay so we can
02:08:13.149
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m13s

fit that and we can fit that and I want
02:08:17.649
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m17s

to show you something interesting and
02:08:21.339
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m21s

this is coming to the punch line that
02:08:22.899
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m22s

another punch line that you net try to
02:08:25.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m25s

spoil which is when we're you know
02:08:27.369
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m27s

remember this is just doing a loop right
02:08:33.909
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m33s

applying the same matrix multiply again
02:08:35.979
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m35s

and again if that matrix multiply tends
02:08:37.689
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m37s

to increase the activations each time
02:08:42.669
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m42s

then effectively we're doing that to the
02:08:46.419
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m46s

power of eight right so it's going to
02:08:48.879
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m48s

like to shoot off really high or if it's
02:08:50.439
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m50s

decreasing it a little bit each time
02:08:53.319
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m53s

that's going to shoot off really low so
02:08:54.869
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m54s

this is what we call a gradient
02:08:57.760
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m57s

explosion right and so we really want to
02:08:58.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h08m58s

make sure that the initial H naught H
02:09:01.659
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m01s

the initial but if we call it the
02:09:07.209
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m07s

initial L hidden that we create is is
02:09:11.889
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m11s

like oversize that's not going to cause
02:09:16.359
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m16s

our activations on average to increase
02:09:19.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m19s

or decrease right and there's actually a
02:09:22.149
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m22s

very nice matrix that does exactly that
02:09:25.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m25s

called the identity matrix so the
02:09:29.939
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m29s

identity matrix for those that don't
02:09:33.459
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m33s

quite remember their linear algebra is
02:09:35.589
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m35s

this this would be a size 3 identity
02:09:39.039
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m39s

matrix all right and so the trick about
02:09:42.309
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m42s

an identity matrix is anything times an
02:09:46.959
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m46s

identity matrix is itself right and so
02:09:49.839
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m49s

therefore you could multiply it by this
02:09:52.929
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m52s

again and again and again and again and
02:09:54.519
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m54s

still end up with itself right so
02:09:56.439
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m56s

there's no gradient explosion so what we
02:09:59.289
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h09m59s

could do is instead
02:10:03.280
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m03s

of using whatever the default random in
02:10:04.690
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m04s

it is for this matrix we could instead
02:10:08.080
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m08s

after we create our errand in is we can
02:10:11.230
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m11s

go into that
02:10:14.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m14s

Erol in right and notice this right we
02:10:15.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m15s

can go m dot RN n right and if we now go
02:10:17.410
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m17s

like so we can get the docs for m dot R
02:10:22.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m22s

and M right and as well as the arguments
02:10:25.989
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m25s

for constructing it it also tells you
02:10:29.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m29s

the inputs and outputs for calling the
02:10:31.930
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m31s

layer and it also tells you the
02:10:33.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m33s

attributes and so it tells you there's
02:10:35.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m35s

something called weight
02:10:37.960
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m37s

H H and these are the learn about hidden
02:10:39.610
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m39s

to hidden weights that's that square
02:10:42.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m42s

matrix right so after we've constructed
02:10:43.480
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m43s

our M we can just go in and say all
02:10:46.390
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m46s

right m dot R and n dot weight h HL dot
02:10:49.120
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m49s

data that's the tensor dot copy
02:10:55.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m55s

underscore in place torch I that is I
02:10:58.680
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h10m58s

for identity in case you are wondering
02:11:03.820
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m03s

so this is an identity matrix of size n
02:11:07.920
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m07s

hidden so this both puts into this
02:11:11.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m11s

weight matrix and returns the identity
02:11:14.949
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m14s

matrix and so this was like actually a
02:11:18.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m18s

Geoffrey Hinton paper was like hey you
02:11:24.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m24s

know after it was it's 2015
02:11:29.110
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m29s

so after recurrent neural Nets have been
02:11:31.449
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m31s

around for decades here's like hey gang
02:11:34.270
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m34s

maybe we should just use the identity
02:11:38.190
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m38s

matrix to initialize this and like it
02:11:40.449
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m40s

actually turns out to work really well
02:11:44.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m44s

and so that was a 2015 paper believe it
02:11:46.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m46s

or not from the father of neural
02:11:49.870
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m49s

networks and so here is the here is our
02:11:52.000
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m52s

implementation of his paper and this is
02:11:54.550
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m54s

an important thing to know right when
02:11:56.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m56s

very famous people like Geoffrey Hinton
02:11:58.090
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m58s

write a paper sometimes in entire
02:11:59.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h11m59s

implementation of that paper looks like
02:12:02.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m02s

one line of code okay so let's do it
02:12:04.810
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m04s

before we got point six one two five
02:12:07.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m07s

seven we'll fit it with exactly the same
02:12:10.660
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m10s

parameters and now we get 0.5 1 and in
02:12:12.969
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m12s

fact
02:12:16.630
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m16s

can keep training 0.50 so like this
02:12:16.900
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m16s

tweak really really really helped okay
02:12:19.330
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m19s

now one of the nice things about this
02:12:22.360
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m22s

tweak was before I could only use a
02:12:24.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m24s

learning rate of one in x3 before it
02:12:26.739
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m26s

started going crazy but after identity
02:12:29.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m29s

matrix I found I could use one in egg
02:12:32.620
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m32s

too because it's you know it's better
02:12:34.300
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m34s

behaved weight initialization I found I
02:12:36.429
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m36s

could use a higher learning rate okay
02:12:38.770
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m38s

and honestly these things you know
02:12:41.890
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m41s

increasingly we're trying to incorporate
02:12:46.750
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m46s

into the defaults in first day I you
02:12:49.179
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m49s

know you don't necessarily personally
02:12:51.370
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m51s

need to actually know them but you know
02:12:53.650
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m53s

at this point we're still at a point
02:12:56.020
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m56s

where you know most things in most
02:12:59.140
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h12m59s

libraries most of the time don't have
02:13:00.730
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m00s

great defaults it's good to know all
02:13:02.290
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m02s

these little tricks it's also nice to
02:13:03.880
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m03s

know if you want to improve something
02:13:05.679
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m05s

what kind of tricks people have used
02:13:07.170
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m07s

elsewhere because you can often borrow
02:13:09.310
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m09s

them yourself all right well that's the
02:13:11.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m11s

end of the lesson today and so next week
02:13:15.250
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m15s

we will look at this idea of a stateful
02:13:17.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m17s

RNN that's going to keep this hidden
02:13:20.560
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m20s

state around and then we're going to go
02:13:22.030
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m22s

back to looking at language models again
02:13:23.830
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m23s

and then finally we're going to go all
02:13:27.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m27s

the way back to computer vision and
02:13:28.570
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m28s

learn about things like rez nets and
02:13:30.070
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m30s

batch norm and all the tricks that were
02:13:32.530
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m32s

in figured out in cats versus dogs see
02:13:35.350
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m35s

you then
02:13:38.440
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m38s

[Applause]
02:13:41.040
https://www.youtube.com/watch?v=sHcLkfRrgoQ#t=02h13m41s

